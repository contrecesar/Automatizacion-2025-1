{
  "log_history": [
    {
      "epoch": 0.004948045522018802,
      "grad_norm": 2.083307981491089,
      "learning_rate": 1.9970311726867887e-05,
      "loss": 0.6662,
      "step": 10
    },
    {
      "epoch": 0.009896091044037604,
      "grad_norm": 2.7390191555023193,
      "learning_rate": 1.9937324756721097e-05,
      "loss": 0.5219,
      "step": 20
    },
    {
      "epoch": 0.014844136566056407,
      "grad_norm": 6.878846645355225,
      "learning_rate": 1.9904337786574303e-05,
      "loss": 0.37,
      "step": 30
    },
    {
      "epoch": 0.01979218208807521,
      "grad_norm": 4.318190097808838,
      "learning_rate": 1.9871350816427513e-05,
      "loss": 0.2521,
      "step": 40
    },
    {
      "epoch": 0.024740227610094014,
      "grad_norm": 9.216415405273438,
      "learning_rate": 1.9838363846280723e-05,
      "loss": 0.2093,
      "step": 50
    },
    {
      "epoch": 0.029688273132112815,
      "grad_norm": 8.236034393310547,
      "learning_rate": 1.980537687613393e-05,
      "loss": 0.1832,
      "step": 60
    },
    {
      "epoch": 0.034636318654131616,
      "grad_norm": 4.756049633026123,
      "learning_rate": 1.9772389905987135e-05,
      "loss": 0.1945,
      "step": 70
    },
    {
      "epoch": 0.03958436417615042,
      "grad_norm": 5.219125747680664,
      "learning_rate": 1.9739402935840345e-05,
      "loss": 0.24,
      "step": 80
    },
    {
      "epoch": 0.044532409698169226,
      "grad_norm": 3.162048578262329,
      "learning_rate": 1.970641596569355e-05,
      "loss": 0.1362,
      "step": 90
    },
    {
      "epoch": 0.04948045522018803,
      "grad_norm": 4.394230365753174,
      "learning_rate": 1.967342899554676e-05,
      "loss": 0.1812,
      "step": 100
    },
    {
      "epoch": 0.05442850074220683,
      "grad_norm": 0.19086267054080963,
      "learning_rate": 1.9640442025399968e-05,
      "loss": 0.0725,
      "step": 110
    },
    {
      "epoch": 0.05937654626422563,
      "grad_norm": 0.19721370935440063,
      "learning_rate": 1.9607455055253177e-05,
      "loss": 0.1096,
      "step": 120
    },
    {
      "epoch": 0.06432459178624443,
      "grad_norm": 13.479732513427734,
      "learning_rate": 1.9574468085106384e-05,
      "loss": 0.1201,
      "step": 130
    },
    {
      "epoch": 0.06927263730826323,
      "grad_norm": 0.12804940342903137,
      "learning_rate": 1.9541481114959593e-05,
      "loss": 0.0866,
      "step": 140
    },
    {
      "epoch": 0.07422068283028203,
      "grad_norm": 0.24177192151546478,
      "learning_rate": 1.95084941448128e-05,
      "loss": 0.0846,
      "step": 150
    },
    {
      "epoch": 0.07916872835230084,
      "grad_norm": 2.2864034175872803,
      "learning_rate": 1.947550717466601e-05,
      "loss": 0.1581,
      "step": 160
    },
    {
      "epoch": 0.08411677387431965,
      "grad_norm": 4.249545574188232,
      "learning_rate": 1.9442520204519216e-05,
      "loss": 0.2232,
      "step": 170
    },
    {
      "epoch": 0.08906481939633845,
      "grad_norm": 0.34422767162323,
      "learning_rate": 1.9409533234372425e-05,
      "loss": 0.1256,
      "step": 180
    },
    {
      "epoch": 0.09401286491835725,
      "grad_norm": 0.42557862401008606,
      "learning_rate": 1.9376546264225632e-05,
      "loss": 0.1423,
      "step": 190
    },
    {
      "epoch": 0.09896091044037605,
      "grad_norm": 19.31597328186035,
      "learning_rate": 1.9343559294078838e-05,
      "loss": 0.111,
      "step": 200
    },
    {
      "epoch": 0.10390895596239486,
      "grad_norm": 0.08680129796266556,
      "learning_rate": 1.9310572323932048e-05,
      "loss": 0.0668,
      "step": 210
    },
    {
      "epoch": 0.10885700148441366,
      "grad_norm": 0.1590888947248459,
      "learning_rate": 1.9277585353785254e-05,
      "loss": 0.1487,
      "step": 220
    },
    {
      "epoch": 0.11380504700643246,
      "grad_norm": 1.1533154249191284,
      "learning_rate": 1.9244598383638464e-05,
      "loss": 0.0903,
      "step": 230
    },
    {
      "epoch": 0.11875309252845126,
      "grad_norm": 0.5391048789024353,
      "learning_rate": 1.9211611413491674e-05,
      "loss": 0.1996,
      "step": 240
    },
    {
      "epoch": 0.12370113805047006,
      "grad_norm": 3.9532554149627686,
      "learning_rate": 1.917862444334488e-05,
      "loss": 0.0967,
      "step": 250
    },
    {
      "epoch": 0.12864918357248886,
      "grad_norm": 10.393773078918457,
      "learning_rate": 1.914563747319809e-05,
      "loss": 0.1028,
      "step": 260
    },
    {
      "epoch": 0.13359722909450766,
      "grad_norm": 5.41870641708374,
      "learning_rate": 1.9112650503051296e-05,
      "loss": 0.1046,
      "step": 270
    },
    {
      "epoch": 0.13854527461652646,
      "grad_norm": 4.591911315917969,
      "learning_rate": 1.9079663532904506e-05,
      "loss": 0.1047,
      "step": 280
    },
    {
      "epoch": 0.14349332013854527,
      "grad_norm": 0.9195568561553955,
      "learning_rate": 1.9046676562757712e-05,
      "loss": 0.0627,
      "step": 290
    },
    {
      "epoch": 0.14844136566056407,
      "grad_norm": 10.907586097717285,
      "learning_rate": 1.901368959261092e-05,
      "loss": 0.2917,
      "step": 300
    },
    {
      "epoch": 0.15338941118258287,
      "grad_norm": 9.88653564453125,
      "learning_rate": 1.8980702622464128e-05,
      "loss": 0.1186,
      "step": 310
    },
    {
      "epoch": 0.15833745670460167,
      "grad_norm": 0.14319217205047607,
      "learning_rate": 1.8947715652317334e-05,
      "loss": 0.1927,
      "step": 320
    },
    {
      "epoch": 0.16328550222662047,
      "grad_norm": 1.7564142942428589,
      "learning_rate": 1.8914728682170544e-05,
      "loss": 0.079,
      "step": 330
    },
    {
      "epoch": 0.1682335477486393,
      "grad_norm": 0.11367207020521164,
      "learning_rate": 1.888174171202375e-05,
      "loss": 0.0614,
      "step": 340
    },
    {
      "epoch": 0.1731815932706581,
      "grad_norm": 3.21763277053833,
      "learning_rate": 1.884875474187696e-05,
      "loss": 0.2662,
      "step": 350
    },
    {
      "epoch": 0.1781296387926769,
      "grad_norm": 4.511270046234131,
      "learning_rate": 1.881576777173017e-05,
      "loss": 0.0934,
      "step": 360
    },
    {
      "epoch": 0.1830776843146957,
      "grad_norm": 0.21536241471767426,
      "learning_rate": 1.8782780801583376e-05,
      "loss": 0.1201,
      "step": 370
    },
    {
      "epoch": 0.1880257298367145,
      "grad_norm": 7.710086822509766,
      "learning_rate": 1.8749793831436586e-05,
      "loss": 0.0766,
      "step": 380
    },
    {
      "epoch": 0.1929737753587333,
      "grad_norm": 0.07848420739173889,
      "learning_rate": 1.8716806861289792e-05,
      "loss": 0.0344,
      "step": 390
    },
    {
      "epoch": 0.1979218208807521,
      "grad_norm": 2.123512029647827,
      "learning_rate": 1.8683819891143e-05,
      "loss": 0.0804,
      "step": 400
    },
    {
      "epoch": 0.2028698664027709,
      "grad_norm": 19.27537727355957,
      "learning_rate": 1.865083292099621e-05,
      "loss": 0.1201,
      "step": 410
    },
    {
      "epoch": 0.2078179119247897,
      "grad_norm": 0.7075232863426208,
      "learning_rate": 1.8617845950849415e-05,
      "loss": 0.0747,
      "step": 420
    },
    {
      "epoch": 0.2127659574468085,
      "grad_norm": 1.48856782913208,
      "learning_rate": 1.8584858980702624e-05,
      "loss": 0.0479,
      "step": 430
    },
    {
      "epoch": 0.2177140029688273,
      "grad_norm": 0.04681114852428436,
      "learning_rate": 1.855187201055583e-05,
      "loss": 0.0651,
      "step": 440
    },
    {
      "epoch": 0.22266204849084612,
      "grad_norm": 0.5338934063911438,
      "learning_rate": 1.851888504040904e-05,
      "loss": 0.028,
      "step": 450
    },
    {
      "epoch": 0.22761009401286492,
      "grad_norm": 1.1672910451889038,
      "learning_rate": 1.8485898070262247e-05,
      "loss": 0.0618,
      "step": 460
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 0.03572314605116844,
      "learning_rate": 1.8452911100115457e-05,
      "loss": 0.1013,
      "step": 470
    },
    {
      "epoch": 0.23750618505690252,
      "grad_norm": 0.13009002804756165,
      "learning_rate": 1.8419924129968666e-05,
      "loss": 0.0387,
      "step": 480
    },
    {
      "epoch": 0.24245423057892132,
      "grad_norm": 0.052606333047151566,
      "learning_rate": 1.8386937159821873e-05,
      "loss": 0.0493,
      "step": 490
    },
    {
      "epoch": 0.24740227610094012,
      "grad_norm": 3.4013123512268066,
      "learning_rate": 1.835395018967508e-05,
      "loss": 0.0868,
      "step": 500
    },
    {
      "epoch": 0.25235032162295895,
      "grad_norm": 0.3067084848880768,
      "learning_rate": 1.832096321952829e-05,
      "loss": 0.1195,
      "step": 510
    },
    {
      "epoch": 0.2572983671449777,
      "grad_norm": 1.599831461906433,
      "learning_rate": 1.8287976249381495e-05,
      "loss": 0.154,
      "step": 520
    },
    {
      "epoch": 0.26224641266699655,
      "grad_norm": 2.829253911972046,
      "learning_rate": 1.82549892792347e-05,
      "loss": 0.161,
      "step": 530
    },
    {
      "epoch": 0.2671944581890153,
      "grad_norm": 0.6623570919036865,
      "learning_rate": 1.822200230908791e-05,
      "loss": 0.1297,
      "step": 540
    },
    {
      "epoch": 0.27214250371103416,
      "grad_norm": 12.95406723022461,
      "learning_rate": 1.818901533894112e-05,
      "loss": 0.0789,
      "step": 550
    },
    {
      "epoch": 0.27709054923305293,
      "grad_norm": 0.39347994327545166,
      "learning_rate": 1.8156028368794327e-05,
      "loss": 0.0469,
      "step": 560
    },
    {
      "epoch": 0.28203859475507176,
      "grad_norm": 0.40931206941604614,
      "learning_rate": 1.8123041398647537e-05,
      "loss": 0.0639,
      "step": 570
    },
    {
      "epoch": 0.28698664027709053,
      "grad_norm": 5.183740615844727,
      "learning_rate": 1.8090054428500743e-05,
      "loss": 0.1431,
      "step": 580
    },
    {
      "epoch": 0.29193468579910936,
      "grad_norm": 0.030934404581785202,
      "learning_rate": 1.8057067458353953e-05,
      "loss": 0.0715,
      "step": 590
    },
    {
      "epoch": 0.29688273132112813,
      "grad_norm": 18.160383224487305,
      "learning_rate": 1.802408048820716e-05,
      "loss": 0.0577,
      "step": 600
    },
    {
      "epoch": 0.30183077684314696,
      "grad_norm": 0.06146349757909775,
      "learning_rate": 1.799109351806037e-05,
      "loss": 0.0733,
      "step": 610
    },
    {
      "epoch": 0.30677882236516574,
      "grad_norm": 0.08057578653097153,
      "learning_rate": 1.7958106547913575e-05,
      "loss": 0.1204,
      "step": 620
    },
    {
      "epoch": 0.31172686788718457,
      "grad_norm": 22.585683822631836,
      "learning_rate": 1.792511957776678e-05,
      "loss": 0.1668,
      "step": 630
    },
    {
      "epoch": 0.31667491340920334,
      "grad_norm": 7.928167343139648,
      "learning_rate": 1.789213260761999e-05,
      "loss": 0.0553,
      "step": 640
    },
    {
      "epoch": 0.32162295893122217,
      "grad_norm": 0.14058524370193481,
      "learning_rate": 1.7859145637473198e-05,
      "loss": 0.1154,
      "step": 650
    },
    {
      "epoch": 0.32657100445324094,
      "grad_norm": 13.486061096191406,
      "learning_rate": 1.7826158667326407e-05,
      "loss": 0.0356,
      "step": 660
    },
    {
      "epoch": 0.33151904997525977,
      "grad_norm": 17.393245697021484,
      "learning_rate": 1.7793171697179617e-05,
      "loss": 0.0242,
      "step": 670
    },
    {
      "epoch": 0.3364670954972786,
      "grad_norm": 18.788312911987305,
      "learning_rate": 1.7760184727032823e-05,
      "loss": 0.0851,
      "step": 680
    },
    {
      "epoch": 0.3414151410192974,
      "grad_norm": 12.172231674194336,
      "learning_rate": 1.7727197756886033e-05,
      "loss": 0.0884,
      "step": 690
    },
    {
      "epoch": 0.3463631865413162,
      "grad_norm": 0.04007274657487869,
      "learning_rate": 1.769421078673924e-05,
      "loss": 0.1315,
      "step": 700
    },
    {
      "epoch": 0.351311232063335,
      "grad_norm": 8.392043113708496,
      "learning_rate": 1.766122381659245e-05,
      "loss": 0.1236,
      "step": 710
    },
    {
      "epoch": 0.3562592775853538,
      "grad_norm": 0.5907721519470215,
      "learning_rate": 1.7628236846445655e-05,
      "loss": 0.1519,
      "step": 720
    },
    {
      "epoch": 0.3612073231073726,
      "grad_norm": 0.5257152318954468,
      "learning_rate": 1.7595249876298862e-05,
      "loss": 0.037,
      "step": 730
    },
    {
      "epoch": 0.3661553686293914,
      "grad_norm": 10.932088851928711,
      "learning_rate": 1.756226290615207e-05,
      "loss": 0.0988,
      "step": 740
    },
    {
      "epoch": 0.3711034141514102,
      "grad_norm": 18.741071701049805,
      "learning_rate": 1.7529275936005278e-05,
      "loss": 0.0791,
      "step": 750
    },
    {
      "epoch": 0.376051459673429,
      "grad_norm": 0.09219519793987274,
      "learning_rate": 1.7496288965858488e-05,
      "loss": 0.0436,
      "step": 760
    },
    {
      "epoch": 0.3809995051954478,
      "grad_norm": 5.648781776428223,
      "learning_rate": 1.7463301995711694e-05,
      "loss": 0.0706,
      "step": 770
    },
    {
      "epoch": 0.3859475507174666,
      "grad_norm": 14.037808418273926,
      "learning_rate": 1.7430315025564904e-05,
      "loss": 0.2534,
      "step": 780
    },
    {
      "epoch": 0.3908955962394854,
      "grad_norm": 0.11006524413824081,
      "learning_rate": 1.7397328055418113e-05,
      "loss": 0.1036,
      "step": 790
    },
    {
      "epoch": 0.3958436417615042,
      "grad_norm": 0.060364361852407455,
      "learning_rate": 1.736434108527132e-05,
      "loss": 0.055,
      "step": 800
    },
    {
      "epoch": 0.400791687283523,
      "grad_norm": 0.09602401405572891,
      "learning_rate": 1.733135411512453e-05,
      "loss": 0.0886,
      "step": 810
    },
    {
      "epoch": 0.4057397328055418,
      "grad_norm": 11.859095573425293,
      "learning_rate": 1.7298367144977736e-05,
      "loss": 0.0266,
      "step": 820
    },
    {
      "epoch": 0.4106877783275606,
      "grad_norm": 0.07104148715734482,
      "learning_rate": 1.7265380174830942e-05,
      "loss": 0.0497,
      "step": 830
    },
    {
      "epoch": 0.4156358238495794,
      "grad_norm": 0.031956661492586136,
      "learning_rate": 1.7232393204684152e-05,
      "loss": 0.0637,
      "step": 840
    },
    {
      "epoch": 0.4205838693715982,
      "grad_norm": 7.584319591522217,
      "learning_rate": 1.7199406234537358e-05,
      "loss": 0.1158,
      "step": 850
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 0.09121901541948318,
      "learning_rate": 1.7166419264390568e-05,
      "loss": 0.1393,
      "step": 860
    },
    {
      "epoch": 0.4304799604156358,
      "grad_norm": 7.501597881317139,
      "learning_rate": 1.7133432294243774e-05,
      "loss": 0.0619,
      "step": 870
    },
    {
      "epoch": 0.4354280059376546,
      "grad_norm": 0.5705838799476624,
      "learning_rate": 1.7100445324096984e-05,
      "loss": 0.0351,
      "step": 880
    },
    {
      "epoch": 0.44037605145967346,
      "grad_norm": 9.694978713989258,
      "learning_rate": 1.706745835395019e-05,
      "loss": 0.1203,
      "step": 890
    },
    {
      "epoch": 0.44532409698169223,
      "grad_norm": 8.816353797912598,
      "learning_rate": 1.70344713838034e-05,
      "loss": 0.1703,
      "step": 900
    },
    {
      "epoch": 0.45027214250371106,
      "grad_norm": 0.23506025969982147,
      "learning_rate": 1.7001484413656606e-05,
      "loss": 0.1034,
      "step": 910
    },
    {
      "epoch": 0.45522018802572983,
      "grad_norm": 0.061143603175878525,
      "learning_rate": 1.6968497443509816e-05,
      "loss": 0.0464,
      "step": 920
    },
    {
      "epoch": 0.46016823354774866,
      "grad_norm": 0.9215734004974365,
      "learning_rate": 1.6935510473363022e-05,
      "loss": 0.0753,
      "step": 930
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 0.040241893380880356,
      "learning_rate": 1.6902523503216232e-05,
      "loss": 0.0564,
      "step": 940
    },
    {
      "epoch": 0.47006432459178626,
      "grad_norm": 0.26941952109336853,
      "learning_rate": 1.686953653306944e-05,
      "loss": 0.0472,
      "step": 950
    },
    {
      "epoch": 0.47501237011380504,
      "grad_norm": 9.566105842590332,
      "learning_rate": 1.6836549562922645e-05,
      "loss": 0.0075,
      "step": 960
    },
    {
      "epoch": 0.47996041563582387,
      "grad_norm": 13.46181583404541,
      "learning_rate": 1.6803562592775854e-05,
      "loss": 0.1029,
      "step": 970
    },
    {
      "epoch": 0.48490846115784264,
      "grad_norm": 20.636093139648438,
      "learning_rate": 1.6770575622629064e-05,
      "loss": 0.0872,
      "step": 980
    },
    {
      "epoch": 0.48985650667986147,
      "grad_norm": 0.32675328850746155,
      "learning_rate": 1.673758865248227e-05,
      "loss": 0.0853,
      "step": 990
    },
    {
      "epoch": 0.49480455220188024,
      "grad_norm": 0.012083613313734531,
      "learning_rate": 1.670460168233548e-05,
      "loss": 0.0021,
      "step": 1000
    },
    {
      "epoch": 0.4997525977238991,
      "grad_norm": 0.043934937566518784,
      "learning_rate": 1.6671614712188687e-05,
      "loss": 0.0862,
      "step": 1010
    },
    {
      "epoch": 0.5047006432459179,
      "grad_norm": 0.09779392927885056,
      "learning_rate": 1.6638627742041896e-05,
      "loss": 0.0915,
      "step": 1020
    },
    {
      "epoch": 0.5096486887679367,
      "grad_norm": 8.221818923950195,
      "learning_rate": 1.6605640771895103e-05,
      "loss": 0.0753,
      "step": 1030
    },
    {
      "epoch": 0.5145967342899554,
      "grad_norm": 0.03063368983566761,
      "learning_rate": 1.6572653801748312e-05,
      "loss": 0.0304,
      "step": 1040
    },
    {
      "epoch": 0.5195447798119742,
      "grad_norm": 2.528777837753296,
      "learning_rate": 1.653966683160152e-05,
      "loss": 0.1146,
      "step": 1050
    },
    {
      "epoch": 0.5244928253339931,
      "grad_norm": 0.02647237479686737,
      "learning_rate": 1.6506679861454725e-05,
      "loss": 0.0445,
      "step": 1060
    },
    {
      "epoch": 0.5294408708560119,
      "grad_norm": 1.3835035562515259,
      "learning_rate": 1.6473692891307935e-05,
      "loss": 0.0487,
      "step": 1070
    },
    {
      "epoch": 0.5343889163780307,
      "grad_norm": 0.15118873119354248,
      "learning_rate": 1.644070592116114e-05,
      "loss": 0.0663,
      "step": 1080
    },
    {
      "epoch": 0.5393369619000494,
      "grad_norm": 23.11678123474121,
      "learning_rate": 1.640771895101435e-05,
      "loss": 0.1359,
      "step": 1090
    },
    {
      "epoch": 0.5442850074220683,
      "grad_norm": 1.441372036933899,
      "learning_rate": 1.6374731980867557e-05,
      "loss": 0.0342,
      "step": 1100
    },
    {
      "epoch": 0.5492330529440871,
      "grad_norm": 0.08466717600822449,
      "learning_rate": 1.6341745010720767e-05,
      "loss": 0.0485,
      "step": 1110
    },
    {
      "epoch": 0.5541810984661059,
      "grad_norm": 0.029211582615971565,
      "learning_rate": 1.6308758040573976e-05,
      "loss": 0.0445,
      "step": 1120
    },
    {
      "epoch": 0.5591291439881247,
      "grad_norm": 0.028145791962742805,
      "learning_rate": 1.6275771070427183e-05,
      "loss": 0.0555,
      "step": 1130
    },
    {
      "epoch": 0.5640771895101435,
      "grad_norm": 0.02021896094083786,
      "learning_rate": 1.6242784100280393e-05,
      "loss": 0.0575,
      "step": 1140
    },
    {
      "epoch": 0.5690252350321623,
      "grad_norm": 0.07333213090896606,
      "learning_rate": 1.62097971301336e-05,
      "loss": 0.0503,
      "step": 1150
    },
    {
      "epoch": 0.5739732805541811,
      "grad_norm": 0.0699671059846878,
      "learning_rate": 1.6176810159986805e-05,
      "loss": 0.0163,
      "step": 1160
    },
    {
      "epoch": 0.5789213260762,
      "grad_norm": 14.429854393005371,
      "learning_rate": 1.6143823189840015e-05,
      "loss": 0.0917,
      "step": 1170
    },
    {
      "epoch": 0.5838693715982187,
      "grad_norm": 0.05973955988883972,
      "learning_rate": 1.611083621969322e-05,
      "loss": 0.0611,
      "step": 1180
    },
    {
      "epoch": 0.5888174171202375,
      "grad_norm": 9.14852523803711,
      "learning_rate": 1.607784924954643e-05,
      "loss": 0.0638,
      "step": 1190
    },
    {
      "epoch": 0.5937654626422563,
      "grad_norm": 0.0851200670003891,
      "learning_rate": 1.6044862279399637e-05,
      "loss": 0.0312,
      "step": 1200
    },
    {
      "epoch": 0.5987135081642752,
      "grad_norm": 0.03217971324920654,
      "learning_rate": 1.6011875309252847e-05,
      "loss": 0.054,
      "step": 1210
    },
    {
      "epoch": 0.6036615536862939,
      "grad_norm": 0.3308243155479431,
      "learning_rate": 1.5978888339106053e-05,
      "loss": 0.0621,
      "step": 1220
    },
    {
      "epoch": 0.6086095992083127,
      "grad_norm": 0.029482772573828697,
      "learning_rate": 1.5945901368959263e-05,
      "loss": 0.0748,
      "step": 1230
    },
    {
      "epoch": 0.6135576447303315,
      "grad_norm": 13.087727546691895,
      "learning_rate": 1.5912914398812473e-05,
      "loss": 0.037,
      "step": 1240
    },
    {
      "epoch": 0.6185056902523504,
      "grad_norm": 12.393936157226562,
      "learning_rate": 1.587992742866568e-05,
      "loss": 0.0282,
      "step": 1250
    },
    {
      "epoch": 0.6234537357743691,
      "grad_norm": 18.055524826049805,
      "learning_rate": 1.5846940458518885e-05,
      "loss": 0.0652,
      "step": 1260
    },
    {
      "epoch": 0.6284017812963879,
      "grad_norm": 0.017833318561315536,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 0.0095,
      "step": 1270
    },
    {
      "epoch": 0.6333498268184067,
      "grad_norm": 11.66836929321289,
      "learning_rate": 1.57809665182253e-05,
      "loss": 0.0926,
      "step": 1280
    },
    {
      "epoch": 0.6382978723404256,
      "grad_norm": 0.19549229741096497,
      "learning_rate": 1.574797954807851e-05,
      "loss": 0.1003,
      "step": 1290
    },
    {
      "epoch": 0.6432459178624443,
      "grad_norm": 12.230384826660156,
      "learning_rate": 1.5714992577931718e-05,
      "loss": 0.05,
      "step": 1300
    },
    {
      "epoch": 0.6481939633844631,
      "grad_norm": 0.3030203878879547,
      "learning_rate": 1.5682005607784927e-05,
      "loss": 0.1441,
      "step": 1310
    },
    {
      "epoch": 0.6531420089064819,
      "grad_norm": 5.655834674835205,
      "learning_rate": 1.5649018637638134e-05,
      "loss": 0.0589,
      "step": 1320
    },
    {
      "epoch": 0.6580900544285008,
      "grad_norm": 0.7592865228652954,
      "learning_rate": 1.5616031667491343e-05,
      "loss": 0.0368,
      "step": 1330
    },
    {
      "epoch": 0.6630380999505195,
      "grad_norm": 0.022791415452957153,
      "learning_rate": 1.558304469734455e-05,
      "loss": 0.0691,
      "step": 1340
    },
    {
      "epoch": 0.6679861454725383,
      "grad_norm": 11.059638977050781,
      "learning_rate": 1.555005772719776e-05,
      "loss": 0.1827,
      "step": 1350
    },
    {
      "epoch": 0.6729341909945572,
      "grad_norm": 1.8564258813858032,
      "learning_rate": 1.5517070757050966e-05,
      "loss": 0.0029,
      "step": 1360
    },
    {
      "epoch": 0.677882236516576,
      "grad_norm": 0.01406863983720541,
      "learning_rate": 1.5484083786904175e-05,
      "loss": 0.0983,
      "step": 1370
    },
    {
      "epoch": 0.6828302820385947,
      "grad_norm": 0.07184905558824539,
      "learning_rate": 1.5451096816757382e-05,
      "loss": 0.0749,
      "step": 1380
    },
    {
      "epoch": 0.6877783275606135,
      "grad_norm": 0.01641121320426464,
      "learning_rate": 1.5418109846610588e-05,
      "loss": 0.0908,
      "step": 1390
    },
    {
      "epoch": 0.6927263730826324,
      "grad_norm": 0.030755706131458282,
      "learning_rate": 1.5385122876463798e-05,
      "loss": 0.0452,
      "step": 1400
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 0.01732504926621914,
      "learning_rate": 1.5352135906317004e-05,
      "loss": 0.0064,
      "step": 1410
    },
    {
      "epoch": 0.70262246412667,
      "grad_norm": 11.422159194946289,
      "learning_rate": 1.5319148936170214e-05,
      "loss": 0.1222,
      "step": 1420
    },
    {
      "epoch": 0.7075705096486887,
      "grad_norm": 0.12126472592353821,
      "learning_rate": 1.5286161966023424e-05,
      "loss": 0.0768,
      "step": 1430
    },
    {
      "epoch": 0.7125185551707076,
      "grad_norm": 0.05225427821278572,
      "learning_rate": 1.525317499587663e-05,
      "loss": 0.0012,
      "step": 1440
    },
    {
      "epoch": 0.7174666006927264,
      "grad_norm": 1.3010988235473633,
      "learning_rate": 1.5220188025729838e-05,
      "loss": 0.0103,
      "step": 1450
    },
    {
      "epoch": 0.7224146462147452,
      "grad_norm": 4.435579776763916,
      "learning_rate": 1.5187201055583046e-05,
      "loss": 0.0444,
      "step": 1460
    },
    {
      "epoch": 0.7273626917367639,
      "grad_norm": 0.9179107546806335,
      "learning_rate": 1.5154214085436254e-05,
      "loss": 0.0735,
      "step": 1470
    },
    {
      "epoch": 0.7323107372587828,
      "grad_norm": 0.042730893939733505,
      "learning_rate": 1.5121227115289464e-05,
      "loss": 0.1438,
      "step": 1480
    },
    {
      "epoch": 0.7372587827808016,
      "grad_norm": 0.036264143884181976,
      "learning_rate": 1.508824014514267e-05,
      "loss": 0.1257,
      "step": 1490
    },
    {
      "epoch": 0.7422068283028204,
      "grad_norm": 9.243889808654785,
      "learning_rate": 1.5055253174995878e-05,
      "loss": 0.0545,
      "step": 1500
    },
    {
      "epoch": 0.7471548738248391,
      "grad_norm": 0.03666732832789421,
      "learning_rate": 1.5022266204849086e-05,
      "loss": 0.0235,
      "step": 1510
    },
    {
      "epoch": 0.752102919346858,
      "grad_norm": 0.21956242620944977,
      "learning_rate": 1.4989279234702294e-05,
      "loss": 0.1495,
      "step": 1520
    },
    {
      "epoch": 0.7570509648688768,
      "grad_norm": 0.06111755967140198,
      "learning_rate": 1.49562922645555e-05,
      "loss": 0.0656,
      "step": 1530
    },
    {
      "epoch": 0.7619990103908956,
      "grad_norm": 0.05373174324631691,
      "learning_rate": 1.492330529440871e-05,
      "loss": 0.0382,
      "step": 1540
    },
    {
      "epoch": 0.7669470559129143,
      "grad_norm": 13.474030494689941,
      "learning_rate": 1.4890318324261918e-05,
      "loss": 0.0404,
      "step": 1550
    },
    {
      "epoch": 0.7718951014349332,
      "grad_norm": 0.13550087809562683,
      "learning_rate": 1.4857331354115126e-05,
      "loss": 0.041,
      "step": 1560
    },
    {
      "epoch": 0.776843146956952,
      "grad_norm": 4.350411415100098,
      "learning_rate": 1.4824344383968334e-05,
      "loss": 0.1222,
      "step": 1570
    },
    {
      "epoch": 0.7817911924789708,
      "grad_norm": 4.205056190490723,
      "learning_rate": 1.479135741382154e-05,
      "loss": 0.0731,
      "step": 1580
    },
    {
      "epoch": 0.7867392380009897,
      "grad_norm": 0.03845684602856636,
      "learning_rate": 1.475837044367475e-05,
      "loss": 0.0635,
      "step": 1590
    },
    {
      "epoch": 0.7916872835230084,
      "grad_norm": 0.23823289573192596,
      "learning_rate": 1.4725383473527957e-05,
      "loss": 0.071,
      "step": 1600
    },
    {
      "epoch": 0.7966353290450272,
      "grad_norm": 3.574568271636963,
      "learning_rate": 1.4692396503381166e-05,
      "loss": 0.0745,
      "step": 1610
    },
    {
      "epoch": 0.801583374567046,
      "grad_norm": 1.308376669883728,
      "learning_rate": 1.4659409533234374e-05,
      "loss": 0.0219,
      "step": 1620
    },
    {
      "epoch": 0.8065314200890649,
      "grad_norm": 0.09026946127414703,
      "learning_rate": 1.462642256308758e-05,
      "loss": 0.0737,
      "step": 1630
    },
    {
      "epoch": 0.8114794656110836,
      "grad_norm": 0.015685511752963066,
      "learning_rate": 1.459343559294079e-05,
      "loss": 0.0341,
      "step": 1640
    },
    {
      "epoch": 0.8164275111331024,
      "grad_norm": 0.058074548840522766,
      "learning_rate": 1.4560448622793997e-05,
      "loss": 0.0289,
      "step": 1650
    },
    {
      "epoch": 0.8213755566551212,
      "grad_norm": 19.68631935119629,
      "learning_rate": 1.4527461652647206e-05,
      "loss": 0.1245,
      "step": 1660
    },
    {
      "epoch": 0.8263236021771401,
      "grad_norm": 0.24659325182437897,
      "learning_rate": 1.4494474682500415e-05,
      "loss": 0.001,
      "step": 1670
    },
    {
      "epoch": 0.8312716476991588,
      "grad_norm": 21.865524291992188,
      "learning_rate": 1.4461487712353621e-05,
      "loss": 0.0423,
      "step": 1680
    },
    {
      "epoch": 0.8362196932211776,
      "grad_norm": 0.02970598265528679,
      "learning_rate": 1.442850074220683e-05,
      "loss": 0.0846,
      "step": 1690
    },
    {
      "epoch": 0.8411677387431964,
      "grad_norm": 0.17488545179367065,
      "learning_rate": 1.4395513772060037e-05,
      "loss": 0.0232,
      "step": 1700
    },
    {
      "epoch": 0.8461157842652153,
      "grad_norm": 0.3715421259403229,
      "learning_rate": 1.4362526801913247e-05,
      "loss": 0.0059,
      "step": 1710
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 15.703872680664062,
      "learning_rate": 1.4329539831766453e-05,
      "loss": 0.1831,
      "step": 1720
    },
    {
      "epoch": 0.8560118753092528,
      "grad_norm": 2.5397257804870605,
      "learning_rate": 1.4296552861619661e-05,
      "loss": 0.0442,
      "step": 1730
    },
    {
      "epoch": 0.8609599208312716,
      "grad_norm": 0.021135611459612846,
      "learning_rate": 1.426356589147287e-05,
      "loss": 0.1019,
      "step": 1740
    },
    {
      "epoch": 0.8659079663532905,
      "grad_norm": 0.11210115998983383,
      "learning_rate": 1.4230578921326077e-05,
      "loss": 0.0259,
      "step": 1750
    },
    {
      "epoch": 0.8708560118753093,
      "grad_norm": 0.037724819034338,
      "learning_rate": 1.4197591951179287e-05,
      "loss": 0.032,
      "step": 1760
    },
    {
      "epoch": 0.875804057397328,
      "grad_norm": 0.03906749188899994,
      "learning_rate": 1.4164604981032493e-05,
      "loss": 0.0666,
      "step": 1770
    },
    {
      "epoch": 0.8807521029193469,
      "grad_norm": 0.02217189408838749,
      "learning_rate": 1.4131618010885701e-05,
      "loss": 0.0378,
      "step": 1780
    },
    {
      "epoch": 0.8857001484413657,
      "grad_norm": 0.03314010053873062,
      "learning_rate": 1.4098631040738907e-05,
      "loss": 0.0257,
      "step": 1790
    },
    {
      "epoch": 0.8906481939633845,
      "grad_norm": 0.6820710897445679,
      "learning_rate": 1.4065644070592117e-05,
      "loss": 0.0897,
      "step": 1800
    },
    {
      "epoch": 0.8955962394854032,
      "grad_norm": 0.03534954413771629,
      "learning_rate": 1.4032657100445327e-05,
      "loss": 0.0241,
      "step": 1810
    },
    {
      "epoch": 0.9005442850074221,
      "grad_norm": 0.012813583016395569,
      "learning_rate": 1.3999670130298533e-05,
      "loss": 0.0535,
      "step": 1820
    },
    {
      "epoch": 0.9054923305294409,
      "grad_norm": 0.012768572196364403,
      "learning_rate": 1.3966683160151741e-05,
      "loss": 0.0649,
      "step": 1830
    },
    {
      "epoch": 0.9104403760514597,
      "grad_norm": 0.20296619832515717,
      "learning_rate": 1.3933696190004948e-05,
      "loss": 0.116,
      "step": 1840
    },
    {
      "epoch": 0.9153884215734784,
      "grad_norm": 0.01773061603307724,
      "learning_rate": 1.3900709219858157e-05,
      "loss": 0.0977,
      "step": 1850
    },
    {
      "epoch": 0.9203364670954973,
      "grad_norm": 4.96028470993042,
      "learning_rate": 1.3867722249711365e-05,
      "loss": 0.0744,
      "step": 1860
    },
    {
      "epoch": 0.9252845126175161,
      "grad_norm": 0.5198617577552795,
      "learning_rate": 1.3834735279564573e-05,
      "loss": 0.0994,
      "step": 1870
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 3.4126696586608887,
      "learning_rate": 1.3801748309417781e-05,
      "loss": 0.0046,
      "step": 1880
    },
    {
      "epoch": 0.9351806036615536,
      "grad_norm": 1.086695671081543,
      "learning_rate": 1.3768761339270988e-05,
      "loss": 0.0382,
      "step": 1890
    },
    {
      "epoch": 0.9401286491835725,
      "grad_norm": 11.169939041137695,
      "learning_rate": 1.3735774369124197e-05,
      "loss": 0.1054,
      "step": 1900
    },
    {
      "epoch": 0.9450766947055913,
      "grad_norm": 0.013259941712021828,
      "learning_rate": 1.3702787398977404e-05,
      "loss": 0.0057,
      "step": 1910
    },
    {
      "epoch": 0.9500247402276101,
      "grad_norm": 0.04192689061164856,
      "learning_rate": 1.3669800428830613e-05,
      "loss": 0.0177,
      "step": 1920
    },
    {
      "epoch": 0.9549727857496288,
      "grad_norm": 0.018220826983451843,
      "learning_rate": 1.3636813458683821e-05,
      "loss": 0.1118,
      "step": 1930
    },
    {
      "epoch": 0.9599208312716477,
      "grad_norm": 0.02413727343082428,
      "learning_rate": 1.3603826488537028e-05,
      "loss": 0.053,
      "step": 1940
    },
    {
      "epoch": 0.9648688767936665,
      "grad_norm": 0.029926756396889687,
      "learning_rate": 1.3570839518390238e-05,
      "loss": 0.1103,
      "step": 1950
    },
    {
      "epoch": 0.9698169223156853,
      "grad_norm": 0.10076188296079636,
      "learning_rate": 1.3537852548243444e-05,
      "loss": 0.0748,
      "step": 1960
    },
    {
      "epoch": 0.974764967837704,
      "grad_norm": 19.11438751220703,
      "learning_rate": 1.3504865578096654e-05,
      "loss": 0.0545,
      "step": 1970
    },
    {
      "epoch": 0.9797130133597229,
      "grad_norm": 6.635544776916504,
      "learning_rate": 1.347187860794986e-05,
      "loss": 0.1036,
      "step": 1980
    },
    {
      "epoch": 0.9846610588817417,
      "grad_norm": 0.031633876264095306,
      "learning_rate": 1.3438891637803068e-05,
      "loss": 0.023,
      "step": 1990
    },
    {
      "epoch": 0.9896091044037605,
      "grad_norm": 9.046653747558594,
      "learning_rate": 1.3405904667656278e-05,
      "loss": 0.0403,
      "step": 2000
    },
    {
      "epoch": 0.9945571499257794,
      "grad_norm": 0.02894374169409275,
      "learning_rate": 1.3372917697509484e-05,
      "loss": 0.0648,
      "step": 2010
    },
    {
      "epoch": 0.9995051954477981,
      "grad_norm": 0.010722910054028034,
      "learning_rate": 1.3339930727362694e-05,
      "loss": 0.018,
      "step": 2020
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9796770601336303,
      "eval_f1": 0.9788956345764672,
      "eval_loss": 0.08078765869140625,
      "eval_precision": 0.9696449026345934,
      "eval_recall": 0.9883245767659078,
      "eval_runtime": 177.9548,
      "eval_samples_per_second": 20.185,
      "eval_steps_per_second": 1.264,
      "step": 2021
    },
    {
      "epoch": 0.004948045522018802,
      "grad_norm": 2.083307981491089,
      "learning_rate": 1.9970311726867887e-05,
      "loss": 0.6662,
      "step": 10
    },
    {
      "epoch": 0.009896091044037604,
      "grad_norm": 2.7390191555023193,
      "learning_rate": 1.9937324756721097e-05,
      "loss": 0.5219,
      "step": 20
    },
    {
      "epoch": 0.014844136566056407,
      "grad_norm": 6.878846645355225,
      "learning_rate": 1.9904337786574303e-05,
      "loss": 0.37,
      "step": 30
    },
    {
      "epoch": 0.01979218208807521,
      "grad_norm": 4.318190097808838,
      "learning_rate": 1.9871350816427513e-05,
      "loss": 0.2521,
      "step": 40
    },
    {
      "epoch": 0.024740227610094014,
      "grad_norm": 9.216415405273438,
      "learning_rate": 1.9838363846280723e-05,
      "loss": 0.2093,
      "step": 50
    },
    {
      "epoch": 0.029688273132112815,
      "grad_norm": 8.236034393310547,
      "learning_rate": 1.980537687613393e-05,
      "loss": 0.1832,
      "step": 60
    },
    {
      "epoch": 0.034636318654131616,
      "grad_norm": 4.756049633026123,
      "learning_rate": 1.9772389905987135e-05,
      "loss": 0.1945,
      "step": 70
    },
    {
      "epoch": 0.03958436417615042,
      "grad_norm": 5.219125747680664,
      "learning_rate": 1.9739402935840345e-05,
      "loss": 0.24,
      "step": 80
    },
    {
      "epoch": 0.044532409698169226,
      "grad_norm": 3.162048578262329,
      "learning_rate": 1.970641596569355e-05,
      "loss": 0.1362,
      "step": 90
    },
    {
      "epoch": 0.04948045522018803,
      "grad_norm": 4.394230365753174,
      "learning_rate": 1.967342899554676e-05,
      "loss": 0.1812,
      "step": 100
    },
    {
      "epoch": 0.05442850074220683,
      "grad_norm": 0.19086267054080963,
      "learning_rate": 1.9640442025399968e-05,
      "loss": 0.0725,
      "step": 110
    },
    {
      "epoch": 0.05937654626422563,
      "grad_norm": 0.19721370935440063,
      "learning_rate": 1.9607455055253177e-05,
      "loss": 0.1096,
      "step": 120
    },
    {
      "epoch": 0.06432459178624443,
      "grad_norm": 13.479732513427734,
      "learning_rate": 1.9574468085106384e-05,
      "loss": 0.1201,
      "step": 130
    },
    {
      "epoch": 0.06927263730826323,
      "grad_norm": 0.12804940342903137,
      "learning_rate": 1.9541481114959593e-05,
      "loss": 0.0866,
      "step": 140
    },
    {
      "epoch": 0.07422068283028203,
      "grad_norm": 0.24177192151546478,
      "learning_rate": 1.95084941448128e-05,
      "loss": 0.0846,
      "step": 150
    },
    {
      "epoch": 0.07916872835230084,
      "grad_norm": 2.2864034175872803,
      "learning_rate": 1.947550717466601e-05,
      "loss": 0.1581,
      "step": 160
    },
    {
      "epoch": 0.08411677387431965,
      "grad_norm": 4.249545574188232,
      "learning_rate": 1.9442520204519216e-05,
      "loss": 0.2232,
      "step": 170
    },
    {
      "epoch": 0.08906481939633845,
      "grad_norm": 0.34422767162323,
      "learning_rate": 1.9409533234372425e-05,
      "loss": 0.1256,
      "step": 180
    },
    {
      "epoch": 0.09401286491835725,
      "grad_norm": 0.42557862401008606,
      "learning_rate": 1.9376546264225632e-05,
      "loss": 0.1423,
      "step": 190
    },
    {
      "epoch": 0.09896091044037605,
      "grad_norm": 19.31597328186035,
      "learning_rate": 1.9343559294078838e-05,
      "loss": 0.111,
      "step": 200
    },
    {
      "epoch": 0.10390895596239486,
      "grad_norm": 0.08680129796266556,
      "learning_rate": 1.9310572323932048e-05,
      "loss": 0.0668,
      "step": 210
    },
    {
      "epoch": 0.10885700148441366,
      "grad_norm": 0.1590888947248459,
      "learning_rate": 1.9277585353785254e-05,
      "loss": 0.1487,
      "step": 220
    },
    {
      "epoch": 0.11380504700643246,
      "grad_norm": 1.1533154249191284,
      "learning_rate": 1.9244598383638464e-05,
      "loss": 0.0903,
      "step": 230
    },
    {
      "epoch": 0.11875309252845126,
      "grad_norm": 0.5391048789024353,
      "learning_rate": 1.9211611413491674e-05,
      "loss": 0.1996,
      "step": 240
    },
    {
      "epoch": 0.12370113805047006,
      "grad_norm": 3.9532554149627686,
      "learning_rate": 1.917862444334488e-05,
      "loss": 0.0967,
      "step": 250
    },
    {
      "epoch": 0.12864918357248886,
      "grad_norm": 10.393773078918457,
      "learning_rate": 1.914563747319809e-05,
      "loss": 0.1028,
      "step": 260
    },
    {
      "epoch": 0.13359722909450766,
      "grad_norm": 5.41870641708374,
      "learning_rate": 1.9112650503051296e-05,
      "loss": 0.1046,
      "step": 270
    },
    {
      "epoch": 0.13854527461652646,
      "grad_norm": 4.591911315917969,
      "learning_rate": 1.9079663532904506e-05,
      "loss": 0.1047,
      "step": 280
    },
    {
      "epoch": 0.14349332013854527,
      "grad_norm": 0.9195568561553955,
      "learning_rate": 1.9046676562757712e-05,
      "loss": 0.0627,
      "step": 290
    },
    {
      "epoch": 0.14844136566056407,
      "grad_norm": 10.907586097717285,
      "learning_rate": 1.901368959261092e-05,
      "loss": 0.2917,
      "step": 300
    },
    {
      "epoch": 0.15338941118258287,
      "grad_norm": 9.88653564453125,
      "learning_rate": 1.8980702622464128e-05,
      "loss": 0.1186,
      "step": 310
    },
    {
      "epoch": 0.15833745670460167,
      "grad_norm": 0.14319217205047607,
      "learning_rate": 1.8947715652317334e-05,
      "loss": 0.1927,
      "step": 320
    },
    {
      "epoch": 0.16328550222662047,
      "grad_norm": 1.7564142942428589,
      "learning_rate": 1.8914728682170544e-05,
      "loss": 0.079,
      "step": 330
    },
    {
      "epoch": 0.1682335477486393,
      "grad_norm": 0.11367207020521164,
      "learning_rate": 1.888174171202375e-05,
      "loss": 0.0614,
      "step": 340
    },
    {
      "epoch": 0.1731815932706581,
      "grad_norm": 3.21763277053833,
      "learning_rate": 1.884875474187696e-05,
      "loss": 0.2662,
      "step": 350
    },
    {
      "epoch": 0.1781296387926769,
      "grad_norm": 4.511270046234131,
      "learning_rate": 1.881576777173017e-05,
      "loss": 0.0934,
      "step": 360
    },
    {
      "epoch": 0.1830776843146957,
      "grad_norm": 0.21536241471767426,
      "learning_rate": 1.8782780801583376e-05,
      "loss": 0.1201,
      "step": 370
    },
    {
      "epoch": 0.1880257298367145,
      "grad_norm": 7.710086822509766,
      "learning_rate": 1.8749793831436586e-05,
      "loss": 0.0766,
      "step": 380
    },
    {
      "epoch": 0.1929737753587333,
      "grad_norm": 0.07848420739173889,
      "learning_rate": 1.8716806861289792e-05,
      "loss": 0.0344,
      "step": 390
    },
    {
      "epoch": 0.1979218208807521,
      "grad_norm": 2.123512029647827,
      "learning_rate": 1.8683819891143e-05,
      "loss": 0.0804,
      "step": 400
    },
    {
      "epoch": 0.2028698664027709,
      "grad_norm": 19.27537727355957,
      "learning_rate": 1.865083292099621e-05,
      "loss": 0.1201,
      "step": 410
    },
    {
      "epoch": 0.2078179119247897,
      "grad_norm": 0.7075232863426208,
      "learning_rate": 1.8617845950849415e-05,
      "loss": 0.0747,
      "step": 420
    },
    {
      "epoch": 0.2127659574468085,
      "grad_norm": 1.48856782913208,
      "learning_rate": 1.8584858980702624e-05,
      "loss": 0.0479,
      "step": 430
    },
    {
      "epoch": 0.2177140029688273,
      "grad_norm": 0.04681114852428436,
      "learning_rate": 1.855187201055583e-05,
      "loss": 0.0651,
      "step": 440
    },
    {
      "epoch": 0.22266204849084612,
      "grad_norm": 0.5338934063911438,
      "learning_rate": 1.851888504040904e-05,
      "loss": 0.028,
      "step": 450
    },
    {
      "epoch": 0.22761009401286492,
      "grad_norm": 1.1672910451889038,
      "learning_rate": 1.8485898070262247e-05,
      "loss": 0.0618,
      "step": 460
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 0.03572314605116844,
      "learning_rate": 1.8452911100115457e-05,
      "loss": 0.1013,
      "step": 470
    },
    {
      "epoch": 0.23750618505690252,
      "grad_norm": 0.13009002804756165,
      "learning_rate": 1.8419924129968666e-05,
      "loss": 0.0387,
      "step": 480
    },
    {
      "epoch": 0.24245423057892132,
      "grad_norm": 0.052606333047151566,
      "learning_rate": 1.8386937159821873e-05,
      "loss": 0.0493,
      "step": 490
    },
    {
      "epoch": 0.24740227610094012,
      "grad_norm": 3.4013123512268066,
      "learning_rate": 1.835395018967508e-05,
      "loss": 0.0868,
      "step": 500
    },
    {
      "epoch": 0.25235032162295895,
      "grad_norm": 0.3067084848880768,
      "learning_rate": 1.832096321952829e-05,
      "loss": 0.1195,
      "step": 510
    },
    {
      "epoch": 0.2572983671449777,
      "grad_norm": 1.599831461906433,
      "learning_rate": 1.8287976249381495e-05,
      "loss": 0.154,
      "step": 520
    },
    {
      "epoch": 0.26224641266699655,
      "grad_norm": 2.829253911972046,
      "learning_rate": 1.82549892792347e-05,
      "loss": 0.161,
      "step": 530
    },
    {
      "epoch": 0.2671944581890153,
      "grad_norm": 0.6623570919036865,
      "learning_rate": 1.822200230908791e-05,
      "loss": 0.1297,
      "step": 540
    },
    {
      "epoch": 0.27214250371103416,
      "grad_norm": 12.95406723022461,
      "learning_rate": 1.818901533894112e-05,
      "loss": 0.0789,
      "step": 550
    },
    {
      "epoch": 0.27709054923305293,
      "grad_norm": 0.39347994327545166,
      "learning_rate": 1.8156028368794327e-05,
      "loss": 0.0469,
      "step": 560
    },
    {
      "epoch": 0.28203859475507176,
      "grad_norm": 0.40931206941604614,
      "learning_rate": 1.8123041398647537e-05,
      "loss": 0.0639,
      "step": 570
    },
    {
      "epoch": 0.28698664027709053,
      "grad_norm": 5.183740615844727,
      "learning_rate": 1.8090054428500743e-05,
      "loss": 0.1431,
      "step": 580
    },
    {
      "epoch": 0.29193468579910936,
      "grad_norm": 0.030934404581785202,
      "learning_rate": 1.8057067458353953e-05,
      "loss": 0.0715,
      "step": 590
    },
    {
      "epoch": 0.29688273132112813,
      "grad_norm": 18.160383224487305,
      "learning_rate": 1.802408048820716e-05,
      "loss": 0.0577,
      "step": 600
    },
    {
      "epoch": 0.30183077684314696,
      "grad_norm": 0.06146349757909775,
      "learning_rate": 1.799109351806037e-05,
      "loss": 0.0733,
      "step": 610
    },
    {
      "epoch": 0.30677882236516574,
      "grad_norm": 0.08057578653097153,
      "learning_rate": 1.7958106547913575e-05,
      "loss": 0.1204,
      "step": 620
    },
    {
      "epoch": 0.31172686788718457,
      "grad_norm": 22.585683822631836,
      "learning_rate": 1.792511957776678e-05,
      "loss": 0.1668,
      "step": 630
    },
    {
      "epoch": 0.31667491340920334,
      "grad_norm": 7.928167343139648,
      "learning_rate": 1.789213260761999e-05,
      "loss": 0.0553,
      "step": 640
    },
    {
      "epoch": 0.32162295893122217,
      "grad_norm": 0.14058524370193481,
      "learning_rate": 1.7859145637473198e-05,
      "loss": 0.1154,
      "step": 650
    },
    {
      "epoch": 0.32657100445324094,
      "grad_norm": 13.486061096191406,
      "learning_rate": 1.7826158667326407e-05,
      "loss": 0.0356,
      "step": 660
    },
    {
      "epoch": 0.33151904997525977,
      "grad_norm": 17.393245697021484,
      "learning_rate": 1.7793171697179617e-05,
      "loss": 0.0242,
      "step": 670
    },
    {
      "epoch": 0.3364670954972786,
      "grad_norm": 18.788312911987305,
      "learning_rate": 1.7760184727032823e-05,
      "loss": 0.0851,
      "step": 680
    },
    {
      "epoch": 0.3414151410192974,
      "grad_norm": 12.172231674194336,
      "learning_rate": 1.7727197756886033e-05,
      "loss": 0.0884,
      "step": 690
    },
    {
      "epoch": 0.3463631865413162,
      "grad_norm": 0.04007274657487869,
      "learning_rate": 1.769421078673924e-05,
      "loss": 0.1315,
      "step": 700
    },
    {
      "epoch": 0.351311232063335,
      "grad_norm": 8.392043113708496,
      "learning_rate": 1.766122381659245e-05,
      "loss": 0.1236,
      "step": 710
    },
    {
      "epoch": 0.3562592775853538,
      "grad_norm": 0.5907721519470215,
      "learning_rate": 1.7628236846445655e-05,
      "loss": 0.1519,
      "step": 720
    },
    {
      "epoch": 0.3612073231073726,
      "grad_norm": 0.5257152318954468,
      "learning_rate": 1.7595249876298862e-05,
      "loss": 0.037,
      "step": 730
    },
    {
      "epoch": 0.3661553686293914,
      "grad_norm": 10.932088851928711,
      "learning_rate": 1.756226290615207e-05,
      "loss": 0.0988,
      "step": 740
    },
    {
      "epoch": 0.3711034141514102,
      "grad_norm": 18.741071701049805,
      "learning_rate": 1.7529275936005278e-05,
      "loss": 0.0791,
      "step": 750
    },
    {
      "epoch": 0.376051459673429,
      "grad_norm": 0.09219519793987274,
      "learning_rate": 1.7496288965858488e-05,
      "loss": 0.0436,
      "step": 760
    },
    {
      "epoch": 0.3809995051954478,
      "grad_norm": 5.648781776428223,
      "learning_rate": 1.7463301995711694e-05,
      "loss": 0.0706,
      "step": 770
    },
    {
      "epoch": 0.3859475507174666,
      "grad_norm": 14.037808418273926,
      "learning_rate": 1.7430315025564904e-05,
      "loss": 0.2534,
      "step": 780
    },
    {
      "epoch": 0.3908955962394854,
      "grad_norm": 0.11006524413824081,
      "learning_rate": 1.7397328055418113e-05,
      "loss": 0.1036,
      "step": 790
    },
    {
      "epoch": 0.3958436417615042,
      "grad_norm": 0.060364361852407455,
      "learning_rate": 1.736434108527132e-05,
      "loss": 0.055,
      "step": 800
    },
    {
      "epoch": 0.400791687283523,
      "grad_norm": 0.09602401405572891,
      "learning_rate": 1.733135411512453e-05,
      "loss": 0.0886,
      "step": 810
    },
    {
      "epoch": 0.4057397328055418,
      "grad_norm": 11.859095573425293,
      "learning_rate": 1.7298367144977736e-05,
      "loss": 0.0266,
      "step": 820
    },
    {
      "epoch": 0.4106877783275606,
      "grad_norm": 0.07104148715734482,
      "learning_rate": 1.7265380174830942e-05,
      "loss": 0.0497,
      "step": 830
    },
    {
      "epoch": 0.4156358238495794,
      "grad_norm": 0.031956661492586136,
      "learning_rate": 1.7232393204684152e-05,
      "loss": 0.0637,
      "step": 840
    },
    {
      "epoch": 0.4205838693715982,
      "grad_norm": 7.584319591522217,
      "learning_rate": 1.7199406234537358e-05,
      "loss": 0.1158,
      "step": 850
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 0.09121901541948318,
      "learning_rate": 1.7166419264390568e-05,
      "loss": 0.1393,
      "step": 860
    },
    {
      "epoch": 0.4304799604156358,
      "grad_norm": 7.501597881317139,
      "learning_rate": 1.7133432294243774e-05,
      "loss": 0.0619,
      "step": 870
    },
    {
      "epoch": 0.4354280059376546,
      "grad_norm": 0.5705838799476624,
      "learning_rate": 1.7100445324096984e-05,
      "loss": 0.0351,
      "step": 880
    },
    {
      "epoch": 0.44037605145967346,
      "grad_norm": 9.694978713989258,
      "learning_rate": 1.706745835395019e-05,
      "loss": 0.1203,
      "step": 890
    },
    {
      "epoch": 0.44532409698169223,
      "grad_norm": 8.816353797912598,
      "learning_rate": 1.70344713838034e-05,
      "loss": 0.1703,
      "step": 900
    },
    {
      "epoch": 0.45027214250371106,
      "grad_norm": 0.23506025969982147,
      "learning_rate": 1.7001484413656606e-05,
      "loss": 0.1034,
      "step": 910
    },
    {
      "epoch": 0.45522018802572983,
      "grad_norm": 0.061143603175878525,
      "learning_rate": 1.6968497443509816e-05,
      "loss": 0.0464,
      "step": 920
    },
    {
      "epoch": 0.46016823354774866,
      "grad_norm": 0.9215734004974365,
      "learning_rate": 1.6935510473363022e-05,
      "loss": 0.0753,
      "step": 930
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 0.040241893380880356,
      "learning_rate": 1.6902523503216232e-05,
      "loss": 0.0564,
      "step": 940
    },
    {
      "epoch": 0.47006432459178626,
      "grad_norm": 0.26941952109336853,
      "learning_rate": 1.686953653306944e-05,
      "loss": 0.0472,
      "step": 950
    },
    {
      "epoch": 0.47501237011380504,
      "grad_norm": 9.566105842590332,
      "learning_rate": 1.6836549562922645e-05,
      "loss": 0.0075,
      "step": 960
    },
    {
      "epoch": 0.47996041563582387,
      "grad_norm": 13.46181583404541,
      "learning_rate": 1.6803562592775854e-05,
      "loss": 0.1029,
      "step": 970
    },
    {
      "epoch": 0.48490846115784264,
      "grad_norm": 20.636093139648438,
      "learning_rate": 1.6770575622629064e-05,
      "loss": 0.0872,
      "step": 980
    },
    {
      "epoch": 0.48985650667986147,
      "grad_norm": 0.32675328850746155,
      "learning_rate": 1.673758865248227e-05,
      "loss": 0.0853,
      "step": 990
    },
    {
      "epoch": 0.49480455220188024,
      "grad_norm": 0.012083613313734531,
      "learning_rate": 1.670460168233548e-05,
      "loss": 0.0021,
      "step": 1000
    },
    {
      "epoch": 0.4997525977238991,
      "grad_norm": 0.043934937566518784,
      "learning_rate": 1.6671614712188687e-05,
      "loss": 0.0862,
      "step": 1010
    },
    {
      "epoch": 0.5047006432459179,
      "grad_norm": 0.09779392927885056,
      "learning_rate": 1.6638627742041896e-05,
      "loss": 0.0915,
      "step": 1020
    },
    {
      "epoch": 0.5096486887679367,
      "grad_norm": 8.221818923950195,
      "learning_rate": 1.6605640771895103e-05,
      "loss": 0.0753,
      "step": 1030
    },
    {
      "epoch": 0.5145967342899554,
      "grad_norm": 0.03063368983566761,
      "learning_rate": 1.6572653801748312e-05,
      "loss": 0.0304,
      "step": 1040
    },
    {
      "epoch": 0.5195447798119742,
      "grad_norm": 2.528777837753296,
      "learning_rate": 1.653966683160152e-05,
      "loss": 0.1146,
      "step": 1050
    },
    {
      "epoch": 0.5244928253339931,
      "grad_norm": 0.02647237479686737,
      "learning_rate": 1.6506679861454725e-05,
      "loss": 0.0445,
      "step": 1060
    },
    {
      "epoch": 0.5294408708560119,
      "grad_norm": 1.3835035562515259,
      "learning_rate": 1.6473692891307935e-05,
      "loss": 0.0487,
      "step": 1070
    },
    {
      "epoch": 0.5343889163780307,
      "grad_norm": 0.15118873119354248,
      "learning_rate": 1.644070592116114e-05,
      "loss": 0.0663,
      "step": 1080
    },
    {
      "epoch": 0.5393369619000494,
      "grad_norm": 23.11678123474121,
      "learning_rate": 1.640771895101435e-05,
      "loss": 0.1359,
      "step": 1090
    },
    {
      "epoch": 0.5442850074220683,
      "grad_norm": 1.441372036933899,
      "learning_rate": 1.6374731980867557e-05,
      "loss": 0.0342,
      "step": 1100
    },
    {
      "epoch": 0.5492330529440871,
      "grad_norm": 0.08466717600822449,
      "learning_rate": 1.6341745010720767e-05,
      "loss": 0.0485,
      "step": 1110
    },
    {
      "epoch": 0.5541810984661059,
      "grad_norm": 0.029211582615971565,
      "learning_rate": 1.6308758040573976e-05,
      "loss": 0.0445,
      "step": 1120
    },
    {
      "epoch": 0.5591291439881247,
      "grad_norm": 0.028145791962742805,
      "learning_rate": 1.6275771070427183e-05,
      "loss": 0.0555,
      "step": 1130
    },
    {
      "epoch": 0.5640771895101435,
      "grad_norm": 0.02021896094083786,
      "learning_rate": 1.6242784100280393e-05,
      "loss": 0.0575,
      "step": 1140
    },
    {
      "epoch": 0.5690252350321623,
      "grad_norm": 0.07333213090896606,
      "learning_rate": 1.62097971301336e-05,
      "loss": 0.0503,
      "step": 1150
    },
    {
      "epoch": 0.5739732805541811,
      "grad_norm": 0.0699671059846878,
      "learning_rate": 1.6176810159986805e-05,
      "loss": 0.0163,
      "step": 1160
    },
    {
      "epoch": 0.5789213260762,
      "grad_norm": 14.429854393005371,
      "learning_rate": 1.6143823189840015e-05,
      "loss": 0.0917,
      "step": 1170
    },
    {
      "epoch": 0.5838693715982187,
      "grad_norm": 0.05973955988883972,
      "learning_rate": 1.611083621969322e-05,
      "loss": 0.0611,
      "step": 1180
    },
    {
      "epoch": 0.5888174171202375,
      "grad_norm": 9.14852523803711,
      "learning_rate": 1.607784924954643e-05,
      "loss": 0.0638,
      "step": 1190
    },
    {
      "epoch": 0.5937654626422563,
      "grad_norm": 0.0851200670003891,
      "learning_rate": 1.6044862279399637e-05,
      "loss": 0.0312,
      "step": 1200
    },
    {
      "epoch": 0.5987135081642752,
      "grad_norm": 0.03217971324920654,
      "learning_rate": 1.6011875309252847e-05,
      "loss": 0.054,
      "step": 1210
    },
    {
      "epoch": 0.6036615536862939,
      "grad_norm": 0.3308243155479431,
      "learning_rate": 1.5978888339106053e-05,
      "loss": 0.0621,
      "step": 1220
    },
    {
      "epoch": 0.6086095992083127,
      "grad_norm": 0.029482772573828697,
      "learning_rate": 1.5945901368959263e-05,
      "loss": 0.0748,
      "step": 1230
    },
    {
      "epoch": 0.6135576447303315,
      "grad_norm": 13.087727546691895,
      "learning_rate": 1.5912914398812473e-05,
      "loss": 0.037,
      "step": 1240
    },
    {
      "epoch": 0.6185056902523504,
      "grad_norm": 12.393936157226562,
      "learning_rate": 1.587992742866568e-05,
      "loss": 0.0282,
      "step": 1250
    },
    {
      "epoch": 0.6234537357743691,
      "grad_norm": 18.055524826049805,
      "learning_rate": 1.5846940458518885e-05,
      "loss": 0.0652,
      "step": 1260
    },
    {
      "epoch": 0.6284017812963879,
      "grad_norm": 0.017833318561315536,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 0.0095,
      "step": 1270
    },
    {
      "epoch": 0.6333498268184067,
      "grad_norm": 11.66836929321289,
      "learning_rate": 1.57809665182253e-05,
      "loss": 0.0926,
      "step": 1280
    },
    {
      "epoch": 0.6382978723404256,
      "grad_norm": 0.19549229741096497,
      "learning_rate": 1.574797954807851e-05,
      "loss": 0.1003,
      "step": 1290
    },
    {
      "epoch": 0.6432459178624443,
      "grad_norm": 12.230384826660156,
      "learning_rate": 1.5714992577931718e-05,
      "loss": 0.05,
      "step": 1300
    },
    {
      "epoch": 0.6481939633844631,
      "grad_norm": 0.3030203878879547,
      "learning_rate": 1.5682005607784927e-05,
      "loss": 0.1441,
      "step": 1310
    },
    {
      "epoch": 0.6531420089064819,
      "grad_norm": 5.655834674835205,
      "learning_rate": 1.5649018637638134e-05,
      "loss": 0.0589,
      "step": 1320
    },
    {
      "epoch": 0.6580900544285008,
      "grad_norm": 0.7592865228652954,
      "learning_rate": 1.5616031667491343e-05,
      "loss": 0.0368,
      "step": 1330
    },
    {
      "epoch": 0.6630380999505195,
      "grad_norm": 0.022791415452957153,
      "learning_rate": 1.558304469734455e-05,
      "loss": 0.0691,
      "step": 1340
    },
    {
      "epoch": 0.6679861454725383,
      "grad_norm": 11.059638977050781,
      "learning_rate": 1.555005772719776e-05,
      "loss": 0.1827,
      "step": 1350
    },
    {
      "epoch": 0.6729341909945572,
      "grad_norm": 1.8564258813858032,
      "learning_rate": 1.5517070757050966e-05,
      "loss": 0.0029,
      "step": 1360
    },
    {
      "epoch": 0.677882236516576,
      "grad_norm": 0.01406863983720541,
      "learning_rate": 1.5484083786904175e-05,
      "loss": 0.0983,
      "step": 1370
    },
    {
      "epoch": 0.6828302820385947,
      "grad_norm": 0.07184905558824539,
      "learning_rate": 1.5451096816757382e-05,
      "loss": 0.0749,
      "step": 1380
    },
    {
      "epoch": 0.6877783275606135,
      "grad_norm": 0.01641121320426464,
      "learning_rate": 1.5418109846610588e-05,
      "loss": 0.0908,
      "step": 1390
    },
    {
      "epoch": 0.6927263730826324,
      "grad_norm": 0.030755706131458282,
      "learning_rate": 1.5385122876463798e-05,
      "loss": 0.0452,
      "step": 1400
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 0.01732504926621914,
      "learning_rate": 1.5352135906317004e-05,
      "loss": 0.0064,
      "step": 1410
    },
    {
      "epoch": 0.70262246412667,
      "grad_norm": 11.422159194946289,
      "learning_rate": 1.5319148936170214e-05,
      "loss": 0.1222,
      "step": 1420
    },
    {
      "epoch": 0.7075705096486887,
      "grad_norm": 0.12126472592353821,
      "learning_rate": 1.5286161966023424e-05,
      "loss": 0.0768,
      "step": 1430
    },
    {
      "epoch": 0.7125185551707076,
      "grad_norm": 0.05225427821278572,
      "learning_rate": 1.525317499587663e-05,
      "loss": 0.0012,
      "step": 1440
    },
    {
      "epoch": 0.7174666006927264,
      "grad_norm": 1.3010988235473633,
      "learning_rate": 1.5220188025729838e-05,
      "loss": 0.0103,
      "step": 1450
    },
    {
      "epoch": 0.7224146462147452,
      "grad_norm": 4.435579776763916,
      "learning_rate": 1.5187201055583046e-05,
      "loss": 0.0444,
      "step": 1460
    },
    {
      "epoch": 0.7273626917367639,
      "grad_norm": 0.9179107546806335,
      "learning_rate": 1.5154214085436254e-05,
      "loss": 0.0735,
      "step": 1470
    },
    {
      "epoch": 0.7323107372587828,
      "grad_norm": 0.042730893939733505,
      "learning_rate": 1.5121227115289464e-05,
      "loss": 0.1438,
      "step": 1480
    },
    {
      "epoch": 0.7372587827808016,
      "grad_norm": 0.036264143884181976,
      "learning_rate": 1.508824014514267e-05,
      "loss": 0.1257,
      "step": 1490
    },
    {
      "epoch": 0.7422068283028204,
      "grad_norm": 9.243889808654785,
      "learning_rate": 1.5055253174995878e-05,
      "loss": 0.0545,
      "step": 1500
    },
    {
      "epoch": 0.7471548738248391,
      "grad_norm": 0.03666732832789421,
      "learning_rate": 1.5022266204849086e-05,
      "loss": 0.0235,
      "step": 1510
    },
    {
      "epoch": 0.752102919346858,
      "grad_norm": 0.21956242620944977,
      "learning_rate": 1.4989279234702294e-05,
      "loss": 0.1495,
      "step": 1520
    },
    {
      "epoch": 0.7570509648688768,
      "grad_norm": 0.06111755967140198,
      "learning_rate": 1.49562922645555e-05,
      "loss": 0.0656,
      "step": 1530
    },
    {
      "epoch": 0.7619990103908956,
      "grad_norm": 0.05373174324631691,
      "learning_rate": 1.492330529440871e-05,
      "loss": 0.0382,
      "step": 1540
    },
    {
      "epoch": 0.7669470559129143,
      "grad_norm": 13.474030494689941,
      "learning_rate": 1.4890318324261918e-05,
      "loss": 0.0404,
      "step": 1550
    },
    {
      "epoch": 0.7718951014349332,
      "grad_norm": 0.13550087809562683,
      "learning_rate": 1.4857331354115126e-05,
      "loss": 0.041,
      "step": 1560
    },
    {
      "epoch": 0.776843146956952,
      "grad_norm": 4.350411415100098,
      "learning_rate": 1.4824344383968334e-05,
      "loss": 0.1222,
      "step": 1570
    },
    {
      "epoch": 0.7817911924789708,
      "grad_norm": 4.205056190490723,
      "learning_rate": 1.479135741382154e-05,
      "loss": 0.0731,
      "step": 1580
    },
    {
      "epoch": 0.7867392380009897,
      "grad_norm": 0.03845684602856636,
      "learning_rate": 1.475837044367475e-05,
      "loss": 0.0635,
      "step": 1590
    },
    {
      "epoch": 0.7916872835230084,
      "grad_norm": 0.23823289573192596,
      "learning_rate": 1.4725383473527957e-05,
      "loss": 0.071,
      "step": 1600
    },
    {
      "epoch": 0.7966353290450272,
      "grad_norm": 3.574568271636963,
      "learning_rate": 1.4692396503381166e-05,
      "loss": 0.0745,
      "step": 1610
    },
    {
      "epoch": 0.801583374567046,
      "grad_norm": 1.308376669883728,
      "learning_rate": 1.4659409533234374e-05,
      "loss": 0.0219,
      "step": 1620
    },
    {
      "epoch": 0.8065314200890649,
      "grad_norm": 0.09026946127414703,
      "learning_rate": 1.462642256308758e-05,
      "loss": 0.0737,
      "step": 1630
    },
    {
      "epoch": 0.8114794656110836,
      "grad_norm": 0.015685511752963066,
      "learning_rate": 1.459343559294079e-05,
      "loss": 0.0341,
      "step": 1640
    },
    {
      "epoch": 0.8164275111331024,
      "grad_norm": 0.058074548840522766,
      "learning_rate": 1.4560448622793997e-05,
      "loss": 0.0289,
      "step": 1650
    },
    {
      "epoch": 0.8213755566551212,
      "grad_norm": 19.68631935119629,
      "learning_rate": 1.4527461652647206e-05,
      "loss": 0.1245,
      "step": 1660
    },
    {
      "epoch": 0.8263236021771401,
      "grad_norm": 0.24659325182437897,
      "learning_rate": 1.4494474682500415e-05,
      "loss": 0.001,
      "step": 1670
    },
    {
      "epoch": 0.8312716476991588,
      "grad_norm": 21.865524291992188,
      "learning_rate": 1.4461487712353621e-05,
      "loss": 0.0423,
      "step": 1680
    },
    {
      "epoch": 0.8362196932211776,
      "grad_norm": 0.02970598265528679,
      "learning_rate": 1.442850074220683e-05,
      "loss": 0.0846,
      "step": 1690
    },
    {
      "epoch": 0.8411677387431964,
      "grad_norm": 0.17488545179367065,
      "learning_rate": 1.4395513772060037e-05,
      "loss": 0.0232,
      "step": 1700
    },
    {
      "epoch": 0.8461157842652153,
      "grad_norm": 0.3715421259403229,
      "learning_rate": 1.4362526801913247e-05,
      "loss": 0.0059,
      "step": 1710
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 15.703872680664062,
      "learning_rate": 1.4329539831766453e-05,
      "loss": 0.1831,
      "step": 1720
    },
    {
      "epoch": 0.8560118753092528,
      "grad_norm": 2.5397257804870605,
      "learning_rate": 1.4296552861619661e-05,
      "loss": 0.0442,
      "step": 1730
    },
    {
      "epoch": 0.8609599208312716,
      "grad_norm": 0.021135611459612846,
      "learning_rate": 1.426356589147287e-05,
      "loss": 0.1019,
      "step": 1740
    },
    {
      "epoch": 0.8659079663532905,
      "grad_norm": 0.11210115998983383,
      "learning_rate": 1.4230578921326077e-05,
      "loss": 0.0259,
      "step": 1750
    },
    {
      "epoch": 0.8708560118753093,
      "grad_norm": 0.037724819034338,
      "learning_rate": 1.4197591951179287e-05,
      "loss": 0.032,
      "step": 1760
    },
    {
      "epoch": 0.875804057397328,
      "grad_norm": 0.03906749188899994,
      "learning_rate": 1.4164604981032493e-05,
      "loss": 0.0666,
      "step": 1770
    },
    {
      "epoch": 0.8807521029193469,
      "grad_norm": 0.02217189408838749,
      "learning_rate": 1.4131618010885701e-05,
      "loss": 0.0378,
      "step": 1780
    },
    {
      "epoch": 0.8857001484413657,
      "grad_norm": 0.03314010053873062,
      "learning_rate": 1.4098631040738907e-05,
      "loss": 0.0257,
      "step": 1790
    },
    {
      "epoch": 0.8906481939633845,
      "grad_norm": 0.6820710897445679,
      "learning_rate": 1.4065644070592117e-05,
      "loss": 0.0897,
      "step": 1800
    },
    {
      "epoch": 0.8955962394854032,
      "grad_norm": 0.03534954413771629,
      "learning_rate": 1.4032657100445327e-05,
      "loss": 0.0241,
      "step": 1810
    },
    {
      "epoch": 0.9005442850074221,
      "grad_norm": 0.012813583016395569,
      "learning_rate": 1.3999670130298533e-05,
      "loss": 0.0535,
      "step": 1820
    },
    {
      "epoch": 0.9054923305294409,
      "grad_norm": 0.012768572196364403,
      "learning_rate": 1.3966683160151741e-05,
      "loss": 0.0649,
      "step": 1830
    },
    {
      "epoch": 0.9104403760514597,
      "grad_norm": 0.20296619832515717,
      "learning_rate": 1.3933696190004948e-05,
      "loss": 0.116,
      "step": 1840
    },
    {
      "epoch": 0.9153884215734784,
      "grad_norm": 0.01773061603307724,
      "learning_rate": 1.3900709219858157e-05,
      "loss": 0.0977,
      "step": 1850
    },
    {
      "epoch": 0.9203364670954973,
      "grad_norm": 4.96028470993042,
      "learning_rate": 1.3867722249711365e-05,
      "loss": 0.0744,
      "step": 1860
    },
    {
      "epoch": 0.9252845126175161,
      "grad_norm": 0.5198617577552795,
      "learning_rate": 1.3834735279564573e-05,
      "loss": 0.0994,
      "step": 1870
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 3.4126696586608887,
      "learning_rate": 1.3801748309417781e-05,
      "loss": 0.0046,
      "step": 1880
    },
    {
      "epoch": 0.9351806036615536,
      "grad_norm": 1.086695671081543,
      "learning_rate": 1.3768761339270988e-05,
      "loss": 0.0382,
      "step": 1890
    },
    {
      "epoch": 0.9401286491835725,
      "grad_norm": 11.169939041137695,
      "learning_rate": 1.3735774369124197e-05,
      "loss": 0.1054,
      "step": 1900
    },
    {
      "epoch": 0.9450766947055913,
      "grad_norm": 0.013259941712021828,
      "learning_rate": 1.3702787398977404e-05,
      "loss": 0.0057,
      "step": 1910
    },
    {
      "epoch": 0.9500247402276101,
      "grad_norm": 0.04192689061164856,
      "learning_rate": 1.3669800428830613e-05,
      "loss": 0.0177,
      "step": 1920
    },
    {
      "epoch": 0.9549727857496288,
      "grad_norm": 0.018220826983451843,
      "learning_rate": 1.3636813458683821e-05,
      "loss": 0.1118,
      "step": 1930
    },
    {
      "epoch": 0.9599208312716477,
      "grad_norm": 0.02413727343082428,
      "learning_rate": 1.3603826488537028e-05,
      "loss": 0.053,
      "step": 1940
    },
    {
      "epoch": 0.9648688767936665,
      "grad_norm": 0.029926756396889687,
      "learning_rate": 1.3570839518390238e-05,
      "loss": 0.1103,
      "step": 1950
    },
    {
      "epoch": 0.9698169223156853,
      "grad_norm": 0.10076188296079636,
      "learning_rate": 1.3537852548243444e-05,
      "loss": 0.0748,
      "step": 1960
    },
    {
      "epoch": 0.974764967837704,
      "grad_norm": 19.11438751220703,
      "learning_rate": 1.3504865578096654e-05,
      "loss": 0.0545,
      "step": 1970
    },
    {
      "epoch": 0.9797130133597229,
      "grad_norm": 6.635544776916504,
      "learning_rate": 1.347187860794986e-05,
      "loss": 0.1036,
      "step": 1980
    },
    {
      "epoch": 0.9846610588817417,
      "grad_norm": 0.031633876264095306,
      "learning_rate": 1.3438891637803068e-05,
      "loss": 0.023,
      "step": 1990
    },
    {
      "epoch": 0.9896091044037605,
      "grad_norm": 9.046653747558594,
      "learning_rate": 1.3405904667656278e-05,
      "loss": 0.0403,
      "step": 2000
    },
    {
      "epoch": 0.9945571499257794,
      "grad_norm": 0.02894374169409275,
      "learning_rate": 1.3372917697509484e-05,
      "loss": 0.0648,
      "step": 2010
    },
    {
      "epoch": 0.9995051954477981,
      "grad_norm": 0.010722910054028034,
      "learning_rate": 1.3339930727362694e-05,
      "loss": 0.018,
      "step": 2020
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9796770601336303,
      "eval_f1": 0.9788956345764672,
      "eval_loss": 0.08078765869140625,
      "eval_precision": 0.9696449026345934,
      "eval_recall": 0.9883245767659078,
      "eval_runtime": 177.9548,
      "eval_samples_per_second": 20.185,
      "eval_steps_per_second": 1.264,
      "step": 2021
    },
    {
      "epoch": 1.004453240969817,
      "grad_norm": 0.03666814789175987,
      "learning_rate": 1.33069437572159e-05,
      "loss": 0.001,
      "step": 2030
    },
    {
      "epoch": 1.0094012864918358,
      "grad_norm": 0.1033797338604927,
      "learning_rate": 1.3273956787069108e-05,
      "loss": 0.0876,
      "step": 2040
    },
    {
      "epoch": 1.0143493320138546,
      "grad_norm": 0.5100687146186829,
      "learning_rate": 1.3240969816922318e-05,
      "loss": 0.0016,
      "step": 2050
    },
    {
      "epoch": 1.0192973775358734,
      "grad_norm": 0.024813350290060043,
      "learning_rate": 1.3207982846775524e-05,
      "loss": 0.0024,
      "step": 2060
    },
    {
      "epoch": 1.0242454230578921,
      "grad_norm": 0.054303087294101715,
      "learning_rate": 1.3174995876628734e-05,
      "loss": 0.0505,
      "step": 2070
    },
    {
      "epoch": 1.029193468579911,
      "grad_norm": 0.02151850424706936,
      "learning_rate": 1.314200890648194e-05,
      "loss": 0.0167,
      "step": 2080
    },
    {
      "epoch": 1.0341415141019297,
      "grad_norm": 0.01498202420771122,
      "learning_rate": 1.3109021936335148e-05,
      "loss": 0.0169,
      "step": 2090
    },
    {
      "epoch": 1.0390895596239484,
      "grad_norm": 0.013668375089764595,
      "learning_rate": 1.3076034966188356e-05,
      "loss": 0.0996,
      "step": 2100
    },
    {
      "epoch": 1.0440376051459674,
      "grad_norm": 7.804310321807861,
      "learning_rate": 1.3043047996041564e-05,
      "loss": 0.088,
      "step": 2110
    },
    {
      "epoch": 1.0489856506679862,
      "grad_norm": 0.03168104216456413,
      "learning_rate": 1.3010061025894774e-05,
      "loss": 0.0485,
      "step": 2120
    },
    {
      "epoch": 1.053933696190005,
      "grad_norm": 0.01966012455523014,
      "learning_rate": 1.297707405574798e-05,
      "loss": 0.0288,
      "step": 2130
    },
    {
      "epoch": 1.0588817417120238,
      "grad_norm": 0.08541480451822281,
      "learning_rate": 1.2944087085601188e-05,
      "loss": 0.0706,
      "step": 2140
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 0.04191906750202179,
      "learning_rate": 1.2911100115454396e-05,
      "loss": 0.031,
      "step": 2150
    },
    {
      "epoch": 1.0687778327560613,
      "grad_norm": 0.012224886566400528,
      "learning_rate": 1.2878113145307604e-05,
      "loss": 0.0211,
      "step": 2160
    },
    {
      "epoch": 1.07372587827808,
      "grad_norm": 0.013992357067763805,
      "learning_rate": 1.2845126175160814e-05,
      "loss": 0.0525,
      "step": 2170
    },
    {
      "epoch": 1.0786739238000989,
      "grad_norm": 22.324195861816406,
      "learning_rate": 1.281213920501402e-05,
      "loss": 0.0583,
      "step": 2180
    },
    {
      "epoch": 1.0836219693221179,
      "grad_norm": 0.058257490396499634,
      "learning_rate": 1.2779152234867228e-05,
      "loss": 0.0078,
      "step": 2190
    },
    {
      "epoch": 1.0885700148441366,
      "grad_norm": 1.3647507429122925,
      "learning_rate": 1.2746165264720436e-05,
      "loss": 0.0296,
      "step": 2200
    },
    {
      "epoch": 1.0935180603661554,
      "grad_norm": 0.013789874501526356,
      "learning_rate": 1.2713178294573645e-05,
      "loss": 0.0248,
      "step": 2210
    },
    {
      "epoch": 1.0984661058881742,
      "grad_norm": 0.02287929318845272,
      "learning_rate": 1.2680191324426851e-05,
      "loss": 0.0277,
      "step": 2220
    },
    {
      "epoch": 1.103414151410193,
      "grad_norm": 0.0214847419410944,
      "learning_rate": 1.264720435428006e-05,
      "loss": 0.0546,
      "step": 2230
    },
    {
      "epoch": 1.1083621969322117,
      "grad_norm": 0.00833534449338913,
      "learning_rate": 1.2614217384133269e-05,
      "loss": 0.0505,
      "step": 2240
    },
    {
      "epoch": 1.1133102424542305,
      "grad_norm": 15.700078964233398,
      "learning_rate": 1.2581230413986477e-05,
      "loss": 0.0887,
      "step": 2250
    },
    {
      "epoch": 1.1182582879762495,
      "grad_norm": 0.05257398262619972,
      "learning_rate": 1.2548243443839685e-05,
      "loss": 0.0356,
      "step": 2260
    },
    {
      "epoch": 1.1232063334982683,
      "grad_norm": 6.80452299118042,
      "learning_rate": 1.2515256473692891e-05,
      "loss": 0.0135,
      "step": 2270
    },
    {
      "epoch": 1.128154379020287,
      "grad_norm": 29.85118293762207,
      "learning_rate": 1.24822695035461e-05,
      "loss": 0.0195,
      "step": 2280
    },
    {
      "epoch": 1.1331024245423058,
      "grad_norm": 0.07157333940267563,
      "learning_rate": 1.2449282533399307e-05,
      "loss": 0.0123,
      "step": 2290
    },
    {
      "epoch": 1.1380504700643246,
      "grad_norm": 0.011316250078380108,
      "learning_rate": 1.2416295563252517e-05,
      "loss": 0.0125,
      "step": 2300
    },
    {
      "epoch": 1.1429985155863434,
      "grad_norm": 0.0074044507928192616,
      "learning_rate": 1.2383308593105725e-05,
      "loss": 0.0391,
      "step": 2310
    },
    {
      "epoch": 1.1479465611083621,
      "grad_norm": 36.9918327331543,
      "learning_rate": 1.2350321622958931e-05,
      "loss": 0.0915,
      "step": 2320
    },
    {
      "epoch": 1.152894606630381,
      "grad_norm": 0.07637502998113632,
      "learning_rate": 1.231733465281214e-05,
      "loss": 0.0102,
      "step": 2330
    },
    {
      "epoch": 1.1578426521524,
      "grad_norm": 9.422124862670898,
      "learning_rate": 1.2284347682665347e-05,
      "loss": 0.0879,
      "step": 2340
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 0.043277278542518616,
      "learning_rate": 1.2251360712518557e-05,
      "loss": 0.0195,
      "step": 2350
    },
    {
      "epoch": 1.1677387431964374,
      "grad_norm": 0.014051000587642193,
      "learning_rate": 1.2218373742371765e-05,
      "loss": 0.0188,
      "step": 2360
    },
    {
      "epoch": 1.1726867887184562,
      "grad_norm": 4.978634834289551,
      "learning_rate": 1.2185386772224971e-05,
      "loss": 0.0029,
      "step": 2370
    },
    {
      "epoch": 1.177634834240475,
      "grad_norm": 0.040173497051000595,
      "learning_rate": 1.2152399802078181e-05,
      "loss": 0.001,
      "step": 2380
    },
    {
      "epoch": 1.1825828797624938,
      "grad_norm": 0.010152610950171947,
      "learning_rate": 1.2119412831931387e-05,
      "loss": 0.0038,
      "step": 2390
    },
    {
      "epoch": 1.1875309252845125,
      "grad_norm": 0.007014419883489609,
      "learning_rate": 1.2086425861784597e-05,
      "loss": 0.038,
      "step": 2400
    },
    {
      "epoch": 1.1924789708065315,
      "grad_norm": 6.724242687225342,
      "learning_rate": 1.2053438891637803e-05,
      "loss": 0.0159,
      "step": 2410
    },
    {
      "epoch": 1.1974270163285503,
      "grad_norm": 0.005857069510966539,
      "learning_rate": 1.2020451921491011e-05,
      "loss": 0.0371,
      "step": 2420
    },
    {
      "epoch": 1.202375061850569,
      "grad_norm": 0.013981127180159092,
      "learning_rate": 1.1987464951344221e-05,
      "loss": 0.0049,
      "step": 2430
    },
    {
      "epoch": 1.2073231073725879,
      "grad_norm": 0.015584176406264305,
      "learning_rate": 1.1954477981197427e-05,
      "loss": 0.0005,
      "step": 2440
    },
    {
      "epoch": 1.2122711528946066,
      "grad_norm": 0.045001570135354996,
      "learning_rate": 1.1921491011050637e-05,
      "loss": 0.0074,
      "step": 2450
    },
    {
      "epoch": 1.2172191984166254,
      "grad_norm": 25.112977981567383,
      "learning_rate": 1.1888504040903843e-05,
      "loss": 0.0113,
      "step": 2460
    },
    {
      "epoch": 1.2221672439386442,
      "grad_norm": 0.007736151572316885,
      "learning_rate": 1.1855517070757051e-05,
      "loss": 0.0188,
      "step": 2470
    },
    {
      "epoch": 1.227115289460663,
      "grad_norm": 5.440616607666016,
      "learning_rate": 1.182253010061026e-05,
      "loss": 0.0372,
      "step": 2480
    },
    {
      "epoch": 1.2320633349826817,
      "grad_norm": 0.010154436342418194,
      "learning_rate": 1.1789543130463468e-05,
      "loss": 0.035,
      "step": 2490
    },
    {
      "epoch": 1.2370113805047007,
      "grad_norm": 0.09873100370168686,
      "learning_rate": 1.1756556160316677e-05,
      "loss": 0.0353,
      "step": 2500
    },
    {
      "epoch": 1.2419594260267195,
      "grad_norm": 0.01580074056982994,
      "learning_rate": 1.1723569190169884e-05,
      "loss": 0.1238,
      "step": 2510
    },
    {
      "epoch": 1.2469074715487383,
      "grad_norm": 0.24190278351306915,
      "learning_rate": 1.1690582220023092e-05,
      "loss": 0.0017,
      "step": 2520
    },
    {
      "epoch": 1.251855517070757,
      "grad_norm": 16.196165084838867,
      "learning_rate": 1.16575952498763e-05,
      "loss": 0.0534,
      "step": 2530
    },
    {
      "epoch": 1.2568035625927758,
      "grad_norm": 0.016106177121400833,
      "learning_rate": 1.1624608279729508e-05,
      "loss": 0.0473,
      "step": 2540
    },
    {
      "epoch": 1.2617516081147946,
      "grad_norm": 0.015392680652439594,
      "learning_rate": 1.1591621309582717e-05,
      "loss": 0.0007,
      "step": 2550
    },
    {
      "epoch": 1.2666996536368136,
      "grad_norm": 0.07327626645565033,
      "learning_rate": 1.1558634339435924e-05,
      "loss": 0.0066,
      "step": 2560
    },
    {
      "epoch": 1.2716476991588324,
      "grad_norm": 0.0071744974702596664,
      "learning_rate": 1.1525647369289132e-05,
      "loss": 0.0209,
      "step": 2570
    },
    {
      "epoch": 1.2765957446808511,
      "grad_norm": 0.07732517272233963,
      "learning_rate": 1.149266039914234e-05,
      "loss": 0.0301,
      "step": 2580
    },
    {
      "epoch": 1.28154379020287,
      "grad_norm": 0.011520346626639366,
      "learning_rate": 1.1459673428995548e-05,
      "loss": 0.023,
      "step": 2590
    },
    {
      "epoch": 1.2864918357248887,
      "grad_norm": 16.55830192565918,
      "learning_rate": 1.1426686458848754e-05,
      "loss": 0.0402,
      "step": 2600
    },
    {
      "epoch": 1.2914398812469075,
      "grad_norm": 0.0367225743830204,
      "learning_rate": 1.1393699488701964e-05,
      "loss": 0.0022,
      "step": 2610
    },
    {
      "epoch": 1.2963879267689262,
      "grad_norm": 6.604392051696777,
      "learning_rate": 1.1360712518555172e-05,
      "loss": 0.0844,
      "step": 2620
    },
    {
      "epoch": 1.301335972290945,
      "grad_norm": 24.009441375732422,
      "learning_rate": 1.132772554840838e-05,
      "loss": 0.0197,
      "step": 2630
    },
    {
      "epoch": 1.3062840178129638,
      "grad_norm": 0.008250854909420013,
      "learning_rate": 1.1294738578261588e-05,
      "loss": 0.0015,
      "step": 2640
    },
    {
      "epoch": 1.3112320633349825,
      "grad_norm": 0.005403931252658367,
      "learning_rate": 1.1261751608114794e-05,
      "loss": 0.0031,
      "step": 2650
    },
    {
      "epoch": 1.3161801088570015,
      "grad_norm": 0.01974160224199295,
      "learning_rate": 1.1228764637968004e-05,
      "loss": 0.0012,
      "step": 2660
    },
    {
      "epoch": 1.3211281543790203,
      "grad_norm": 6.7506937980651855,
      "learning_rate": 1.119577766782121e-05,
      "loss": 0.0829,
      "step": 2670
    },
    {
      "epoch": 1.326076199901039,
      "grad_norm": 0.00753178121522069,
      "learning_rate": 1.116279069767442e-05,
      "loss": 0.0228,
      "step": 2680
    },
    {
      "epoch": 1.3310242454230579,
      "grad_norm": 28.35800552368164,
      "learning_rate": 1.1129803727527628e-05,
      "loss": 0.0792,
      "step": 2690
    },
    {
      "epoch": 1.3359722909450766,
      "grad_norm": 0.04140781983733177,
      "learning_rate": 1.1096816757380834e-05,
      "loss": 0.0007,
      "step": 2700
    },
    {
      "epoch": 1.3409203364670956,
      "grad_norm": 0.006482183933258057,
      "learning_rate": 1.1063829787234044e-05,
      "loss": 0.0007,
      "step": 2710
    },
    {
      "epoch": 1.3458683819891144,
      "grad_norm": 0.03146492689847946,
      "learning_rate": 1.103084281708725e-05,
      "loss": 0.0522,
      "step": 2720
    },
    {
      "epoch": 1.3508164275111332,
      "grad_norm": 0.02071508765220642,
      "learning_rate": 1.099785584694046e-05,
      "loss": 0.0682,
      "step": 2730
    },
    {
      "epoch": 1.355764473033152,
      "grad_norm": 0.014511290937662125,
      "learning_rate": 1.0964868876793668e-05,
      "loss": 0.0095,
      "step": 2740
    },
    {
      "epoch": 1.3607125185551707,
      "grad_norm": 10.541193008422852,
      "learning_rate": 1.0931881906646875e-05,
      "loss": 0.0309,
      "step": 2750
    },
    {
      "epoch": 1.3656605640771895,
      "grad_norm": 0.13435038924217224,
      "learning_rate": 1.0898894936500084e-05,
      "loss": 0.0312,
      "step": 2760
    },
    {
      "epoch": 1.3706086095992083,
      "grad_norm": 23.22443962097168,
      "learning_rate": 1.086590796635329e-05,
      "loss": 0.0638,
      "step": 2770
    },
    {
      "epoch": 1.375556655121227,
      "grad_norm": 0.008771920576691628,
      "learning_rate": 1.08329209962065e-05,
      "loss": 0.0411,
      "step": 2780
    },
    {
      "epoch": 1.3805047006432458,
      "grad_norm": 0.021610986441373825,
      "learning_rate": 1.0799934026059707e-05,
      "loss": 0.0182,
      "step": 2790
    },
    {
      "epoch": 1.3854527461652646,
      "grad_norm": 0.01100457925349474,
      "learning_rate": 1.0766947055912915e-05,
      "loss": 0.0221,
      "step": 2800
    },
    {
      "epoch": 1.3904007916872836,
      "grad_norm": 0.007084810175001621,
      "learning_rate": 1.0733960085766124e-05,
      "loss": 0.0455,
      "step": 2810
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 0.006107959896326065,
      "learning_rate": 1.070097311561933e-05,
      "loss": 0.0004,
      "step": 2820
    },
    {
      "epoch": 1.4002968827313211,
      "grad_norm": 0.012325859628617764,
      "learning_rate": 1.066798614547254e-05,
      "loss": 0.0662,
      "step": 2830
    },
    {
      "epoch": 1.40524492825334,
      "grad_norm": 0.020029524341225624,
      "learning_rate": 1.0634999175325747e-05,
      "loss": 0.0006,
      "step": 2840
    },
    {
      "epoch": 1.4101929737753587,
      "grad_norm": 0.0261476319283247,
      "learning_rate": 1.0602012205178955e-05,
      "loss": 0.0533,
      "step": 2850
    },
    {
      "epoch": 1.4151410192973775,
      "grad_norm": 24.135831832885742,
      "learning_rate": 1.0569025235032164e-05,
      "loss": 0.0309,
      "step": 2860
    },
    {
      "epoch": 1.4200890648193965,
      "grad_norm": 0.0943942442536354,
      "learning_rate": 1.053603826488537e-05,
      "loss": 0.0008,
      "step": 2870
    },
    {
      "epoch": 1.4250371103414152,
      "grad_norm": 2.7857162952423096,
      "learning_rate": 1.050305129473858e-05,
      "loss": 0.0362,
      "step": 2880
    },
    {
      "epoch": 1.429985155863434,
      "grad_norm": 0.011027824133634567,
      "learning_rate": 1.0470064324591787e-05,
      "loss": 0.0039,
      "step": 2890
    },
    {
      "epoch": 1.4349332013854528,
      "grad_norm": 6.543318748474121,
      "learning_rate": 1.0437077354444995e-05,
      "loss": 0.0378,
      "step": 2900
    },
    {
      "epoch": 1.4398812469074715,
      "grad_norm": 0.007737865671515465,
      "learning_rate": 1.0404090384298203e-05,
      "loss": 0.0897,
      "step": 2910
    },
    {
      "epoch": 1.4448292924294903,
      "grad_norm": 0.06362294405698776,
      "learning_rate": 1.0371103414151411e-05,
      "loss": 0.0277,
      "step": 2920
    },
    {
      "epoch": 1.449777337951509,
      "grad_norm": 0.027419665828347206,
      "learning_rate": 1.033811644400462e-05,
      "loss": 0.0363,
      "step": 2930
    },
    {
      "epoch": 1.4547253834735279,
      "grad_norm": 0.009364278987050056,
      "learning_rate": 1.0305129473857827e-05,
      "loss": 0.0017,
      "step": 2940
    },
    {
      "epoch": 1.4596734289955466,
      "grad_norm": 0.02894723042845726,
      "learning_rate": 1.0272142503711035e-05,
      "loss": 0.0689,
      "step": 2950
    },
    {
      "epoch": 1.4646214745175656,
      "grad_norm": 0.22872985899448395,
      "learning_rate": 1.0239155533564243e-05,
      "loss": 0.0016,
      "step": 2960
    },
    {
      "epoch": 1.4695695200395844,
      "grad_norm": 18.981563568115234,
      "learning_rate": 1.0206168563417451e-05,
      "loss": 0.0181,
      "step": 2970
    },
    {
      "epoch": 1.4745175655616032,
      "grad_norm": 10.5872220993042,
      "learning_rate": 1.0173181593270657e-05,
      "loss": 0.0186,
      "step": 2980
    },
    {
      "epoch": 1.479465611083622,
      "grad_norm": 0.054291002452373505,
      "learning_rate": 1.0140194623123867e-05,
      "loss": 0.0022,
      "step": 2990
    },
    {
      "epoch": 1.4844136566056407,
      "grad_norm": 0.012018779292702675,
      "learning_rate": 1.0107207652977075e-05,
      "loss": 0.0005,
      "step": 3000
    },
    {
      "epoch": 1.4893617021276595,
      "grad_norm": 0.06269412487745285,
      "learning_rate": 1.0074220682830283e-05,
      "loss": 0.0004,
      "step": 3010
    },
    {
      "epoch": 1.4943097476496785,
      "grad_norm": 0.004042445216327906,
      "learning_rate": 1.0041233712683491e-05,
      "loss": 0.0525,
      "step": 3020
    },
    {
      "epoch": 1.4992577931716973,
      "grad_norm": 0.018975773826241493,
      "learning_rate": 1.0008246742536698e-05,
      "loss": 0.0247,
      "step": 3030
    },
    {
      "epoch": 1.504205838693716,
      "grad_norm": 0.010897436179220676,
      "learning_rate": 9.975259772389907e-06,
      "loss": 0.0008,
      "step": 3040
    },
    {
      "epoch": 1.5091538842157348,
      "grad_norm": 0.0046326336450874805,
      "learning_rate": 9.942272802243115e-06,
      "loss": 0.0003,
      "step": 3050
    },
    {
      "epoch": 1.5141019297377536,
      "grad_norm": 0.012245386838912964,
      "learning_rate": 9.909285832096323e-06,
      "loss": 0.0202,
      "step": 3060
    },
    {
      "epoch": 1.5190499752597724,
      "grad_norm": 0.3625534176826477,
      "learning_rate": 9.87629886194953e-06,
      "loss": 0.0433,
      "step": 3070
    },
    {
      "epoch": 1.5239980207817911,
      "grad_norm": 0.003943112678825855,
      "learning_rate": 9.84331189180274e-06,
      "loss": 0.0006,
      "step": 3080
    },
    {
      "epoch": 1.52894606630381,
      "grad_norm": 0.005678342655301094,
      "learning_rate": 9.810324921655947e-06,
      "loss": 0.1175,
      "step": 3090
    },
    {
      "epoch": 1.5338941118258287,
      "grad_norm": 11.577986717224121,
      "learning_rate": 9.777337951509155e-06,
      "loss": 0.0567,
      "step": 3100
    },
    {
      "epoch": 1.5388421573478475,
      "grad_norm": 0.1379033476114273,
      "learning_rate": 9.744350981362363e-06,
      "loss": 0.0371,
      "step": 3110
    },
    {
      "epoch": 1.5437902028698665,
      "grad_norm": 0.04025011509656906,
      "learning_rate": 9.71136401121557e-06,
      "loss": 0.0016,
      "step": 3120
    },
    {
      "epoch": 1.5487382483918852,
      "grad_norm": 0.4979284703731537,
      "learning_rate": 9.678377041068778e-06,
      "loss": 0.0008,
      "step": 3130
    },
    {
      "epoch": 1.553686293913904,
      "grad_norm": 0.0037207389250397682,
      "learning_rate": 9.645390070921986e-06,
      "loss": 0.0714,
      "step": 3140
    },
    {
      "epoch": 1.5586343394359228,
      "grad_norm": 0.0035515367053449154,
      "learning_rate": 9.612403100775196e-06,
      "loss": 0.0015,
      "step": 3150
    },
    {
      "epoch": 1.5635823849579418,
      "grad_norm": 0.01500615756958723,
      "learning_rate": 9.579416130628404e-06,
      "loss": 0.0265,
      "step": 3160
    },
    {
      "epoch": 1.5685304304799605,
      "grad_norm": 0.03990001231431961,
      "learning_rate": 9.54642916048161e-06,
      "loss": 0.0241,
      "step": 3170
    },
    {
      "epoch": 1.5734784760019793,
      "grad_norm": 0.01519977580755949,
      "learning_rate": 9.513442190334818e-06,
      "loss": 0.0343,
      "step": 3180
    },
    {
      "epoch": 1.578426521523998,
      "grad_norm": 0.04252380505204201,
      "learning_rate": 9.480455220188026e-06,
      "loss": 0.0432,
      "step": 3190
    },
    {
      "epoch": 1.5833745670460169,
      "grad_norm": 0.027739819139242172,
      "learning_rate": 9.447468250041234e-06,
      "loss": 0.0259,
      "step": 3200
    },
    {
      "epoch": 1.5883226125680356,
      "grad_norm": 0.7119622826576233,
      "learning_rate": 9.414481279894444e-06,
      "loss": 0.0422,
      "step": 3210
    },
    {
      "epoch": 1.5932706580900544,
      "grad_norm": 0.009176445193588734,
      "learning_rate": 9.38149430974765e-06,
      "loss": 0.007,
      "step": 3220
    },
    {
      "epoch": 1.5982187036120732,
      "grad_norm": 0.029267290607094765,
      "learning_rate": 9.348507339600858e-06,
      "loss": 0.0192,
      "step": 3230
    },
    {
      "epoch": 1.603166749134092,
      "grad_norm": 0.03919142857193947,
      "learning_rate": 9.315520369454066e-06,
      "loss": 0.0052,
      "step": 3240
    },
    {
      "epoch": 1.6081147946561107,
      "grad_norm": 0.013373768888413906,
      "learning_rate": 9.282533399307274e-06,
      "loss": 0.0447,
      "step": 3250
    },
    {
      "epoch": 1.6130628401781295,
      "grad_norm": 0.007165670860558748,
      "learning_rate": 9.249546429160482e-06,
      "loss": 0.1264,
      "step": 3260
    },
    {
      "epoch": 1.6180108857001483,
      "grad_norm": 0.031128862872719765,
      "learning_rate": 9.21655945901369e-06,
      "loss": 0.0068,
      "step": 3270
    },
    {
      "epoch": 1.6229589312221673,
      "grad_norm": 0.0545368492603302,
      "learning_rate": 9.183572488866898e-06,
      "loss": 0.0159,
      "step": 3280
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 0.02729974500834942,
      "learning_rate": 9.150585518720106e-06,
      "loss": 0.0341,
      "step": 3290
    },
    {
      "epoch": 1.6328550222662048,
      "grad_norm": 0.011085924692451954,
      "learning_rate": 9.117598548573314e-06,
      "loss": 0.0087,
      "step": 3300
    },
    {
      "epoch": 1.6378030677882236,
      "grad_norm": 0.013864624314010143,
      "learning_rate": 9.084611578426522e-06,
      "loss": 0.0048,
      "step": 3310
    },
    {
      "epoch": 1.6427511133102426,
      "grad_norm": 0.026874905452132225,
      "learning_rate": 9.05162460827973e-06,
      "loss": 0.0633,
      "step": 3320
    },
    {
      "epoch": 1.6476991588322614,
      "grad_norm": 0.007826819084584713,
      "learning_rate": 9.018637638132938e-06,
      "loss": 0.0338,
      "step": 3330
    },
    {
      "epoch": 1.6526472043542801,
      "grad_norm": 0.40751057863235474,
      "learning_rate": 8.985650667986146e-06,
      "loss": 0.002,
      "step": 3340
    },
    {
      "epoch": 1.657595249876299,
      "grad_norm": 0.021191757172346115,
      "learning_rate": 8.952663697839354e-06,
      "loss": 0.0006,
      "step": 3350
    },
    {
      "epoch": 1.6625432953983177,
      "grad_norm": 0.052131686359643936,
      "learning_rate": 8.919676727692562e-06,
      "loss": 0.0392,
      "step": 3360
    },
    {
      "epoch": 1.6674913409203365,
      "grad_norm": 0.02477187290787697,
      "learning_rate": 8.88668975754577e-06,
      "loss": 0.001,
      "step": 3370
    },
    {
      "epoch": 1.6724393864423552,
      "grad_norm": 0.00810127891600132,
      "learning_rate": 8.853702787398978e-06,
      "loss": 0.0525,
      "step": 3380
    },
    {
      "epoch": 1.677387431964374,
      "grad_norm": 0.054788365960121155,
      "learning_rate": 8.820715817252186e-06,
      "loss": 0.0017,
      "step": 3390
    },
    {
      "epoch": 1.6823354774863928,
      "grad_norm": 5.561379909515381,
      "learning_rate": 8.787728847105394e-06,
      "loss": 0.028,
      "step": 3400
    },
    {
      "epoch": 1.6872835230084116,
      "grad_norm": 0.0126836858689785,
      "learning_rate": 8.754741876958603e-06,
      "loss": 0.0449,
      "step": 3410
    },
    {
      "epoch": 1.6922315685304303,
      "grad_norm": 0.019765423610806465,
      "learning_rate": 8.72175490681181e-06,
      "loss": 0.0359,
      "step": 3420
    },
    {
      "epoch": 1.6971796140524493,
      "grad_norm": 0.01800246722996235,
      "learning_rate": 8.688767936665019e-06,
      "loss": 0.0399,
      "step": 3430
    },
    {
      "epoch": 1.702127659574468,
      "grad_norm": 0.014041384682059288,
      "learning_rate": 8.655780966518225e-06,
      "loss": 0.005,
      "step": 3440
    },
    {
      "epoch": 1.7070757050964869,
      "grad_norm": 0.4837110638618469,
      "learning_rate": 8.622793996371433e-06,
      "loss": 0.0315,
      "step": 3450
    },
    {
      "epoch": 1.7120237506185056,
      "grad_norm": 0.006166455335915089,
      "learning_rate": 8.589807026224643e-06,
      "loss": 0.042,
      "step": 3460
    },
    {
      "epoch": 1.7169717961405246,
      "grad_norm": 0.0362619087100029,
      "learning_rate": 8.55682005607785e-06,
      "loss": 0.0414,
      "step": 3470
    },
    {
      "epoch": 1.7219198416625434,
      "grad_norm": 0.00517397653311491,
      "learning_rate": 8.523833085931059e-06,
      "loss": 0.0203,
      "step": 3480
    },
    {
      "epoch": 1.7268678871845622,
      "grad_norm": 0.01671973243355751,
      "learning_rate": 8.490846115784265e-06,
      "loss": 0.0243,
      "step": 3490
    },
    {
      "epoch": 1.731815932706581,
      "grad_norm": 0.06342405080795288,
      "learning_rate": 8.457859145637473e-06,
      "loss": 0.0908,
      "step": 3500
    },
    {
      "epoch": 1.7367639782285997,
      "grad_norm": 0.015172328799962997,
      "learning_rate": 8.424872175490681e-06,
      "loss": 0.0391,
      "step": 3510
    },
    {
      "epoch": 1.7417120237506185,
      "grad_norm": 0.3814590871334076,
      "learning_rate": 8.39188520534389e-06,
      "loss": 0.0322,
      "step": 3520
    },
    {
      "epoch": 1.7466600692726373,
      "grad_norm": 0.00695811165496707,
      "learning_rate": 8.358898235197099e-06,
      "loss": 0.0008,
      "step": 3530
    },
    {
      "epoch": 1.751608114794656,
      "grad_norm": 0.05707438662648201,
      "learning_rate": 8.325911265050305e-06,
      "loss": 0.0007,
      "step": 3540
    },
    {
      "epoch": 1.7565561603166748,
      "grad_norm": 6.248075008392334,
      "learning_rate": 8.292924294903513e-06,
      "loss": 0.0363,
      "step": 3550
    },
    {
      "epoch": 1.7615042058386936,
      "grad_norm": 25.869897842407227,
      "learning_rate": 8.259937324756721e-06,
      "loss": 0.0157,
      "step": 3560
    },
    {
      "epoch": 1.7664522513607124,
      "grad_norm": 0.0035779187455773354,
      "learning_rate": 8.22695035460993e-06,
      "loss": 0.0186,
      "step": 3570
    },
    {
      "epoch": 1.7714002968827314,
      "grad_norm": 0.07602275162935257,
      "learning_rate": 8.193963384463137e-06,
      "loss": 0.0164,
      "step": 3580
    },
    {
      "epoch": 1.7763483424047501,
      "grad_norm": 12.292678833007812,
      "learning_rate": 8.160976414316345e-06,
      "loss": 0.0493,
      "step": 3590
    },
    {
      "epoch": 1.781296387926769,
      "grad_norm": 0.007006868254393339,
      "learning_rate": 8.127989444169553e-06,
      "loss": 0.0432,
      "step": 3600
    },
    {
      "epoch": 1.7862444334487877,
      "grad_norm": 0.008165273815393448,
      "learning_rate": 8.095002474022761e-06,
      "loss": 0.0053,
      "step": 3610
    },
    {
      "epoch": 1.7911924789708067,
      "grad_norm": 0.010084825567901134,
      "learning_rate": 8.06201550387597e-06,
      "loss": 0.0005,
      "step": 3620
    },
    {
      "epoch": 1.7961405244928255,
      "grad_norm": 0.00842586811631918,
      "learning_rate": 8.029028533729177e-06,
      "loss": 0.0004,
      "step": 3630
    },
    {
      "epoch": 1.8010885700148442,
      "grad_norm": 0.007646196521818638,
      "learning_rate": 7.996041563582385e-06,
      "loss": 0.0448,
      "step": 3640
    },
    {
      "epoch": 1.806036615536863,
      "grad_norm": 0.010266706347465515,
      "learning_rate": 7.963054593435593e-06,
      "loss": 0.0358,
      "step": 3650
    },
    {
      "epoch": 1.8109846610588818,
      "grad_norm": 0.1010296642780304,
      "learning_rate": 7.930067623288801e-06,
      "loss": 0.036,
      "step": 3660
    },
    {
      "epoch": 1.8159327065809006,
      "grad_norm": 0.11074648797512054,
      "learning_rate": 7.89708065314201e-06,
      "loss": 0.0438,
      "step": 3670
    },
    {
      "epoch": 1.8208807521029193,
      "grad_norm": 0.005548635497689247,
      "learning_rate": 7.864093682995218e-06,
      "loss": 0.0003,
      "step": 3680
    },
    {
      "epoch": 1.825828797624938,
      "grad_norm": 0.005831524264067411,
      "learning_rate": 7.831106712848426e-06,
      "loss": 0.0158,
      "step": 3690
    },
    {
      "epoch": 1.8307768431469569,
      "grad_norm": 0.004487977363169193,
      "learning_rate": 7.798119742701634e-06,
      "loss": 0.084,
      "step": 3700
    },
    {
      "epoch": 1.8357248886689757,
      "grad_norm": 0.03560226410627365,
      "learning_rate": 7.765132772554842e-06,
      "loss": 0.0007,
      "step": 3710
    },
    {
      "epoch": 1.8406729341909944,
      "grad_norm": 0.49525684118270874,
      "learning_rate": 7.73214580240805e-06,
      "loss": 0.0392,
      "step": 3720
    },
    {
      "epoch": 1.8456209797130132,
      "grad_norm": 0.013986232690513134,
      "learning_rate": 7.699158832261258e-06,
      "loss": 0.0359,
      "step": 3730
    },
    {
      "epoch": 1.8505690252350322,
      "grad_norm": 0.002906743437051773,
      "learning_rate": 7.666171862114466e-06,
      "loss": 0.0004,
      "step": 3740
    },
    {
      "epoch": 1.855517070757051,
      "grad_norm": 0.004092598799616098,
      "learning_rate": 7.633184891967674e-06,
      "loss": 0.0232,
      "step": 3750
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 0.029369333758950233,
      "learning_rate": 7.600197921820881e-06,
      "loss": 0.0004,
      "step": 3760
    },
    {
      "epoch": 1.8654131618010885,
      "grad_norm": 0.009330643340945244,
      "learning_rate": 7.567210951674089e-06,
      "loss": 0.0003,
      "step": 3770
    },
    {
      "epoch": 1.8703612073231075,
      "grad_norm": 0.007097158115357161,
      "learning_rate": 7.534223981527298e-06,
      "loss": 0.0014,
      "step": 3780
    },
    {
      "epoch": 1.8753092528451263,
      "grad_norm": 0.015100574120879173,
      "learning_rate": 7.501237011380506e-06,
      "loss": 0.0348,
      "step": 3790
    },
    {
      "epoch": 1.880257298367145,
      "grad_norm": 3.703728675842285,
      "learning_rate": 7.468250041233713e-06,
      "loss": 0.0767,
      "step": 3800
    },
    {
      "epoch": 1.8852053438891638,
      "grad_norm": 0.061271123588085175,
      "learning_rate": 7.435263071086921e-06,
      "loss": 0.0477,
      "step": 3810
    },
    {
      "epoch": 1.8901533894111826,
      "grad_norm": 5.990945339202881,
      "learning_rate": 7.402276100940129e-06,
      "loss": 0.0623,
      "step": 3820
    },
    {
      "epoch": 1.8951014349332014,
      "grad_norm": 0.003692222060635686,
      "learning_rate": 7.369289130793337e-06,
      "loss": 0.0006,
      "step": 3830
    },
    {
      "epoch": 1.9000494804552202,
      "grad_norm": 0.02694610506296158,
      "learning_rate": 7.336302160646546e-06,
      "loss": 0.0556,
      "step": 3840
    },
    {
      "epoch": 1.904997525977239,
      "grad_norm": 3.6279897689819336,
      "learning_rate": 7.303315190499753e-06,
      "loss": 0.052,
      "step": 3850
    },
    {
      "epoch": 1.9099455714992577,
      "grad_norm": 0.09477703273296356,
      "learning_rate": 7.270328220352961e-06,
      "loss": 0.0005,
      "step": 3860
    },
    {
      "epoch": 1.9148936170212765,
      "grad_norm": 0.05096007511019707,
      "learning_rate": 7.237341250206169e-06,
      "loss": 0.0434,
      "step": 3870
    },
    {
      "epoch": 1.9198416625432952,
      "grad_norm": 0.014571033418178558,
      "learning_rate": 7.204354280059377e-06,
      "loss": 0.0039,
      "step": 3880
    },
    {
      "epoch": 1.9247897080653142,
      "grad_norm": 7.116293430328369,
      "learning_rate": 7.171367309912584e-06,
      "loss": 0.0372,
      "step": 3890
    },
    {
      "epoch": 1.929737753587333,
      "grad_norm": 0.8212539553642273,
      "learning_rate": 7.138380339765793e-06,
      "loss": 0.001,
      "step": 3900
    },
    {
      "epoch": 1.9346857991093518,
      "grad_norm": 27.64038848876953,
      "learning_rate": 7.105393369619001e-06,
      "loss": 0.007,
      "step": 3910
    },
    {
      "epoch": 1.9396338446313706,
      "grad_norm": 0.017232894897460938,
      "learning_rate": 7.072406399472209e-06,
      "loss": 0.0675,
      "step": 3920
    },
    {
      "epoch": 1.9445818901533896,
      "grad_norm": 0.018140103667974472,
      "learning_rate": 7.039419429325417e-06,
      "loss": 0.0004,
      "step": 3930
    },
    {
      "epoch": 1.9495299356754083,
      "grad_norm": 0.016247550025582314,
      "learning_rate": 7.0064324591786245e-06,
      "loss": 0.048,
      "step": 3940
    },
    {
      "epoch": 1.954477981197427,
      "grad_norm": 7.350187301635742,
      "learning_rate": 6.9734454890318325e-06,
      "loss": 0.0398,
      "step": 3950
    },
    {
      "epoch": 1.9594260267194459,
      "grad_norm": 0.012748106382787228,
      "learning_rate": 6.940458518885041e-06,
      "loss": 0.0013,
      "step": 3960
    },
    {
      "epoch": 1.9643740722414647,
      "grad_norm": 0.0030664829537272453,
      "learning_rate": 6.907471548738249e-06,
      "loss": 0.0003,
      "step": 3970
    },
    {
      "epoch": 1.9693221177634834,
      "grad_norm": 0.722181499004364,
      "learning_rate": 6.8744845785914574e-06,
      "loss": 0.0005,
      "step": 3980
    },
    {
      "epoch": 1.9742701632855022,
      "grad_norm": 0.7054228782653809,
      "learning_rate": 6.841497608444665e-06,
      "loss": 0.002,
      "step": 3990
    },
    {
      "epoch": 1.979218208807521,
      "grad_norm": 0.033851075917482376,
      "learning_rate": 6.808510638297873e-06,
      "loss": 0.0173,
      "step": 4000
    },
    {
      "epoch": 1.9841662543295397,
      "grad_norm": 0.002102657686918974,
      "learning_rate": 6.775523668151081e-06,
      "loss": 0.0006,
      "step": 4010
    },
    {
      "epoch": 1.9891142998515585,
      "grad_norm": 0.005957062356173992,
      "learning_rate": 6.742536698004289e-06,
      "loss": 0.0328,
      "step": 4020
    },
    {
      "epoch": 1.9940623453735773,
      "grad_norm": 0.13474895060062408,
      "learning_rate": 6.7095497278574976e-06,
      "loss": 0.0465,
      "step": 4030
    },
    {
      "epoch": 1.9990103908955963,
      "grad_norm": 0.0016277660615742207,
      "learning_rate": 6.676562757710705e-06,
      "loss": 0.0143,
      "step": 4040
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9824610244988864,
      "eval_f1": 0.9816272965879265,
      "eval_loss": 0.08680925518274307,
      "eval_precision": 0.9807692307692307,
      "eval_recall": 0.9824868651488616,
      "eval_runtime": 179.5523,
      "eval_samples_per_second": 20.005,
      "eval_steps_per_second": 1.253,
      "step": 4042
    },
    {
      "epoch": 0.004948045522018802,
      "grad_norm": 2.083307981491089,
      "learning_rate": 1.9970311726867887e-05,
      "loss": 0.6662,
      "step": 10
    },
    {
      "epoch": 0.009896091044037604,
      "grad_norm": 2.7390191555023193,
      "learning_rate": 1.9937324756721097e-05,
      "loss": 0.5219,
      "step": 20
    },
    {
      "epoch": 0.014844136566056407,
      "grad_norm": 6.878846645355225,
      "learning_rate": 1.9904337786574303e-05,
      "loss": 0.37,
      "step": 30
    },
    {
      "epoch": 0.01979218208807521,
      "grad_norm": 4.318190097808838,
      "learning_rate": 1.9871350816427513e-05,
      "loss": 0.2521,
      "step": 40
    },
    {
      "epoch": 0.024740227610094014,
      "grad_norm": 9.216415405273438,
      "learning_rate": 1.9838363846280723e-05,
      "loss": 0.2093,
      "step": 50
    },
    {
      "epoch": 0.029688273132112815,
      "grad_norm": 8.236034393310547,
      "learning_rate": 1.980537687613393e-05,
      "loss": 0.1832,
      "step": 60
    },
    {
      "epoch": 0.034636318654131616,
      "grad_norm": 4.756049633026123,
      "learning_rate": 1.9772389905987135e-05,
      "loss": 0.1945,
      "step": 70
    },
    {
      "epoch": 0.03958436417615042,
      "grad_norm": 5.219125747680664,
      "learning_rate": 1.9739402935840345e-05,
      "loss": 0.24,
      "step": 80
    },
    {
      "epoch": 0.044532409698169226,
      "grad_norm": 3.162048578262329,
      "learning_rate": 1.970641596569355e-05,
      "loss": 0.1362,
      "step": 90
    },
    {
      "epoch": 0.04948045522018803,
      "grad_norm": 4.394230365753174,
      "learning_rate": 1.967342899554676e-05,
      "loss": 0.1812,
      "step": 100
    },
    {
      "epoch": 0.05442850074220683,
      "grad_norm": 0.19086267054080963,
      "learning_rate": 1.9640442025399968e-05,
      "loss": 0.0725,
      "step": 110
    },
    {
      "epoch": 0.05937654626422563,
      "grad_norm": 0.19721370935440063,
      "learning_rate": 1.9607455055253177e-05,
      "loss": 0.1096,
      "step": 120
    },
    {
      "epoch": 0.06432459178624443,
      "grad_norm": 13.479732513427734,
      "learning_rate": 1.9574468085106384e-05,
      "loss": 0.1201,
      "step": 130
    },
    {
      "epoch": 0.06927263730826323,
      "grad_norm": 0.12804940342903137,
      "learning_rate": 1.9541481114959593e-05,
      "loss": 0.0866,
      "step": 140
    },
    {
      "epoch": 0.07422068283028203,
      "grad_norm": 0.24177192151546478,
      "learning_rate": 1.95084941448128e-05,
      "loss": 0.0846,
      "step": 150
    },
    {
      "epoch": 0.07916872835230084,
      "grad_norm": 2.2864034175872803,
      "learning_rate": 1.947550717466601e-05,
      "loss": 0.1581,
      "step": 160
    },
    {
      "epoch": 0.08411677387431965,
      "grad_norm": 4.249545574188232,
      "learning_rate": 1.9442520204519216e-05,
      "loss": 0.2232,
      "step": 170
    },
    {
      "epoch": 0.08906481939633845,
      "grad_norm": 0.34422767162323,
      "learning_rate": 1.9409533234372425e-05,
      "loss": 0.1256,
      "step": 180
    },
    {
      "epoch": 0.09401286491835725,
      "grad_norm": 0.42557862401008606,
      "learning_rate": 1.9376546264225632e-05,
      "loss": 0.1423,
      "step": 190
    },
    {
      "epoch": 0.09896091044037605,
      "grad_norm": 19.31597328186035,
      "learning_rate": 1.9343559294078838e-05,
      "loss": 0.111,
      "step": 200
    },
    {
      "epoch": 0.10390895596239486,
      "grad_norm": 0.08680129796266556,
      "learning_rate": 1.9310572323932048e-05,
      "loss": 0.0668,
      "step": 210
    },
    {
      "epoch": 0.10885700148441366,
      "grad_norm": 0.1590888947248459,
      "learning_rate": 1.9277585353785254e-05,
      "loss": 0.1487,
      "step": 220
    },
    {
      "epoch": 0.11380504700643246,
      "grad_norm": 1.1533154249191284,
      "learning_rate": 1.9244598383638464e-05,
      "loss": 0.0903,
      "step": 230
    },
    {
      "epoch": 0.11875309252845126,
      "grad_norm": 0.5391048789024353,
      "learning_rate": 1.9211611413491674e-05,
      "loss": 0.1996,
      "step": 240
    },
    {
      "epoch": 0.12370113805047006,
      "grad_norm": 3.9532554149627686,
      "learning_rate": 1.917862444334488e-05,
      "loss": 0.0967,
      "step": 250
    },
    {
      "epoch": 0.12864918357248886,
      "grad_norm": 10.393773078918457,
      "learning_rate": 1.914563747319809e-05,
      "loss": 0.1028,
      "step": 260
    },
    {
      "epoch": 0.13359722909450766,
      "grad_norm": 5.41870641708374,
      "learning_rate": 1.9112650503051296e-05,
      "loss": 0.1046,
      "step": 270
    },
    {
      "epoch": 0.13854527461652646,
      "grad_norm": 4.591911315917969,
      "learning_rate": 1.9079663532904506e-05,
      "loss": 0.1047,
      "step": 280
    },
    {
      "epoch": 0.14349332013854527,
      "grad_norm": 0.9195568561553955,
      "learning_rate": 1.9046676562757712e-05,
      "loss": 0.0627,
      "step": 290
    },
    {
      "epoch": 0.14844136566056407,
      "grad_norm": 10.907586097717285,
      "learning_rate": 1.901368959261092e-05,
      "loss": 0.2917,
      "step": 300
    },
    {
      "epoch": 0.15338941118258287,
      "grad_norm": 9.88653564453125,
      "learning_rate": 1.8980702622464128e-05,
      "loss": 0.1186,
      "step": 310
    },
    {
      "epoch": 0.15833745670460167,
      "grad_norm": 0.14319217205047607,
      "learning_rate": 1.8947715652317334e-05,
      "loss": 0.1927,
      "step": 320
    },
    {
      "epoch": 0.16328550222662047,
      "grad_norm": 1.7564142942428589,
      "learning_rate": 1.8914728682170544e-05,
      "loss": 0.079,
      "step": 330
    },
    {
      "epoch": 0.1682335477486393,
      "grad_norm": 0.11367207020521164,
      "learning_rate": 1.888174171202375e-05,
      "loss": 0.0614,
      "step": 340
    },
    {
      "epoch": 0.1731815932706581,
      "grad_norm": 3.21763277053833,
      "learning_rate": 1.884875474187696e-05,
      "loss": 0.2662,
      "step": 350
    },
    {
      "epoch": 0.1781296387926769,
      "grad_norm": 4.511270046234131,
      "learning_rate": 1.881576777173017e-05,
      "loss": 0.0934,
      "step": 360
    },
    {
      "epoch": 0.1830776843146957,
      "grad_norm": 0.21536241471767426,
      "learning_rate": 1.8782780801583376e-05,
      "loss": 0.1201,
      "step": 370
    },
    {
      "epoch": 0.1880257298367145,
      "grad_norm": 7.710086822509766,
      "learning_rate": 1.8749793831436586e-05,
      "loss": 0.0766,
      "step": 380
    },
    {
      "epoch": 0.1929737753587333,
      "grad_norm": 0.07848420739173889,
      "learning_rate": 1.8716806861289792e-05,
      "loss": 0.0344,
      "step": 390
    },
    {
      "epoch": 0.1979218208807521,
      "grad_norm": 2.123512029647827,
      "learning_rate": 1.8683819891143e-05,
      "loss": 0.0804,
      "step": 400
    },
    {
      "epoch": 0.2028698664027709,
      "grad_norm": 19.27537727355957,
      "learning_rate": 1.865083292099621e-05,
      "loss": 0.1201,
      "step": 410
    },
    {
      "epoch": 0.2078179119247897,
      "grad_norm": 0.7075232863426208,
      "learning_rate": 1.8617845950849415e-05,
      "loss": 0.0747,
      "step": 420
    },
    {
      "epoch": 0.2127659574468085,
      "grad_norm": 1.48856782913208,
      "learning_rate": 1.8584858980702624e-05,
      "loss": 0.0479,
      "step": 430
    },
    {
      "epoch": 0.2177140029688273,
      "grad_norm": 0.04681114852428436,
      "learning_rate": 1.855187201055583e-05,
      "loss": 0.0651,
      "step": 440
    },
    {
      "epoch": 0.22266204849084612,
      "grad_norm": 0.5338934063911438,
      "learning_rate": 1.851888504040904e-05,
      "loss": 0.028,
      "step": 450
    },
    {
      "epoch": 0.22761009401286492,
      "grad_norm": 1.1672910451889038,
      "learning_rate": 1.8485898070262247e-05,
      "loss": 0.0618,
      "step": 460
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 0.03572314605116844,
      "learning_rate": 1.8452911100115457e-05,
      "loss": 0.1013,
      "step": 470
    },
    {
      "epoch": 0.23750618505690252,
      "grad_norm": 0.13009002804756165,
      "learning_rate": 1.8419924129968666e-05,
      "loss": 0.0387,
      "step": 480
    },
    {
      "epoch": 0.24245423057892132,
      "grad_norm": 0.052606333047151566,
      "learning_rate": 1.8386937159821873e-05,
      "loss": 0.0493,
      "step": 490
    },
    {
      "epoch": 0.24740227610094012,
      "grad_norm": 3.4013123512268066,
      "learning_rate": 1.835395018967508e-05,
      "loss": 0.0868,
      "step": 500
    },
    {
      "epoch": 0.25235032162295895,
      "grad_norm": 0.3067084848880768,
      "learning_rate": 1.832096321952829e-05,
      "loss": 0.1195,
      "step": 510
    },
    {
      "epoch": 0.2572983671449777,
      "grad_norm": 1.599831461906433,
      "learning_rate": 1.8287976249381495e-05,
      "loss": 0.154,
      "step": 520
    },
    {
      "epoch": 0.26224641266699655,
      "grad_norm": 2.829253911972046,
      "learning_rate": 1.82549892792347e-05,
      "loss": 0.161,
      "step": 530
    },
    {
      "epoch": 0.2671944581890153,
      "grad_norm": 0.6623570919036865,
      "learning_rate": 1.822200230908791e-05,
      "loss": 0.1297,
      "step": 540
    },
    {
      "epoch": 0.27214250371103416,
      "grad_norm": 12.95406723022461,
      "learning_rate": 1.818901533894112e-05,
      "loss": 0.0789,
      "step": 550
    },
    {
      "epoch": 0.27709054923305293,
      "grad_norm": 0.39347994327545166,
      "learning_rate": 1.8156028368794327e-05,
      "loss": 0.0469,
      "step": 560
    },
    {
      "epoch": 0.28203859475507176,
      "grad_norm": 0.40931206941604614,
      "learning_rate": 1.8123041398647537e-05,
      "loss": 0.0639,
      "step": 570
    },
    {
      "epoch": 0.28698664027709053,
      "grad_norm": 5.183740615844727,
      "learning_rate": 1.8090054428500743e-05,
      "loss": 0.1431,
      "step": 580
    },
    {
      "epoch": 0.29193468579910936,
      "grad_norm": 0.030934404581785202,
      "learning_rate": 1.8057067458353953e-05,
      "loss": 0.0715,
      "step": 590
    },
    {
      "epoch": 0.29688273132112813,
      "grad_norm": 18.160383224487305,
      "learning_rate": 1.802408048820716e-05,
      "loss": 0.0577,
      "step": 600
    },
    {
      "epoch": 0.30183077684314696,
      "grad_norm": 0.06146349757909775,
      "learning_rate": 1.799109351806037e-05,
      "loss": 0.0733,
      "step": 610
    },
    {
      "epoch": 0.30677882236516574,
      "grad_norm": 0.08057578653097153,
      "learning_rate": 1.7958106547913575e-05,
      "loss": 0.1204,
      "step": 620
    },
    {
      "epoch": 0.31172686788718457,
      "grad_norm": 22.585683822631836,
      "learning_rate": 1.792511957776678e-05,
      "loss": 0.1668,
      "step": 630
    },
    {
      "epoch": 0.31667491340920334,
      "grad_norm": 7.928167343139648,
      "learning_rate": 1.789213260761999e-05,
      "loss": 0.0553,
      "step": 640
    },
    {
      "epoch": 0.32162295893122217,
      "grad_norm": 0.14058524370193481,
      "learning_rate": 1.7859145637473198e-05,
      "loss": 0.1154,
      "step": 650
    },
    {
      "epoch": 0.32657100445324094,
      "grad_norm": 13.486061096191406,
      "learning_rate": 1.7826158667326407e-05,
      "loss": 0.0356,
      "step": 660
    },
    {
      "epoch": 0.33151904997525977,
      "grad_norm": 17.393245697021484,
      "learning_rate": 1.7793171697179617e-05,
      "loss": 0.0242,
      "step": 670
    },
    {
      "epoch": 0.3364670954972786,
      "grad_norm": 18.788312911987305,
      "learning_rate": 1.7760184727032823e-05,
      "loss": 0.0851,
      "step": 680
    },
    {
      "epoch": 0.3414151410192974,
      "grad_norm": 12.172231674194336,
      "learning_rate": 1.7727197756886033e-05,
      "loss": 0.0884,
      "step": 690
    },
    {
      "epoch": 0.3463631865413162,
      "grad_norm": 0.04007274657487869,
      "learning_rate": 1.769421078673924e-05,
      "loss": 0.1315,
      "step": 700
    },
    {
      "epoch": 0.351311232063335,
      "grad_norm": 8.392043113708496,
      "learning_rate": 1.766122381659245e-05,
      "loss": 0.1236,
      "step": 710
    },
    {
      "epoch": 0.3562592775853538,
      "grad_norm": 0.5907721519470215,
      "learning_rate": 1.7628236846445655e-05,
      "loss": 0.1519,
      "step": 720
    },
    {
      "epoch": 0.3612073231073726,
      "grad_norm": 0.5257152318954468,
      "learning_rate": 1.7595249876298862e-05,
      "loss": 0.037,
      "step": 730
    },
    {
      "epoch": 0.3661553686293914,
      "grad_norm": 10.932088851928711,
      "learning_rate": 1.756226290615207e-05,
      "loss": 0.0988,
      "step": 740
    },
    {
      "epoch": 0.3711034141514102,
      "grad_norm": 18.741071701049805,
      "learning_rate": 1.7529275936005278e-05,
      "loss": 0.0791,
      "step": 750
    },
    {
      "epoch": 0.376051459673429,
      "grad_norm": 0.09219519793987274,
      "learning_rate": 1.7496288965858488e-05,
      "loss": 0.0436,
      "step": 760
    },
    {
      "epoch": 0.3809995051954478,
      "grad_norm": 5.648781776428223,
      "learning_rate": 1.7463301995711694e-05,
      "loss": 0.0706,
      "step": 770
    },
    {
      "epoch": 0.3859475507174666,
      "grad_norm": 14.037808418273926,
      "learning_rate": 1.7430315025564904e-05,
      "loss": 0.2534,
      "step": 780
    },
    {
      "epoch": 0.3908955962394854,
      "grad_norm": 0.11006524413824081,
      "learning_rate": 1.7397328055418113e-05,
      "loss": 0.1036,
      "step": 790
    },
    {
      "epoch": 0.3958436417615042,
      "grad_norm": 0.060364361852407455,
      "learning_rate": 1.736434108527132e-05,
      "loss": 0.055,
      "step": 800
    },
    {
      "epoch": 0.400791687283523,
      "grad_norm": 0.09602401405572891,
      "learning_rate": 1.733135411512453e-05,
      "loss": 0.0886,
      "step": 810
    },
    {
      "epoch": 0.4057397328055418,
      "grad_norm": 11.859095573425293,
      "learning_rate": 1.7298367144977736e-05,
      "loss": 0.0266,
      "step": 820
    },
    {
      "epoch": 0.4106877783275606,
      "grad_norm": 0.07104148715734482,
      "learning_rate": 1.7265380174830942e-05,
      "loss": 0.0497,
      "step": 830
    },
    {
      "epoch": 0.4156358238495794,
      "grad_norm": 0.031956661492586136,
      "learning_rate": 1.7232393204684152e-05,
      "loss": 0.0637,
      "step": 840
    },
    {
      "epoch": 0.4205838693715982,
      "grad_norm": 7.584319591522217,
      "learning_rate": 1.7199406234537358e-05,
      "loss": 0.1158,
      "step": 850
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 0.09121901541948318,
      "learning_rate": 1.7166419264390568e-05,
      "loss": 0.1393,
      "step": 860
    },
    {
      "epoch": 0.4304799604156358,
      "grad_norm": 7.501597881317139,
      "learning_rate": 1.7133432294243774e-05,
      "loss": 0.0619,
      "step": 870
    },
    {
      "epoch": 0.4354280059376546,
      "grad_norm": 0.5705838799476624,
      "learning_rate": 1.7100445324096984e-05,
      "loss": 0.0351,
      "step": 880
    },
    {
      "epoch": 0.44037605145967346,
      "grad_norm": 9.694978713989258,
      "learning_rate": 1.706745835395019e-05,
      "loss": 0.1203,
      "step": 890
    },
    {
      "epoch": 0.44532409698169223,
      "grad_norm": 8.816353797912598,
      "learning_rate": 1.70344713838034e-05,
      "loss": 0.1703,
      "step": 900
    },
    {
      "epoch": 0.45027214250371106,
      "grad_norm": 0.23506025969982147,
      "learning_rate": 1.7001484413656606e-05,
      "loss": 0.1034,
      "step": 910
    },
    {
      "epoch": 0.45522018802572983,
      "grad_norm": 0.061143603175878525,
      "learning_rate": 1.6968497443509816e-05,
      "loss": 0.0464,
      "step": 920
    },
    {
      "epoch": 0.46016823354774866,
      "grad_norm": 0.9215734004974365,
      "learning_rate": 1.6935510473363022e-05,
      "loss": 0.0753,
      "step": 930
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 0.040241893380880356,
      "learning_rate": 1.6902523503216232e-05,
      "loss": 0.0564,
      "step": 940
    },
    {
      "epoch": 0.47006432459178626,
      "grad_norm": 0.26941952109336853,
      "learning_rate": 1.686953653306944e-05,
      "loss": 0.0472,
      "step": 950
    },
    {
      "epoch": 0.47501237011380504,
      "grad_norm": 9.566105842590332,
      "learning_rate": 1.6836549562922645e-05,
      "loss": 0.0075,
      "step": 960
    },
    {
      "epoch": 0.47996041563582387,
      "grad_norm": 13.46181583404541,
      "learning_rate": 1.6803562592775854e-05,
      "loss": 0.1029,
      "step": 970
    },
    {
      "epoch": 0.48490846115784264,
      "grad_norm": 20.636093139648438,
      "learning_rate": 1.6770575622629064e-05,
      "loss": 0.0872,
      "step": 980
    },
    {
      "epoch": 0.48985650667986147,
      "grad_norm": 0.32675328850746155,
      "learning_rate": 1.673758865248227e-05,
      "loss": 0.0853,
      "step": 990
    },
    {
      "epoch": 0.49480455220188024,
      "grad_norm": 0.012083613313734531,
      "learning_rate": 1.670460168233548e-05,
      "loss": 0.0021,
      "step": 1000
    },
    {
      "epoch": 0.4997525977238991,
      "grad_norm": 0.043934937566518784,
      "learning_rate": 1.6671614712188687e-05,
      "loss": 0.0862,
      "step": 1010
    },
    {
      "epoch": 0.5047006432459179,
      "grad_norm": 0.09779392927885056,
      "learning_rate": 1.6638627742041896e-05,
      "loss": 0.0915,
      "step": 1020
    },
    {
      "epoch": 0.5096486887679367,
      "grad_norm": 8.221818923950195,
      "learning_rate": 1.6605640771895103e-05,
      "loss": 0.0753,
      "step": 1030
    },
    {
      "epoch": 0.5145967342899554,
      "grad_norm": 0.03063368983566761,
      "learning_rate": 1.6572653801748312e-05,
      "loss": 0.0304,
      "step": 1040
    },
    {
      "epoch": 0.5195447798119742,
      "grad_norm": 2.528777837753296,
      "learning_rate": 1.653966683160152e-05,
      "loss": 0.1146,
      "step": 1050
    },
    {
      "epoch": 0.5244928253339931,
      "grad_norm": 0.02647237479686737,
      "learning_rate": 1.6506679861454725e-05,
      "loss": 0.0445,
      "step": 1060
    },
    {
      "epoch": 0.5294408708560119,
      "grad_norm": 1.3835035562515259,
      "learning_rate": 1.6473692891307935e-05,
      "loss": 0.0487,
      "step": 1070
    },
    {
      "epoch": 0.5343889163780307,
      "grad_norm": 0.15118873119354248,
      "learning_rate": 1.644070592116114e-05,
      "loss": 0.0663,
      "step": 1080
    },
    {
      "epoch": 0.5393369619000494,
      "grad_norm": 23.11678123474121,
      "learning_rate": 1.640771895101435e-05,
      "loss": 0.1359,
      "step": 1090
    },
    {
      "epoch": 0.5442850074220683,
      "grad_norm": 1.441372036933899,
      "learning_rate": 1.6374731980867557e-05,
      "loss": 0.0342,
      "step": 1100
    },
    {
      "epoch": 0.5492330529440871,
      "grad_norm": 0.08466717600822449,
      "learning_rate": 1.6341745010720767e-05,
      "loss": 0.0485,
      "step": 1110
    },
    {
      "epoch": 0.5541810984661059,
      "grad_norm": 0.029211582615971565,
      "learning_rate": 1.6308758040573976e-05,
      "loss": 0.0445,
      "step": 1120
    },
    {
      "epoch": 0.5591291439881247,
      "grad_norm": 0.028145791962742805,
      "learning_rate": 1.6275771070427183e-05,
      "loss": 0.0555,
      "step": 1130
    },
    {
      "epoch": 0.5640771895101435,
      "grad_norm": 0.02021896094083786,
      "learning_rate": 1.6242784100280393e-05,
      "loss": 0.0575,
      "step": 1140
    },
    {
      "epoch": 0.5690252350321623,
      "grad_norm": 0.07333213090896606,
      "learning_rate": 1.62097971301336e-05,
      "loss": 0.0503,
      "step": 1150
    },
    {
      "epoch": 0.5739732805541811,
      "grad_norm": 0.0699671059846878,
      "learning_rate": 1.6176810159986805e-05,
      "loss": 0.0163,
      "step": 1160
    },
    {
      "epoch": 0.5789213260762,
      "grad_norm": 14.429854393005371,
      "learning_rate": 1.6143823189840015e-05,
      "loss": 0.0917,
      "step": 1170
    },
    {
      "epoch": 0.5838693715982187,
      "grad_norm": 0.05973955988883972,
      "learning_rate": 1.611083621969322e-05,
      "loss": 0.0611,
      "step": 1180
    },
    {
      "epoch": 0.5888174171202375,
      "grad_norm": 9.14852523803711,
      "learning_rate": 1.607784924954643e-05,
      "loss": 0.0638,
      "step": 1190
    },
    {
      "epoch": 0.5937654626422563,
      "grad_norm": 0.0851200670003891,
      "learning_rate": 1.6044862279399637e-05,
      "loss": 0.0312,
      "step": 1200
    },
    {
      "epoch": 0.5987135081642752,
      "grad_norm": 0.03217971324920654,
      "learning_rate": 1.6011875309252847e-05,
      "loss": 0.054,
      "step": 1210
    },
    {
      "epoch": 0.6036615536862939,
      "grad_norm": 0.3308243155479431,
      "learning_rate": 1.5978888339106053e-05,
      "loss": 0.0621,
      "step": 1220
    },
    {
      "epoch": 0.6086095992083127,
      "grad_norm": 0.029482772573828697,
      "learning_rate": 1.5945901368959263e-05,
      "loss": 0.0748,
      "step": 1230
    },
    {
      "epoch": 0.6135576447303315,
      "grad_norm": 13.087727546691895,
      "learning_rate": 1.5912914398812473e-05,
      "loss": 0.037,
      "step": 1240
    },
    {
      "epoch": 0.6185056902523504,
      "grad_norm": 12.393936157226562,
      "learning_rate": 1.587992742866568e-05,
      "loss": 0.0282,
      "step": 1250
    },
    {
      "epoch": 0.6234537357743691,
      "grad_norm": 18.055524826049805,
      "learning_rate": 1.5846940458518885e-05,
      "loss": 0.0652,
      "step": 1260
    },
    {
      "epoch": 0.6284017812963879,
      "grad_norm": 0.017833318561315536,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 0.0095,
      "step": 1270
    },
    {
      "epoch": 0.6333498268184067,
      "grad_norm": 11.66836929321289,
      "learning_rate": 1.57809665182253e-05,
      "loss": 0.0926,
      "step": 1280
    },
    {
      "epoch": 0.6382978723404256,
      "grad_norm": 0.19549229741096497,
      "learning_rate": 1.574797954807851e-05,
      "loss": 0.1003,
      "step": 1290
    },
    {
      "epoch": 0.6432459178624443,
      "grad_norm": 12.230384826660156,
      "learning_rate": 1.5714992577931718e-05,
      "loss": 0.05,
      "step": 1300
    },
    {
      "epoch": 0.6481939633844631,
      "grad_norm": 0.3030203878879547,
      "learning_rate": 1.5682005607784927e-05,
      "loss": 0.1441,
      "step": 1310
    },
    {
      "epoch": 0.6531420089064819,
      "grad_norm": 5.655834674835205,
      "learning_rate": 1.5649018637638134e-05,
      "loss": 0.0589,
      "step": 1320
    },
    {
      "epoch": 0.6580900544285008,
      "grad_norm": 0.7592865228652954,
      "learning_rate": 1.5616031667491343e-05,
      "loss": 0.0368,
      "step": 1330
    },
    {
      "epoch": 0.6630380999505195,
      "grad_norm": 0.022791415452957153,
      "learning_rate": 1.558304469734455e-05,
      "loss": 0.0691,
      "step": 1340
    },
    {
      "epoch": 0.6679861454725383,
      "grad_norm": 11.059638977050781,
      "learning_rate": 1.555005772719776e-05,
      "loss": 0.1827,
      "step": 1350
    },
    {
      "epoch": 0.6729341909945572,
      "grad_norm": 1.8564258813858032,
      "learning_rate": 1.5517070757050966e-05,
      "loss": 0.0029,
      "step": 1360
    },
    {
      "epoch": 0.677882236516576,
      "grad_norm": 0.01406863983720541,
      "learning_rate": 1.5484083786904175e-05,
      "loss": 0.0983,
      "step": 1370
    },
    {
      "epoch": 0.6828302820385947,
      "grad_norm": 0.07184905558824539,
      "learning_rate": 1.5451096816757382e-05,
      "loss": 0.0749,
      "step": 1380
    },
    {
      "epoch": 0.6877783275606135,
      "grad_norm": 0.01641121320426464,
      "learning_rate": 1.5418109846610588e-05,
      "loss": 0.0908,
      "step": 1390
    },
    {
      "epoch": 0.6927263730826324,
      "grad_norm": 0.030755706131458282,
      "learning_rate": 1.5385122876463798e-05,
      "loss": 0.0452,
      "step": 1400
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 0.01732504926621914,
      "learning_rate": 1.5352135906317004e-05,
      "loss": 0.0064,
      "step": 1410
    },
    {
      "epoch": 0.70262246412667,
      "grad_norm": 11.422159194946289,
      "learning_rate": 1.5319148936170214e-05,
      "loss": 0.1222,
      "step": 1420
    },
    {
      "epoch": 0.7075705096486887,
      "grad_norm": 0.12126472592353821,
      "learning_rate": 1.5286161966023424e-05,
      "loss": 0.0768,
      "step": 1430
    },
    {
      "epoch": 0.7125185551707076,
      "grad_norm": 0.05225427821278572,
      "learning_rate": 1.525317499587663e-05,
      "loss": 0.0012,
      "step": 1440
    },
    {
      "epoch": 0.7174666006927264,
      "grad_norm": 1.3010988235473633,
      "learning_rate": 1.5220188025729838e-05,
      "loss": 0.0103,
      "step": 1450
    },
    {
      "epoch": 0.7224146462147452,
      "grad_norm": 4.435579776763916,
      "learning_rate": 1.5187201055583046e-05,
      "loss": 0.0444,
      "step": 1460
    },
    {
      "epoch": 0.7273626917367639,
      "grad_norm": 0.9179107546806335,
      "learning_rate": 1.5154214085436254e-05,
      "loss": 0.0735,
      "step": 1470
    },
    {
      "epoch": 0.7323107372587828,
      "grad_norm": 0.042730893939733505,
      "learning_rate": 1.5121227115289464e-05,
      "loss": 0.1438,
      "step": 1480
    },
    {
      "epoch": 0.7372587827808016,
      "grad_norm": 0.036264143884181976,
      "learning_rate": 1.508824014514267e-05,
      "loss": 0.1257,
      "step": 1490
    },
    {
      "epoch": 0.7422068283028204,
      "grad_norm": 9.243889808654785,
      "learning_rate": 1.5055253174995878e-05,
      "loss": 0.0545,
      "step": 1500
    },
    {
      "epoch": 0.7471548738248391,
      "grad_norm": 0.03666732832789421,
      "learning_rate": 1.5022266204849086e-05,
      "loss": 0.0235,
      "step": 1510
    },
    {
      "epoch": 0.752102919346858,
      "grad_norm": 0.21956242620944977,
      "learning_rate": 1.4989279234702294e-05,
      "loss": 0.1495,
      "step": 1520
    },
    {
      "epoch": 0.7570509648688768,
      "grad_norm": 0.06111755967140198,
      "learning_rate": 1.49562922645555e-05,
      "loss": 0.0656,
      "step": 1530
    },
    {
      "epoch": 0.7619990103908956,
      "grad_norm": 0.05373174324631691,
      "learning_rate": 1.492330529440871e-05,
      "loss": 0.0382,
      "step": 1540
    },
    {
      "epoch": 0.7669470559129143,
      "grad_norm": 13.474030494689941,
      "learning_rate": 1.4890318324261918e-05,
      "loss": 0.0404,
      "step": 1550
    },
    {
      "epoch": 0.7718951014349332,
      "grad_norm": 0.13550087809562683,
      "learning_rate": 1.4857331354115126e-05,
      "loss": 0.041,
      "step": 1560
    },
    {
      "epoch": 0.776843146956952,
      "grad_norm": 4.350411415100098,
      "learning_rate": 1.4824344383968334e-05,
      "loss": 0.1222,
      "step": 1570
    },
    {
      "epoch": 0.7817911924789708,
      "grad_norm": 4.205056190490723,
      "learning_rate": 1.479135741382154e-05,
      "loss": 0.0731,
      "step": 1580
    },
    {
      "epoch": 0.7867392380009897,
      "grad_norm": 0.03845684602856636,
      "learning_rate": 1.475837044367475e-05,
      "loss": 0.0635,
      "step": 1590
    },
    {
      "epoch": 0.7916872835230084,
      "grad_norm": 0.23823289573192596,
      "learning_rate": 1.4725383473527957e-05,
      "loss": 0.071,
      "step": 1600
    },
    {
      "epoch": 0.7966353290450272,
      "grad_norm": 3.574568271636963,
      "learning_rate": 1.4692396503381166e-05,
      "loss": 0.0745,
      "step": 1610
    },
    {
      "epoch": 0.801583374567046,
      "grad_norm": 1.308376669883728,
      "learning_rate": 1.4659409533234374e-05,
      "loss": 0.0219,
      "step": 1620
    },
    {
      "epoch": 0.8065314200890649,
      "grad_norm": 0.09026946127414703,
      "learning_rate": 1.462642256308758e-05,
      "loss": 0.0737,
      "step": 1630
    },
    {
      "epoch": 0.8114794656110836,
      "grad_norm": 0.015685511752963066,
      "learning_rate": 1.459343559294079e-05,
      "loss": 0.0341,
      "step": 1640
    },
    {
      "epoch": 0.8164275111331024,
      "grad_norm": 0.058074548840522766,
      "learning_rate": 1.4560448622793997e-05,
      "loss": 0.0289,
      "step": 1650
    },
    {
      "epoch": 0.8213755566551212,
      "grad_norm": 19.68631935119629,
      "learning_rate": 1.4527461652647206e-05,
      "loss": 0.1245,
      "step": 1660
    },
    {
      "epoch": 0.8263236021771401,
      "grad_norm": 0.24659325182437897,
      "learning_rate": 1.4494474682500415e-05,
      "loss": 0.001,
      "step": 1670
    },
    {
      "epoch": 0.8312716476991588,
      "grad_norm": 21.865524291992188,
      "learning_rate": 1.4461487712353621e-05,
      "loss": 0.0423,
      "step": 1680
    },
    {
      "epoch": 0.8362196932211776,
      "grad_norm": 0.02970598265528679,
      "learning_rate": 1.442850074220683e-05,
      "loss": 0.0846,
      "step": 1690
    },
    {
      "epoch": 0.8411677387431964,
      "grad_norm": 0.17488545179367065,
      "learning_rate": 1.4395513772060037e-05,
      "loss": 0.0232,
      "step": 1700
    },
    {
      "epoch": 0.8461157842652153,
      "grad_norm": 0.3715421259403229,
      "learning_rate": 1.4362526801913247e-05,
      "loss": 0.0059,
      "step": 1710
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 15.703872680664062,
      "learning_rate": 1.4329539831766453e-05,
      "loss": 0.1831,
      "step": 1720
    },
    {
      "epoch": 0.8560118753092528,
      "grad_norm": 2.5397257804870605,
      "learning_rate": 1.4296552861619661e-05,
      "loss": 0.0442,
      "step": 1730
    },
    {
      "epoch": 0.8609599208312716,
      "grad_norm": 0.021135611459612846,
      "learning_rate": 1.426356589147287e-05,
      "loss": 0.1019,
      "step": 1740
    },
    {
      "epoch": 0.8659079663532905,
      "grad_norm": 0.11210115998983383,
      "learning_rate": 1.4230578921326077e-05,
      "loss": 0.0259,
      "step": 1750
    },
    {
      "epoch": 0.8708560118753093,
      "grad_norm": 0.037724819034338,
      "learning_rate": 1.4197591951179287e-05,
      "loss": 0.032,
      "step": 1760
    },
    {
      "epoch": 0.875804057397328,
      "grad_norm": 0.03906749188899994,
      "learning_rate": 1.4164604981032493e-05,
      "loss": 0.0666,
      "step": 1770
    },
    {
      "epoch": 0.8807521029193469,
      "grad_norm": 0.02217189408838749,
      "learning_rate": 1.4131618010885701e-05,
      "loss": 0.0378,
      "step": 1780
    },
    {
      "epoch": 0.8857001484413657,
      "grad_norm": 0.03314010053873062,
      "learning_rate": 1.4098631040738907e-05,
      "loss": 0.0257,
      "step": 1790
    },
    {
      "epoch": 0.8906481939633845,
      "grad_norm": 0.6820710897445679,
      "learning_rate": 1.4065644070592117e-05,
      "loss": 0.0897,
      "step": 1800
    },
    {
      "epoch": 0.8955962394854032,
      "grad_norm": 0.03534954413771629,
      "learning_rate": 1.4032657100445327e-05,
      "loss": 0.0241,
      "step": 1810
    },
    {
      "epoch": 0.9005442850074221,
      "grad_norm": 0.012813583016395569,
      "learning_rate": 1.3999670130298533e-05,
      "loss": 0.0535,
      "step": 1820
    },
    {
      "epoch": 0.9054923305294409,
      "grad_norm": 0.012768572196364403,
      "learning_rate": 1.3966683160151741e-05,
      "loss": 0.0649,
      "step": 1830
    },
    {
      "epoch": 0.9104403760514597,
      "grad_norm": 0.20296619832515717,
      "learning_rate": 1.3933696190004948e-05,
      "loss": 0.116,
      "step": 1840
    },
    {
      "epoch": 0.9153884215734784,
      "grad_norm": 0.01773061603307724,
      "learning_rate": 1.3900709219858157e-05,
      "loss": 0.0977,
      "step": 1850
    },
    {
      "epoch": 0.9203364670954973,
      "grad_norm": 4.96028470993042,
      "learning_rate": 1.3867722249711365e-05,
      "loss": 0.0744,
      "step": 1860
    },
    {
      "epoch": 0.9252845126175161,
      "grad_norm": 0.5198617577552795,
      "learning_rate": 1.3834735279564573e-05,
      "loss": 0.0994,
      "step": 1870
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 3.4126696586608887,
      "learning_rate": 1.3801748309417781e-05,
      "loss": 0.0046,
      "step": 1880
    },
    {
      "epoch": 0.9351806036615536,
      "grad_norm": 1.086695671081543,
      "learning_rate": 1.3768761339270988e-05,
      "loss": 0.0382,
      "step": 1890
    },
    {
      "epoch": 0.9401286491835725,
      "grad_norm": 11.169939041137695,
      "learning_rate": 1.3735774369124197e-05,
      "loss": 0.1054,
      "step": 1900
    },
    {
      "epoch": 0.9450766947055913,
      "grad_norm": 0.013259941712021828,
      "learning_rate": 1.3702787398977404e-05,
      "loss": 0.0057,
      "step": 1910
    },
    {
      "epoch": 0.9500247402276101,
      "grad_norm": 0.04192689061164856,
      "learning_rate": 1.3669800428830613e-05,
      "loss": 0.0177,
      "step": 1920
    },
    {
      "epoch": 0.9549727857496288,
      "grad_norm": 0.018220826983451843,
      "learning_rate": 1.3636813458683821e-05,
      "loss": 0.1118,
      "step": 1930
    },
    {
      "epoch": 0.9599208312716477,
      "grad_norm": 0.02413727343082428,
      "learning_rate": 1.3603826488537028e-05,
      "loss": 0.053,
      "step": 1940
    },
    {
      "epoch": 0.9648688767936665,
      "grad_norm": 0.029926756396889687,
      "learning_rate": 1.3570839518390238e-05,
      "loss": 0.1103,
      "step": 1950
    },
    {
      "epoch": 0.9698169223156853,
      "grad_norm": 0.10076188296079636,
      "learning_rate": 1.3537852548243444e-05,
      "loss": 0.0748,
      "step": 1960
    },
    {
      "epoch": 0.974764967837704,
      "grad_norm": 19.11438751220703,
      "learning_rate": 1.3504865578096654e-05,
      "loss": 0.0545,
      "step": 1970
    },
    {
      "epoch": 0.9797130133597229,
      "grad_norm": 6.635544776916504,
      "learning_rate": 1.347187860794986e-05,
      "loss": 0.1036,
      "step": 1980
    },
    {
      "epoch": 0.9846610588817417,
      "grad_norm": 0.031633876264095306,
      "learning_rate": 1.3438891637803068e-05,
      "loss": 0.023,
      "step": 1990
    },
    {
      "epoch": 0.9896091044037605,
      "grad_norm": 9.046653747558594,
      "learning_rate": 1.3405904667656278e-05,
      "loss": 0.0403,
      "step": 2000
    },
    {
      "epoch": 0.9945571499257794,
      "grad_norm": 0.02894374169409275,
      "learning_rate": 1.3372917697509484e-05,
      "loss": 0.0648,
      "step": 2010
    },
    {
      "epoch": 0.9995051954477981,
      "grad_norm": 0.010722910054028034,
      "learning_rate": 1.3339930727362694e-05,
      "loss": 0.018,
      "step": 2020
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9796770601336303,
      "eval_f1": 0.9788956345764672,
      "eval_loss": 0.08078765869140625,
      "eval_precision": 0.9696449026345934,
      "eval_recall": 0.9883245767659078,
      "eval_runtime": 177.9548,
      "eval_samples_per_second": 20.185,
      "eval_steps_per_second": 1.264,
      "step": 2021
    },
    {
      "epoch": 1.004453240969817,
      "grad_norm": 0.03666814789175987,
      "learning_rate": 1.33069437572159e-05,
      "loss": 0.001,
      "step": 2030
    },
    {
      "epoch": 1.0094012864918358,
      "grad_norm": 0.1033797338604927,
      "learning_rate": 1.3273956787069108e-05,
      "loss": 0.0876,
      "step": 2040
    },
    {
      "epoch": 1.0143493320138546,
      "grad_norm": 0.5100687146186829,
      "learning_rate": 1.3240969816922318e-05,
      "loss": 0.0016,
      "step": 2050
    },
    {
      "epoch": 1.0192973775358734,
      "grad_norm": 0.024813350290060043,
      "learning_rate": 1.3207982846775524e-05,
      "loss": 0.0024,
      "step": 2060
    },
    {
      "epoch": 1.0242454230578921,
      "grad_norm": 0.054303087294101715,
      "learning_rate": 1.3174995876628734e-05,
      "loss": 0.0505,
      "step": 2070
    },
    {
      "epoch": 1.029193468579911,
      "grad_norm": 0.02151850424706936,
      "learning_rate": 1.314200890648194e-05,
      "loss": 0.0167,
      "step": 2080
    },
    {
      "epoch": 1.0341415141019297,
      "grad_norm": 0.01498202420771122,
      "learning_rate": 1.3109021936335148e-05,
      "loss": 0.0169,
      "step": 2090
    },
    {
      "epoch": 1.0390895596239484,
      "grad_norm": 0.013668375089764595,
      "learning_rate": 1.3076034966188356e-05,
      "loss": 0.0996,
      "step": 2100
    },
    {
      "epoch": 1.0440376051459674,
      "grad_norm": 7.804310321807861,
      "learning_rate": 1.3043047996041564e-05,
      "loss": 0.088,
      "step": 2110
    },
    {
      "epoch": 1.0489856506679862,
      "grad_norm": 0.03168104216456413,
      "learning_rate": 1.3010061025894774e-05,
      "loss": 0.0485,
      "step": 2120
    },
    {
      "epoch": 1.053933696190005,
      "grad_norm": 0.01966012455523014,
      "learning_rate": 1.297707405574798e-05,
      "loss": 0.0288,
      "step": 2130
    },
    {
      "epoch": 1.0588817417120238,
      "grad_norm": 0.08541480451822281,
      "learning_rate": 1.2944087085601188e-05,
      "loss": 0.0706,
      "step": 2140
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 0.04191906750202179,
      "learning_rate": 1.2911100115454396e-05,
      "loss": 0.031,
      "step": 2150
    },
    {
      "epoch": 1.0687778327560613,
      "grad_norm": 0.012224886566400528,
      "learning_rate": 1.2878113145307604e-05,
      "loss": 0.0211,
      "step": 2160
    },
    {
      "epoch": 1.07372587827808,
      "grad_norm": 0.013992357067763805,
      "learning_rate": 1.2845126175160814e-05,
      "loss": 0.0525,
      "step": 2170
    },
    {
      "epoch": 1.0786739238000989,
      "grad_norm": 22.324195861816406,
      "learning_rate": 1.281213920501402e-05,
      "loss": 0.0583,
      "step": 2180
    },
    {
      "epoch": 1.0836219693221179,
      "grad_norm": 0.058257490396499634,
      "learning_rate": 1.2779152234867228e-05,
      "loss": 0.0078,
      "step": 2190
    },
    {
      "epoch": 1.0885700148441366,
      "grad_norm": 1.3647507429122925,
      "learning_rate": 1.2746165264720436e-05,
      "loss": 0.0296,
      "step": 2200
    },
    {
      "epoch": 1.0935180603661554,
      "grad_norm": 0.013789874501526356,
      "learning_rate": 1.2713178294573645e-05,
      "loss": 0.0248,
      "step": 2210
    },
    {
      "epoch": 1.0984661058881742,
      "grad_norm": 0.02287929318845272,
      "learning_rate": 1.2680191324426851e-05,
      "loss": 0.0277,
      "step": 2220
    },
    {
      "epoch": 1.103414151410193,
      "grad_norm": 0.0214847419410944,
      "learning_rate": 1.264720435428006e-05,
      "loss": 0.0546,
      "step": 2230
    },
    {
      "epoch": 1.1083621969322117,
      "grad_norm": 0.00833534449338913,
      "learning_rate": 1.2614217384133269e-05,
      "loss": 0.0505,
      "step": 2240
    },
    {
      "epoch": 1.1133102424542305,
      "grad_norm": 15.700078964233398,
      "learning_rate": 1.2581230413986477e-05,
      "loss": 0.0887,
      "step": 2250
    },
    {
      "epoch": 1.1182582879762495,
      "grad_norm": 0.05257398262619972,
      "learning_rate": 1.2548243443839685e-05,
      "loss": 0.0356,
      "step": 2260
    },
    {
      "epoch": 1.1232063334982683,
      "grad_norm": 6.80452299118042,
      "learning_rate": 1.2515256473692891e-05,
      "loss": 0.0135,
      "step": 2270
    },
    {
      "epoch": 1.128154379020287,
      "grad_norm": 29.85118293762207,
      "learning_rate": 1.24822695035461e-05,
      "loss": 0.0195,
      "step": 2280
    },
    {
      "epoch": 1.1331024245423058,
      "grad_norm": 0.07157333940267563,
      "learning_rate": 1.2449282533399307e-05,
      "loss": 0.0123,
      "step": 2290
    },
    {
      "epoch": 1.1380504700643246,
      "grad_norm": 0.011316250078380108,
      "learning_rate": 1.2416295563252517e-05,
      "loss": 0.0125,
      "step": 2300
    },
    {
      "epoch": 1.1429985155863434,
      "grad_norm": 0.0074044507928192616,
      "learning_rate": 1.2383308593105725e-05,
      "loss": 0.0391,
      "step": 2310
    },
    {
      "epoch": 1.1479465611083621,
      "grad_norm": 36.9918327331543,
      "learning_rate": 1.2350321622958931e-05,
      "loss": 0.0915,
      "step": 2320
    },
    {
      "epoch": 1.152894606630381,
      "grad_norm": 0.07637502998113632,
      "learning_rate": 1.231733465281214e-05,
      "loss": 0.0102,
      "step": 2330
    },
    {
      "epoch": 1.1578426521524,
      "grad_norm": 9.422124862670898,
      "learning_rate": 1.2284347682665347e-05,
      "loss": 0.0879,
      "step": 2340
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 0.043277278542518616,
      "learning_rate": 1.2251360712518557e-05,
      "loss": 0.0195,
      "step": 2350
    },
    {
      "epoch": 1.1677387431964374,
      "grad_norm": 0.014051000587642193,
      "learning_rate": 1.2218373742371765e-05,
      "loss": 0.0188,
      "step": 2360
    },
    {
      "epoch": 1.1726867887184562,
      "grad_norm": 4.978634834289551,
      "learning_rate": 1.2185386772224971e-05,
      "loss": 0.0029,
      "step": 2370
    },
    {
      "epoch": 1.177634834240475,
      "grad_norm": 0.040173497051000595,
      "learning_rate": 1.2152399802078181e-05,
      "loss": 0.001,
      "step": 2380
    },
    {
      "epoch": 1.1825828797624938,
      "grad_norm": 0.010152610950171947,
      "learning_rate": 1.2119412831931387e-05,
      "loss": 0.0038,
      "step": 2390
    },
    {
      "epoch": 1.1875309252845125,
      "grad_norm": 0.007014419883489609,
      "learning_rate": 1.2086425861784597e-05,
      "loss": 0.038,
      "step": 2400
    },
    {
      "epoch": 1.1924789708065315,
      "grad_norm": 6.724242687225342,
      "learning_rate": 1.2053438891637803e-05,
      "loss": 0.0159,
      "step": 2410
    },
    {
      "epoch": 1.1974270163285503,
      "grad_norm": 0.005857069510966539,
      "learning_rate": 1.2020451921491011e-05,
      "loss": 0.0371,
      "step": 2420
    },
    {
      "epoch": 1.202375061850569,
      "grad_norm": 0.013981127180159092,
      "learning_rate": 1.1987464951344221e-05,
      "loss": 0.0049,
      "step": 2430
    },
    {
      "epoch": 1.2073231073725879,
      "grad_norm": 0.015584176406264305,
      "learning_rate": 1.1954477981197427e-05,
      "loss": 0.0005,
      "step": 2440
    },
    {
      "epoch": 1.2122711528946066,
      "grad_norm": 0.045001570135354996,
      "learning_rate": 1.1921491011050637e-05,
      "loss": 0.0074,
      "step": 2450
    },
    {
      "epoch": 1.2172191984166254,
      "grad_norm": 25.112977981567383,
      "learning_rate": 1.1888504040903843e-05,
      "loss": 0.0113,
      "step": 2460
    },
    {
      "epoch": 1.2221672439386442,
      "grad_norm": 0.007736151572316885,
      "learning_rate": 1.1855517070757051e-05,
      "loss": 0.0188,
      "step": 2470
    },
    {
      "epoch": 1.227115289460663,
      "grad_norm": 5.440616607666016,
      "learning_rate": 1.182253010061026e-05,
      "loss": 0.0372,
      "step": 2480
    },
    {
      "epoch": 1.2320633349826817,
      "grad_norm": 0.010154436342418194,
      "learning_rate": 1.1789543130463468e-05,
      "loss": 0.035,
      "step": 2490
    },
    {
      "epoch": 1.2370113805047007,
      "grad_norm": 0.09873100370168686,
      "learning_rate": 1.1756556160316677e-05,
      "loss": 0.0353,
      "step": 2500
    },
    {
      "epoch": 1.2419594260267195,
      "grad_norm": 0.01580074056982994,
      "learning_rate": 1.1723569190169884e-05,
      "loss": 0.1238,
      "step": 2510
    },
    {
      "epoch": 1.2469074715487383,
      "grad_norm": 0.24190278351306915,
      "learning_rate": 1.1690582220023092e-05,
      "loss": 0.0017,
      "step": 2520
    },
    {
      "epoch": 1.251855517070757,
      "grad_norm": 16.196165084838867,
      "learning_rate": 1.16575952498763e-05,
      "loss": 0.0534,
      "step": 2530
    },
    {
      "epoch": 1.2568035625927758,
      "grad_norm": 0.016106177121400833,
      "learning_rate": 1.1624608279729508e-05,
      "loss": 0.0473,
      "step": 2540
    },
    {
      "epoch": 1.2617516081147946,
      "grad_norm": 0.015392680652439594,
      "learning_rate": 1.1591621309582717e-05,
      "loss": 0.0007,
      "step": 2550
    },
    {
      "epoch": 1.2666996536368136,
      "grad_norm": 0.07327626645565033,
      "learning_rate": 1.1558634339435924e-05,
      "loss": 0.0066,
      "step": 2560
    },
    {
      "epoch": 1.2716476991588324,
      "grad_norm": 0.0071744974702596664,
      "learning_rate": 1.1525647369289132e-05,
      "loss": 0.0209,
      "step": 2570
    },
    {
      "epoch": 1.2765957446808511,
      "grad_norm": 0.07732517272233963,
      "learning_rate": 1.149266039914234e-05,
      "loss": 0.0301,
      "step": 2580
    },
    {
      "epoch": 1.28154379020287,
      "grad_norm": 0.011520346626639366,
      "learning_rate": 1.1459673428995548e-05,
      "loss": 0.023,
      "step": 2590
    },
    {
      "epoch": 1.2864918357248887,
      "grad_norm": 16.55830192565918,
      "learning_rate": 1.1426686458848754e-05,
      "loss": 0.0402,
      "step": 2600
    },
    {
      "epoch": 1.2914398812469075,
      "grad_norm": 0.0367225743830204,
      "learning_rate": 1.1393699488701964e-05,
      "loss": 0.0022,
      "step": 2610
    },
    {
      "epoch": 1.2963879267689262,
      "grad_norm": 6.604392051696777,
      "learning_rate": 1.1360712518555172e-05,
      "loss": 0.0844,
      "step": 2620
    },
    {
      "epoch": 1.301335972290945,
      "grad_norm": 24.009441375732422,
      "learning_rate": 1.132772554840838e-05,
      "loss": 0.0197,
      "step": 2630
    },
    {
      "epoch": 1.3062840178129638,
      "grad_norm": 0.008250854909420013,
      "learning_rate": 1.1294738578261588e-05,
      "loss": 0.0015,
      "step": 2640
    },
    {
      "epoch": 1.3112320633349825,
      "grad_norm": 0.005403931252658367,
      "learning_rate": 1.1261751608114794e-05,
      "loss": 0.0031,
      "step": 2650
    },
    {
      "epoch": 1.3161801088570015,
      "grad_norm": 0.01974160224199295,
      "learning_rate": 1.1228764637968004e-05,
      "loss": 0.0012,
      "step": 2660
    },
    {
      "epoch": 1.3211281543790203,
      "grad_norm": 6.7506937980651855,
      "learning_rate": 1.119577766782121e-05,
      "loss": 0.0829,
      "step": 2670
    },
    {
      "epoch": 1.326076199901039,
      "grad_norm": 0.00753178121522069,
      "learning_rate": 1.116279069767442e-05,
      "loss": 0.0228,
      "step": 2680
    },
    {
      "epoch": 1.3310242454230579,
      "grad_norm": 28.35800552368164,
      "learning_rate": 1.1129803727527628e-05,
      "loss": 0.0792,
      "step": 2690
    },
    {
      "epoch": 1.3359722909450766,
      "grad_norm": 0.04140781983733177,
      "learning_rate": 1.1096816757380834e-05,
      "loss": 0.0007,
      "step": 2700
    },
    {
      "epoch": 1.3409203364670956,
      "grad_norm": 0.006482183933258057,
      "learning_rate": 1.1063829787234044e-05,
      "loss": 0.0007,
      "step": 2710
    },
    {
      "epoch": 1.3458683819891144,
      "grad_norm": 0.03146492689847946,
      "learning_rate": 1.103084281708725e-05,
      "loss": 0.0522,
      "step": 2720
    },
    {
      "epoch": 1.3508164275111332,
      "grad_norm": 0.02071508765220642,
      "learning_rate": 1.099785584694046e-05,
      "loss": 0.0682,
      "step": 2730
    },
    {
      "epoch": 1.355764473033152,
      "grad_norm": 0.014511290937662125,
      "learning_rate": 1.0964868876793668e-05,
      "loss": 0.0095,
      "step": 2740
    },
    {
      "epoch": 1.3607125185551707,
      "grad_norm": 10.541193008422852,
      "learning_rate": 1.0931881906646875e-05,
      "loss": 0.0309,
      "step": 2750
    },
    {
      "epoch": 1.3656605640771895,
      "grad_norm": 0.13435038924217224,
      "learning_rate": 1.0898894936500084e-05,
      "loss": 0.0312,
      "step": 2760
    },
    {
      "epoch": 1.3706086095992083,
      "grad_norm": 23.22443962097168,
      "learning_rate": 1.086590796635329e-05,
      "loss": 0.0638,
      "step": 2770
    },
    {
      "epoch": 1.375556655121227,
      "grad_norm": 0.008771920576691628,
      "learning_rate": 1.08329209962065e-05,
      "loss": 0.0411,
      "step": 2780
    },
    {
      "epoch": 1.3805047006432458,
      "grad_norm": 0.021610986441373825,
      "learning_rate": 1.0799934026059707e-05,
      "loss": 0.0182,
      "step": 2790
    },
    {
      "epoch": 1.3854527461652646,
      "grad_norm": 0.01100457925349474,
      "learning_rate": 1.0766947055912915e-05,
      "loss": 0.0221,
      "step": 2800
    },
    {
      "epoch": 1.3904007916872836,
      "grad_norm": 0.007084810175001621,
      "learning_rate": 1.0733960085766124e-05,
      "loss": 0.0455,
      "step": 2810
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 0.006107959896326065,
      "learning_rate": 1.070097311561933e-05,
      "loss": 0.0004,
      "step": 2820
    },
    {
      "epoch": 1.4002968827313211,
      "grad_norm": 0.012325859628617764,
      "learning_rate": 1.066798614547254e-05,
      "loss": 0.0662,
      "step": 2830
    },
    {
      "epoch": 1.40524492825334,
      "grad_norm": 0.020029524341225624,
      "learning_rate": 1.0634999175325747e-05,
      "loss": 0.0006,
      "step": 2840
    },
    {
      "epoch": 1.4101929737753587,
      "grad_norm": 0.0261476319283247,
      "learning_rate": 1.0602012205178955e-05,
      "loss": 0.0533,
      "step": 2850
    },
    {
      "epoch": 1.4151410192973775,
      "grad_norm": 24.135831832885742,
      "learning_rate": 1.0569025235032164e-05,
      "loss": 0.0309,
      "step": 2860
    },
    {
      "epoch": 1.4200890648193965,
      "grad_norm": 0.0943942442536354,
      "learning_rate": 1.053603826488537e-05,
      "loss": 0.0008,
      "step": 2870
    },
    {
      "epoch": 1.4250371103414152,
      "grad_norm": 2.7857162952423096,
      "learning_rate": 1.050305129473858e-05,
      "loss": 0.0362,
      "step": 2880
    },
    {
      "epoch": 1.429985155863434,
      "grad_norm": 0.011027824133634567,
      "learning_rate": 1.0470064324591787e-05,
      "loss": 0.0039,
      "step": 2890
    },
    {
      "epoch": 1.4349332013854528,
      "grad_norm": 6.543318748474121,
      "learning_rate": 1.0437077354444995e-05,
      "loss": 0.0378,
      "step": 2900
    },
    {
      "epoch": 1.4398812469074715,
      "grad_norm": 0.007737865671515465,
      "learning_rate": 1.0404090384298203e-05,
      "loss": 0.0897,
      "step": 2910
    },
    {
      "epoch": 1.4448292924294903,
      "grad_norm": 0.06362294405698776,
      "learning_rate": 1.0371103414151411e-05,
      "loss": 0.0277,
      "step": 2920
    },
    {
      "epoch": 1.449777337951509,
      "grad_norm": 0.027419665828347206,
      "learning_rate": 1.033811644400462e-05,
      "loss": 0.0363,
      "step": 2930
    },
    {
      "epoch": 1.4547253834735279,
      "grad_norm": 0.009364278987050056,
      "learning_rate": 1.0305129473857827e-05,
      "loss": 0.0017,
      "step": 2940
    },
    {
      "epoch": 1.4596734289955466,
      "grad_norm": 0.02894723042845726,
      "learning_rate": 1.0272142503711035e-05,
      "loss": 0.0689,
      "step": 2950
    },
    {
      "epoch": 1.4646214745175656,
      "grad_norm": 0.22872985899448395,
      "learning_rate": 1.0239155533564243e-05,
      "loss": 0.0016,
      "step": 2960
    },
    {
      "epoch": 1.4695695200395844,
      "grad_norm": 18.981563568115234,
      "learning_rate": 1.0206168563417451e-05,
      "loss": 0.0181,
      "step": 2970
    },
    {
      "epoch": 1.4745175655616032,
      "grad_norm": 10.5872220993042,
      "learning_rate": 1.0173181593270657e-05,
      "loss": 0.0186,
      "step": 2980
    },
    {
      "epoch": 1.479465611083622,
      "grad_norm": 0.054291002452373505,
      "learning_rate": 1.0140194623123867e-05,
      "loss": 0.0022,
      "step": 2990
    },
    {
      "epoch": 1.4844136566056407,
      "grad_norm": 0.012018779292702675,
      "learning_rate": 1.0107207652977075e-05,
      "loss": 0.0005,
      "step": 3000
    },
    {
      "epoch": 1.4893617021276595,
      "grad_norm": 0.06269412487745285,
      "learning_rate": 1.0074220682830283e-05,
      "loss": 0.0004,
      "step": 3010
    },
    {
      "epoch": 1.4943097476496785,
      "grad_norm": 0.004042445216327906,
      "learning_rate": 1.0041233712683491e-05,
      "loss": 0.0525,
      "step": 3020
    },
    {
      "epoch": 1.4992577931716973,
      "grad_norm": 0.018975773826241493,
      "learning_rate": 1.0008246742536698e-05,
      "loss": 0.0247,
      "step": 3030
    },
    {
      "epoch": 1.504205838693716,
      "grad_norm": 0.010897436179220676,
      "learning_rate": 9.975259772389907e-06,
      "loss": 0.0008,
      "step": 3040
    },
    {
      "epoch": 1.5091538842157348,
      "grad_norm": 0.0046326336450874805,
      "learning_rate": 9.942272802243115e-06,
      "loss": 0.0003,
      "step": 3050
    },
    {
      "epoch": 1.5141019297377536,
      "grad_norm": 0.012245386838912964,
      "learning_rate": 9.909285832096323e-06,
      "loss": 0.0202,
      "step": 3060
    },
    {
      "epoch": 1.5190499752597724,
      "grad_norm": 0.3625534176826477,
      "learning_rate": 9.87629886194953e-06,
      "loss": 0.0433,
      "step": 3070
    },
    {
      "epoch": 1.5239980207817911,
      "grad_norm": 0.003943112678825855,
      "learning_rate": 9.84331189180274e-06,
      "loss": 0.0006,
      "step": 3080
    },
    {
      "epoch": 1.52894606630381,
      "grad_norm": 0.005678342655301094,
      "learning_rate": 9.810324921655947e-06,
      "loss": 0.1175,
      "step": 3090
    },
    {
      "epoch": 1.5338941118258287,
      "grad_norm": 11.577986717224121,
      "learning_rate": 9.777337951509155e-06,
      "loss": 0.0567,
      "step": 3100
    },
    {
      "epoch": 1.5388421573478475,
      "grad_norm": 0.1379033476114273,
      "learning_rate": 9.744350981362363e-06,
      "loss": 0.0371,
      "step": 3110
    },
    {
      "epoch": 1.5437902028698665,
      "grad_norm": 0.04025011509656906,
      "learning_rate": 9.71136401121557e-06,
      "loss": 0.0016,
      "step": 3120
    },
    {
      "epoch": 1.5487382483918852,
      "grad_norm": 0.4979284703731537,
      "learning_rate": 9.678377041068778e-06,
      "loss": 0.0008,
      "step": 3130
    },
    {
      "epoch": 1.553686293913904,
      "grad_norm": 0.0037207389250397682,
      "learning_rate": 9.645390070921986e-06,
      "loss": 0.0714,
      "step": 3140
    },
    {
      "epoch": 1.5586343394359228,
      "grad_norm": 0.0035515367053449154,
      "learning_rate": 9.612403100775196e-06,
      "loss": 0.0015,
      "step": 3150
    },
    {
      "epoch": 1.5635823849579418,
      "grad_norm": 0.01500615756958723,
      "learning_rate": 9.579416130628404e-06,
      "loss": 0.0265,
      "step": 3160
    },
    {
      "epoch": 1.5685304304799605,
      "grad_norm": 0.03990001231431961,
      "learning_rate": 9.54642916048161e-06,
      "loss": 0.0241,
      "step": 3170
    },
    {
      "epoch": 1.5734784760019793,
      "grad_norm": 0.01519977580755949,
      "learning_rate": 9.513442190334818e-06,
      "loss": 0.0343,
      "step": 3180
    },
    {
      "epoch": 1.578426521523998,
      "grad_norm": 0.04252380505204201,
      "learning_rate": 9.480455220188026e-06,
      "loss": 0.0432,
      "step": 3190
    },
    {
      "epoch": 1.5833745670460169,
      "grad_norm": 0.027739819139242172,
      "learning_rate": 9.447468250041234e-06,
      "loss": 0.0259,
      "step": 3200
    },
    {
      "epoch": 1.5883226125680356,
      "grad_norm": 0.7119622826576233,
      "learning_rate": 9.414481279894444e-06,
      "loss": 0.0422,
      "step": 3210
    },
    {
      "epoch": 1.5932706580900544,
      "grad_norm": 0.009176445193588734,
      "learning_rate": 9.38149430974765e-06,
      "loss": 0.007,
      "step": 3220
    },
    {
      "epoch": 1.5982187036120732,
      "grad_norm": 0.029267290607094765,
      "learning_rate": 9.348507339600858e-06,
      "loss": 0.0192,
      "step": 3230
    },
    {
      "epoch": 1.603166749134092,
      "grad_norm": 0.03919142857193947,
      "learning_rate": 9.315520369454066e-06,
      "loss": 0.0052,
      "step": 3240
    },
    {
      "epoch": 1.6081147946561107,
      "grad_norm": 0.013373768888413906,
      "learning_rate": 9.282533399307274e-06,
      "loss": 0.0447,
      "step": 3250
    },
    {
      "epoch": 1.6130628401781295,
      "grad_norm": 0.007165670860558748,
      "learning_rate": 9.249546429160482e-06,
      "loss": 0.1264,
      "step": 3260
    },
    {
      "epoch": 1.6180108857001483,
      "grad_norm": 0.031128862872719765,
      "learning_rate": 9.21655945901369e-06,
      "loss": 0.0068,
      "step": 3270
    },
    {
      "epoch": 1.6229589312221673,
      "grad_norm": 0.0545368492603302,
      "learning_rate": 9.183572488866898e-06,
      "loss": 0.0159,
      "step": 3280
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 0.02729974500834942,
      "learning_rate": 9.150585518720106e-06,
      "loss": 0.0341,
      "step": 3290
    },
    {
      "epoch": 1.6328550222662048,
      "grad_norm": 0.011085924692451954,
      "learning_rate": 9.117598548573314e-06,
      "loss": 0.0087,
      "step": 3300
    },
    {
      "epoch": 1.6378030677882236,
      "grad_norm": 0.013864624314010143,
      "learning_rate": 9.084611578426522e-06,
      "loss": 0.0048,
      "step": 3310
    },
    {
      "epoch": 1.6427511133102426,
      "grad_norm": 0.026874905452132225,
      "learning_rate": 9.05162460827973e-06,
      "loss": 0.0633,
      "step": 3320
    },
    {
      "epoch": 1.6476991588322614,
      "grad_norm": 0.007826819084584713,
      "learning_rate": 9.018637638132938e-06,
      "loss": 0.0338,
      "step": 3330
    },
    {
      "epoch": 1.6526472043542801,
      "grad_norm": 0.40751057863235474,
      "learning_rate": 8.985650667986146e-06,
      "loss": 0.002,
      "step": 3340
    },
    {
      "epoch": 1.657595249876299,
      "grad_norm": 0.021191757172346115,
      "learning_rate": 8.952663697839354e-06,
      "loss": 0.0006,
      "step": 3350
    },
    {
      "epoch": 1.6625432953983177,
      "grad_norm": 0.052131686359643936,
      "learning_rate": 8.919676727692562e-06,
      "loss": 0.0392,
      "step": 3360
    },
    {
      "epoch": 1.6674913409203365,
      "grad_norm": 0.02477187290787697,
      "learning_rate": 8.88668975754577e-06,
      "loss": 0.001,
      "step": 3370
    },
    {
      "epoch": 1.6724393864423552,
      "grad_norm": 0.00810127891600132,
      "learning_rate": 8.853702787398978e-06,
      "loss": 0.0525,
      "step": 3380
    },
    {
      "epoch": 1.677387431964374,
      "grad_norm": 0.054788365960121155,
      "learning_rate": 8.820715817252186e-06,
      "loss": 0.0017,
      "step": 3390
    },
    {
      "epoch": 1.6823354774863928,
      "grad_norm": 5.561379909515381,
      "learning_rate": 8.787728847105394e-06,
      "loss": 0.028,
      "step": 3400
    },
    {
      "epoch": 1.6872835230084116,
      "grad_norm": 0.0126836858689785,
      "learning_rate": 8.754741876958603e-06,
      "loss": 0.0449,
      "step": 3410
    },
    {
      "epoch": 1.6922315685304303,
      "grad_norm": 0.019765423610806465,
      "learning_rate": 8.72175490681181e-06,
      "loss": 0.0359,
      "step": 3420
    },
    {
      "epoch": 1.6971796140524493,
      "grad_norm": 0.01800246722996235,
      "learning_rate": 8.688767936665019e-06,
      "loss": 0.0399,
      "step": 3430
    },
    {
      "epoch": 1.702127659574468,
      "grad_norm": 0.014041384682059288,
      "learning_rate": 8.655780966518225e-06,
      "loss": 0.005,
      "step": 3440
    },
    {
      "epoch": 1.7070757050964869,
      "grad_norm": 0.4837110638618469,
      "learning_rate": 8.622793996371433e-06,
      "loss": 0.0315,
      "step": 3450
    },
    {
      "epoch": 1.7120237506185056,
      "grad_norm": 0.006166455335915089,
      "learning_rate": 8.589807026224643e-06,
      "loss": 0.042,
      "step": 3460
    },
    {
      "epoch": 1.7169717961405246,
      "grad_norm": 0.0362619087100029,
      "learning_rate": 8.55682005607785e-06,
      "loss": 0.0414,
      "step": 3470
    },
    {
      "epoch": 1.7219198416625434,
      "grad_norm": 0.00517397653311491,
      "learning_rate": 8.523833085931059e-06,
      "loss": 0.0203,
      "step": 3480
    },
    {
      "epoch": 1.7268678871845622,
      "grad_norm": 0.01671973243355751,
      "learning_rate": 8.490846115784265e-06,
      "loss": 0.0243,
      "step": 3490
    },
    {
      "epoch": 1.731815932706581,
      "grad_norm": 0.06342405080795288,
      "learning_rate": 8.457859145637473e-06,
      "loss": 0.0908,
      "step": 3500
    },
    {
      "epoch": 1.7367639782285997,
      "grad_norm": 0.015172328799962997,
      "learning_rate": 8.424872175490681e-06,
      "loss": 0.0391,
      "step": 3510
    },
    {
      "epoch": 1.7417120237506185,
      "grad_norm": 0.3814590871334076,
      "learning_rate": 8.39188520534389e-06,
      "loss": 0.0322,
      "step": 3520
    },
    {
      "epoch": 1.7466600692726373,
      "grad_norm": 0.00695811165496707,
      "learning_rate": 8.358898235197099e-06,
      "loss": 0.0008,
      "step": 3530
    },
    {
      "epoch": 1.751608114794656,
      "grad_norm": 0.05707438662648201,
      "learning_rate": 8.325911265050305e-06,
      "loss": 0.0007,
      "step": 3540
    },
    {
      "epoch": 1.7565561603166748,
      "grad_norm": 6.248075008392334,
      "learning_rate": 8.292924294903513e-06,
      "loss": 0.0363,
      "step": 3550
    },
    {
      "epoch": 1.7615042058386936,
      "grad_norm": 25.869897842407227,
      "learning_rate": 8.259937324756721e-06,
      "loss": 0.0157,
      "step": 3560
    },
    {
      "epoch": 1.7664522513607124,
      "grad_norm": 0.0035779187455773354,
      "learning_rate": 8.22695035460993e-06,
      "loss": 0.0186,
      "step": 3570
    },
    {
      "epoch": 1.7714002968827314,
      "grad_norm": 0.07602275162935257,
      "learning_rate": 8.193963384463137e-06,
      "loss": 0.0164,
      "step": 3580
    },
    {
      "epoch": 1.7763483424047501,
      "grad_norm": 12.292678833007812,
      "learning_rate": 8.160976414316345e-06,
      "loss": 0.0493,
      "step": 3590
    },
    {
      "epoch": 1.781296387926769,
      "grad_norm": 0.007006868254393339,
      "learning_rate": 8.127989444169553e-06,
      "loss": 0.0432,
      "step": 3600
    },
    {
      "epoch": 1.7862444334487877,
      "grad_norm": 0.008165273815393448,
      "learning_rate": 8.095002474022761e-06,
      "loss": 0.0053,
      "step": 3610
    },
    {
      "epoch": 1.7911924789708067,
      "grad_norm": 0.010084825567901134,
      "learning_rate": 8.06201550387597e-06,
      "loss": 0.0005,
      "step": 3620
    },
    {
      "epoch": 1.7961405244928255,
      "grad_norm": 0.00842586811631918,
      "learning_rate": 8.029028533729177e-06,
      "loss": 0.0004,
      "step": 3630
    },
    {
      "epoch": 1.8010885700148442,
      "grad_norm": 0.007646196521818638,
      "learning_rate": 7.996041563582385e-06,
      "loss": 0.0448,
      "step": 3640
    },
    {
      "epoch": 1.806036615536863,
      "grad_norm": 0.010266706347465515,
      "learning_rate": 7.963054593435593e-06,
      "loss": 0.0358,
      "step": 3650
    },
    {
      "epoch": 1.8109846610588818,
      "grad_norm": 0.1010296642780304,
      "learning_rate": 7.930067623288801e-06,
      "loss": 0.036,
      "step": 3660
    },
    {
      "epoch": 1.8159327065809006,
      "grad_norm": 0.11074648797512054,
      "learning_rate": 7.89708065314201e-06,
      "loss": 0.0438,
      "step": 3670
    },
    {
      "epoch": 1.8208807521029193,
      "grad_norm": 0.005548635497689247,
      "learning_rate": 7.864093682995218e-06,
      "loss": 0.0003,
      "step": 3680
    },
    {
      "epoch": 1.825828797624938,
      "grad_norm": 0.005831524264067411,
      "learning_rate": 7.831106712848426e-06,
      "loss": 0.0158,
      "step": 3690
    },
    {
      "epoch": 1.8307768431469569,
      "grad_norm": 0.004487977363169193,
      "learning_rate": 7.798119742701634e-06,
      "loss": 0.084,
      "step": 3700
    },
    {
      "epoch": 1.8357248886689757,
      "grad_norm": 0.03560226410627365,
      "learning_rate": 7.765132772554842e-06,
      "loss": 0.0007,
      "step": 3710
    },
    {
      "epoch": 1.8406729341909944,
      "grad_norm": 0.49525684118270874,
      "learning_rate": 7.73214580240805e-06,
      "loss": 0.0392,
      "step": 3720
    },
    {
      "epoch": 1.8456209797130132,
      "grad_norm": 0.013986232690513134,
      "learning_rate": 7.699158832261258e-06,
      "loss": 0.0359,
      "step": 3730
    },
    {
      "epoch": 1.8505690252350322,
      "grad_norm": 0.002906743437051773,
      "learning_rate": 7.666171862114466e-06,
      "loss": 0.0004,
      "step": 3740
    },
    {
      "epoch": 1.855517070757051,
      "grad_norm": 0.004092598799616098,
      "learning_rate": 7.633184891967674e-06,
      "loss": 0.0232,
      "step": 3750
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 0.029369333758950233,
      "learning_rate": 7.600197921820881e-06,
      "loss": 0.0004,
      "step": 3760
    },
    {
      "epoch": 1.8654131618010885,
      "grad_norm": 0.009330643340945244,
      "learning_rate": 7.567210951674089e-06,
      "loss": 0.0003,
      "step": 3770
    },
    {
      "epoch": 1.8703612073231075,
      "grad_norm": 0.007097158115357161,
      "learning_rate": 7.534223981527298e-06,
      "loss": 0.0014,
      "step": 3780
    },
    {
      "epoch": 1.8753092528451263,
      "grad_norm": 0.015100574120879173,
      "learning_rate": 7.501237011380506e-06,
      "loss": 0.0348,
      "step": 3790
    },
    {
      "epoch": 1.880257298367145,
      "grad_norm": 3.703728675842285,
      "learning_rate": 7.468250041233713e-06,
      "loss": 0.0767,
      "step": 3800
    },
    {
      "epoch": 1.8852053438891638,
      "grad_norm": 0.061271123588085175,
      "learning_rate": 7.435263071086921e-06,
      "loss": 0.0477,
      "step": 3810
    },
    {
      "epoch": 1.8901533894111826,
      "grad_norm": 5.990945339202881,
      "learning_rate": 7.402276100940129e-06,
      "loss": 0.0623,
      "step": 3820
    },
    {
      "epoch": 1.8951014349332014,
      "grad_norm": 0.003692222060635686,
      "learning_rate": 7.369289130793337e-06,
      "loss": 0.0006,
      "step": 3830
    },
    {
      "epoch": 1.9000494804552202,
      "grad_norm": 0.02694610506296158,
      "learning_rate": 7.336302160646546e-06,
      "loss": 0.0556,
      "step": 3840
    },
    {
      "epoch": 1.904997525977239,
      "grad_norm": 3.6279897689819336,
      "learning_rate": 7.303315190499753e-06,
      "loss": 0.052,
      "step": 3850
    },
    {
      "epoch": 1.9099455714992577,
      "grad_norm": 0.09477703273296356,
      "learning_rate": 7.270328220352961e-06,
      "loss": 0.0005,
      "step": 3860
    },
    {
      "epoch": 1.9148936170212765,
      "grad_norm": 0.05096007511019707,
      "learning_rate": 7.237341250206169e-06,
      "loss": 0.0434,
      "step": 3870
    },
    {
      "epoch": 1.9198416625432952,
      "grad_norm": 0.014571033418178558,
      "learning_rate": 7.204354280059377e-06,
      "loss": 0.0039,
      "step": 3880
    },
    {
      "epoch": 1.9247897080653142,
      "grad_norm": 7.116293430328369,
      "learning_rate": 7.171367309912584e-06,
      "loss": 0.0372,
      "step": 3890
    },
    {
      "epoch": 1.929737753587333,
      "grad_norm": 0.8212539553642273,
      "learning_rate": 7.138380339765793e-06,
      "loss": 0.001,
      "step": 3900
    },
    {
      "epoch": 1.9346857991093518,
      "grad_norm": 27.64038848876953,
      "learning_rate": 7.105393369619001e-06,
      "loss": 0.007,
      "step": 3910
    },
    {
      "epoch": 1.9396338446313706,
      "grad_norm": 0.017232894897460938,
      "learning_rate": 7.072406399472209e-06,
      "loss": 0.0675,
      "step": 3920
    },
    {
      "epoch": 1.9445818901533896,
      "grad_norm": 0.018140103667974472,
      "learning_rate": 7.039419429325417e-06,
      "loss": 0.0004,
      "step": 3930
    },
    {
      "epoch": 1.9495299356754083,
      "grad_norm": 0.016247550025582314,
      "learning_rate": 7.0064324591786245e-06,
      "loss": 0.048,
      "step": 3940
    },
    {
      "epoch": 1.954477981197427,
      "grad_norm": 7.350187301635742,
      "learning_rate": 6.9734454890318325e-06,
      "loss": 0.0398,
      "step": 3950
    },
    {
      "epoch": 1.9594260267194459,
      "grad_norm": 0.012748106382787228,
      "learning_rate": 6.940458518885041e-06,
      "loss": 0.0013,
      "step": 3960
    },
    {
      "epoch": 1.9643740722414647,
      "grad_norm": 0.0030664829537272453,
      "learning_rate": 6.907471548738249e-06,
      "loss": 0.0003,
      "step": 3970
    },
    {
      "epoch": 1.9693221177634834,
      "grad_norm": 0.722181499004364,
      "learning_rate": 6.8744845785914574e-06,
      "loss": 0.0005,
      "step": 3980
    },
    {
      "epoch": 1.9742701632855022,
      "grad_norm": 0.7054228782653809,
      "learning_rate": 6.841497608444665e-06,
      "loss": 0.002,
      "step": 3990
    },
    {
      "epoch": 1.979218208807521,
      "grad_norm": 0.033851075917482376,
      "learning_rate": 6.808510638297873e-06,
      "loss": 0.0173,
      "step": 4000
    },
    {
      "epoch": 1.9841662543295397,
      "grad_norm": 0.002102657686918974,
      "learning_rate": 6.775523668151081e-06,
      "loss": 0.0006,
      "step": 4010
    },
    {
      "epoch": 1.9891142998515585,
      "grad_norm": 0.005957062356173992,
      "learning_rate": 6.742536698004289e-06,
      "loss": 0.0328,
      "step": 4020
    },
    {
      "epoch": 1.9940623453735773,
      "grad_norm": 0.13474895060062408,
      "learning_rate": 6.7095497278574976e-06,
      "loss": 0.0465,
      "step": 4030
    },
    {
      "epoch": 1.9990103908955963,
      "grad_norm": 0.0016277660615742207,
      "learning_rate": 6.676562757710705e-06,
      "loss": 0.0143,
      "step": 4040
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9824610244988864,
      "eval_f1": 0.9816272965879265,
      "eval_loss": 0.08680925518274307,
      "eval_precision": 0.9807692307692307,
      "eval_recall": 0.9824868651488616,
      "eval_runtime": 179.5523,
      "eval_samples_per_second": 20.005,
      "eval_steps_per_second": 1.253,
      "step": 4042
    },
    {
      "epoch": 2.003958436417615,
      "grad_norm": 0.01351602841168642,
      "learning_rate": 6.643575787563913e-06,
      "loss": 0.002,
      "step": 4050
    },
    {
      "epoch": 2.008906481939634,
      "grad_norm": 3.6719350814819336,
      "learning_rate": 6.610588817417121e-06,
      "loss": 0.0014,
      "step": 4060
    },
    {
      "epoch": 2.013854527461653,
      "grad_norm": 0.004929321352392435,
      "learning_rate": 6.577601847270329e-06,
      "loss": 0.0002,
      "step": 4070
    },
    {
      "epoch": 2.0188025729836716,
      "grad_norm": 0.004917253740131855,
      "learning_rate": 6.544614877123536e-06,
      "loss": 0.0003,
      "step": 4080
    },
    {
      "epoch": 2.0237506185056904,
      "grad_norm": 0.015419934876263142,
      "learning_rate": 6.511627906976745e-06,
      "loss": 0.0334,
      "step": 4090
    },
    {
      "epoch": 2.028698664027709,
      "grad_norm": 0.0019502502400428057,
      "learning_rate": 6.478640936829953e-06,
      "loss": 0.0003,
      "step": 4100
    },
    {
      "epoch": 2.033646709549728,
      "grad_norm": 0.13238799571990967,
      "learning_rate": 6.445653966683161e-06,
      "loss": 0.0003,
      "step": 4110
    },
    {
      "epoch": 2.0385947550717467,
      "grad_norm": 0.026311131194233894,
      "learning_rate": 6.412666996536369e-06,
      "loss": 0.0007,
      "step": 4120
    },
    {
      "epoch": 2.0435428005937655,
      "grad_norm": 0.036085065454244614,
      "learning_rate": 6.379680026389576e-06,
      "loss": 0.0003,
      "step": 4130
    },
    {
      "epoch": 2.0484908461157842,
      "grad_norm": 0.004194773267954588,
      "learning_rate": 6.346693056242784e-06,
      "loss": 0.0003,
      "step": 4140
    },
    {
      "epoch": 2.053438891637803,
      "grad_norm": 0.004128331784158945,
      "learning_rate": 6.313706086095993e-06,
      "loss": 0.0004,
      "step": 4150
    },
    {
      "epoch": 2.058386937159822,
      "grad_norm": 0.0044623129069805145,
      "learning_rate": 6.280719115949201e-06,
      "loss": 0.0001,
      "step": 4160
    },
    {
      "epoch": 2.0633349826818406,
      "grad_norm": 0.0030897052492946386,
      "learning_rate": 6.247732145802409e-06,
      "loss": 0.0003,
      "step": 4170
    },
    {
      "epoch": 2.0682830282038593,
      "grad_norm": 0.004432178568094969,
      "learning_rate": 6.214745175655616e-06,
      "loss": 0.0543,
      "step": 4180
    },
    {
      "epoch": 2.073231073725878,
      "grad_norm": 0.0054119788110256195,
      "learning_rate": 6.181758205508824e-06,
      "loss": 0.0021,
      "step": 4190
    },
    {
      "epoch": 2.078179119247897,
      "grad_norm": 0.002704002195969224,
      "learning_rate": 6.148771235362032e-06,
      "loss": 0.0002,
      "step": 4200
    },
    {
      "epoch": 2.083127164769916,
      "grad_norm": 0.007471583317965269,
      "learning_rate": 6.11578426521524e-06,
      "loss": 0.0018,
      "step": 4210
    },
    {
      "epoch": 2.088075210291935,
      "grad_norm": 0.009237687103450298,
      "learning_rate": 6.082797295068449e-06,
      "loss": 0.0024,
      "step": 4220
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 0.004300485830754042,
      "learning_rate": 6.049810324921656e-06,
      "loss": 0.0002,
      "step": 4230
    },
    {
      "epoch": 2.0979713013359724,
      "grad_norm": 0.007319197058677673,
      "learning_rate": 6.016823354774864e-06,
      "loss": 0.0002,
      "step": 4240
    },
    {
      "epoch": 2.102919346857991,
      "grad_norm": 0.004904646892100573,
      "learning_rate": 5.9838363846280724e-06,
      "loss": 0.0002,
      "step": 4250
    },
    {
      "epoch": 2.10786739238001,
      "grad_norm": 0.013267798349261284,
      "learning_rate": 5.9508494144812805e-06,
      "loss": 0.0002,
      "step": 4260
    },
    {
      "epoch": 2.1128154379020287,
      "grad_norm": 0.013790003024041653,
      "learning_rate": 5.917862444334488e-06,
      "loss": 0.0002,
      "step": 4270
    },
    {
      "epoch": 2.1177634834240475,
      "grad_norm": 0.0019451534608379006,
      "learning_rate": 5.8848754741876965e-06,
      "loss": 0.0039,
      "step": 4280
    },
    {
      "epoch": 2.1227115289460663,
      "grad_norm": 0.0011693532578647137,
      "learning_rate": 5.8518885040409045e-06,
      "loss": 0.0003,
      "step": 4290
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 0.002211399143561721,
      "learning_rate": 5.8189015338941126e-06,
      "loss": 0.0004,
      "step": 4300
    },
    {
      "epoch": 2.132607619990104,
      "grad_norm": 46.28287887573242,
      "learning_rate": 5.785914563747321e-06,
      "loss": 0.0181,
      "step": 4310
    },
    {
      "epoch": 2.1375556655121226,
      "grad_norm": 17.652889251708984,
      "learning_rate": 5.752927593600528e-06,
      "loss": 0.0048,
      "step": 4320
    },
    {
      "epoch": 2.1425037110341414,
      "grad_norm": 0.002271536737680435,
      "learning_rate": 5.719940623453736e-06,
      "loss": 0.0001,
      "step": 4330
    },
    {
      "epoch": 2.14745175655616,
      "grad_norm": 0.004437596071511507,
      "learning_rate": 5.686953653306945e-06,
      "loss": 0.0001,
      "step": 4340
    },
    {
      "epoch": 2.152399802078179,
      "grad_norm": 10.926047325134277,
      "learning_rate": 5.653966683160153e-06,
      "loss": 0.0287,
      "step": 4350
    },
    {
      "epoch": 2.1573478476001977,
      "grad_norm": 0.0028960583731532097,
      "learning_rate": 5.620979713013361e-06,
      "loss": 0.0356,
      "step": 4360
    },
    {
      "epoch": 2.162295893122217,
      "grad_norm": 0.49639928340911865,
      "learning_rate": 5.587992742866568e-06,
      "loss": 0.0002,
      "step": 4370
    },
    {
      "epoch": 2.1672439386442357,
      "grad_norm": 0.001960741588845849,
      "learning_rate": 5.555005772719776e-06,
      "loss": 0.0001,
      "step": 4380
    },
    {
      "epoch": 2.1721919841662545,
      "grad_norm": 0.0036481982097029686,
      "learning_rate": 5.522018802572984e-06,
      "loss": 0.0001,
      "step": 4390
    },
    {
      "epoch": 2.1771400296882732,
      "grad_norm": 0.00601158058270812,
      "learning_rate": 5.489031832426193e-06,
      "loss": 0.0001,
      "step": 4400
    },
    {
      "epoch": 2.182088075210292,
      "grad_norm": 0.019852012395858765,
      "learning_rate": 5.456044862279401e-06,
      "loss": 0.0002,
      "step": 4410
    },
    {
      "epoch": 2.187036120732311,
      "grad_norm": 0.02943561039865017,
      "learning_rate": 5.423057892132608e-06,
      "loss": 0.0246,
      "step": 4420
    },
    {
      "epoch": 2.1919841662543296,
      "grad_norm": 0.009593152441084385,
      "learning_rate": 5.390070921985816e-06,
      "loss": 0.0001,
      "step": 4430
    },
    {
      "epoch": 2.1969322117763483,
      "grad_norm": 0.0021481579169631004,
      "learning_rate": 5.357083951839024e-06,
      "loss": 0.0001,
      "step": 4440
    },
    {
      "epoch": 2.201880257298367,
      "grad_norm": 0.026334363967180252,
      "learning_rate": 5.324096981692231e-06,
      "loss": 0.0002,
      "step": 4450
    },
    {
      "epoch": 2.206828302820386,
      "grad_norm": 0.002670216141268611,
      "learning_rate": 5.291110011545439e-06,
      "loss": 0.0062,
      "step": 4460
    },
    {
      "epoch": 2.2117763483424047,
      "grad_norm": 0.0021432251669466496,
      "learning_rate": 5.258123041398648e-06,
      "loss": 0.0009,
      "step": 4470
    },
    {
      "epoch": 2.2167243938644234,
      "grad_norm": 0.0029445861000567675,
      "learning_rate": 5.225136071251856e-06,
      "loss": 0.0001,
      "step": 4480
    },
    {
      "epoch": 2.221672439386442,
      "grad_norm": 0.0012175028678029776,
      "learning_rate": 5.192149101105064e-06,
      "loss": 0.045,
      "step": 4490
    },
    {
      "epoch": 2.226620484908461,
      "grad_norm": 0.01314514223486185,
      "learning_rate": 5.159162130958271e-06,
      "loss": 0.0026,
      "step": 4500
    },
    {
      "epoch": 2.2315685304304798,
      "grad_norm": 0.004103405401110649,
      "learning_rate": 5.126175160811479e-06,
      "loss": 0.0002,
      "step": 4510
    },
    {
      "epoch": 2.236516575952499,
      "grad_norm": 0.005845348816365004,
      "learning_rate": 5.0931881906646874e-06,
      "loss": 0.0295,
      "step": 4520
    },
    {
      "epoch": 2.2414646214745177,
      "grad_norm": 0.04150300472974777,
      "learning_rate": 5.060201220517896e-06,
      "loss": 0.0008,
      "step": 4530
    },
    {
      "epoch": 2.2464126669965365,
      "grad_norm": 0.13588480651378632,
      "learning_rate": 5.027214250371104e-06,
      "loss": 0.0003,
      "step": 4540
    },
    {
      "epoch": 2.2513607125185553,
      "grad_norm": 1.8727428913116455,
      "learning_rate": 4.9942272802243115e-06,
      "loss": 0.0671,
      "step": 4550
    },
    {
      "epoch": 2.256308758040574,
      "grad_norm": 0.0021279880311340094,
      "learning_rate": 4.9612403100775195e-06,
      "loss": 0.0001,
      "step": 4560
    },
    {
      "epoch": 2.261256803562593,
      "grad_norm": 0.0014481705147773027,
      "learning_rate": 4.9282533399307276e-06,
      "loss": 0.0001,
      "step": 4570
    },
    {
      "epoch": 2.2662048490846116,
      "grad_norm": 0.004608985036611557,
      "learning_rate": 4.895266369783936e-06,
      "loss": 0.0188,
      "step": 4580
    },
    {
      "epoch": 2.2711528946066304,
      "grad_norm": 0.007127012591809034,
      "learning_rate": 4.862279399637144e-06,
      "loss": 0.0024,
      "step": 4590
    },
    {
      "epoch": 2.276100940128649,
      "grad_norm": 0.006366201676428318,
      "learning_rate": 4.829292429490352e-06,
      "loss": 0.0009,
      "step": 4600
    },
    {
      "epoch": 2.281048985650668,
      "grad_norm": 0.005156997125595808,
      "learning_rate": 4.79630545934356e-06,
      "loss": 0.0003,
      "step": 4610
    },
    {
      "epoch": 2.2859970311726867,
      "grad_norm": 0.005614394322037697,
      "learning_rate": 4.763318489196768e-06,
      "loss": 0.0002,
      "step": 4620
    },
    {
      "epoch": 2.2909450766947055,
      "grad_norm": 0.0016416936414316297,
      "learning_rate": 4.730331519049976e-06,
      "loss": 0.0303,
      "step": 4630
    },
    {
      "epoch": 2.2958931222167243,
      "grad_norm": 0.0029577245004475117,
      "learning_rate": 4.697344548903184e-06,
      "loss": 0.0002,
      "step": 4640
    },
    {
      "epoch": 2.300841167738743,
      "grad_norm": 0.005743753165006638,
      "learning_rate": 4.664357578756392e-06,
      "loss": 0.0345,
      "step": 4650
    },
    {
      "epoch": 2.305789213260762,
      "grad_norm": 0.004077433608472347,
      "learning_rate": 4.6313706086096e-06,
      "loss": 0.0001,
      "step": 4660
    },
    {
      "epoch": 2.3107372587827806,
      "grad_norm": 0.00983007624745369,
      "learning_rate": 4.598383638462808e-06,
      "loss": 0.0253,
      "step": 4670
    },
    {
      "epoch": 2.3156853043048,
      "grad_norm": 0.015230049379169941,
      "learning_rate": 4.565396668316016e-06,
      "loss": 0.0002,
      "step": 4680
    },
    {
      "epoch": 2.3206333498268186,
      "grad_norm": 0.0024304953403770924,
      "learning_rate": 4.532409698169223e-06,
      "loss": 0.0003,
      "step": 4690
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 0.0026129139587283134,
      "learning_rate": 4.499422728022432e-06,
      "loss": 0.0002,
      "step": 4700
    },
    {
      "epoch": 2.330529440870856,
      "grad_norm": 0.005281013902276754,
      "learning_rate": 4.46643575787564e-06,
      "loss": 0.0001,
      "step": 4710
    },
    {
      "epoch": 2.335477486392875,
      "grad_norm": 0.003511981340125203,
      "learning_rate": 4.433448787728847e-06,
      "loss": 0.0001,
      "step": 4720
    },
    {
      "epoch": 2.3404255319148937,
      "grad_norm": 0.0020302068442106247,
      "learning_rate": 4.400461817582056e-06,
      "loss": 0.0001,
      "step": 4730
    },
    {
      "epoch": 2.3453735774369124,
      "grad_norm": 0.00576286856085062,
      "learning_rate": 4.367474847435263e-06,
      "loss": 0.0003,
      "step": 4740
    },
    {
      "epoch": 2.350321622958931,
      "grad_norm": 0.008695372380316257,
      "learning_rate": 4.334487877288471e-06,
      "loss": 0.0011,
      "step": 4750
    },
    {
      "epoch": 2.35526966848095,
      "grad_norm": 0.0017747282981872559,
      "learning_rate": 4.301500907141679e-06,
      "loss": 0.0003,
      "step": 4760
    },
    {
      "epoch": 2.3602177140029688,
      "grad_norm": 0.002633430063724518,
      "learning_rate": 4.268513936994887e-06,
      "loss": 0.0117,
      "step": 4770
    },
    {
      "epoch": 2.3651657595249875,
      "grad_norm": 0.003147283336147666,
      "learning_rate": 4.235526966848095e-06,
      "loss": 0.0002,
      "step": 4780
    },
    {
      "epoch": 2.3701138050470063,
      "grad_norm": 0.0037363118026405573,
      "learning_rate": 4.202539996701303e-06,
      "loss": 0.0001,
      "step": 4790
    },
    {
      "epoch": 2.375061850569025,
      "grad_norm": 0.1831626147031784,
      "learning_rate": 4.169553026554511e-06,
      "loss": 0.0002,
      "step": 4800
    },
    {
      "epoch": 2.380009896091044,
      "grad_norm": 0.002630019560456276,
      "learning_rate": 4.136566056407719e-06,
      "loss": 0.0001,
      "step": 4810
    },
    {
      "epoch": 2.384957941613063,
      "grad_norm": 0.01875361241400242,
      "learning_rate": 4.103579086260927e-06,
      "loss": 0.0001,
      "step": 4820
    },
    {
      "epoch": 2.389905987135082,
      "grad_norm": 0.08698087185621262,
      "learning_rate": 4.070592116114135e-06,
      "loss": 0.0727,
      "step": 4830
    },
    {
      "epoch": 2.3948540326571006,
      "grad_norm": 0.004000427201390266,
      "learning_rate": 4.037605145967343e-06,
      "loss": 0.0001,
      "step": 4840
    },
    {
      "epoch": 2.3998020781791194,
      "grad_norm": 0.023847997188568115,
      "learning_rate": 4.004618175820551e-06,
      "loss": 0.0001,
      "step": 4850
    },
    {
      "epoch": 2.404750123701138,
      "grad_norm": 0.02525121532380581,
      "learning_rate": 3.9716312056737595e-06,
      "loss": 0.0002,
      "step": 4860
    },
    {
      "epoch": 2.409698169223157,
      "grad_norm": 0.017693230882287025,
      "learning_rate": 3.9386442355269675e-06,
      "loss": 0.0003,
      "step": 4870
    },
    {
      "epoch": 2.4146462147451757,
      "grad_norm": 0.013050897978246212,
      "learning_rate": 3.905657265380175e-06,
      "loss": 0.0001,
      "step": 4880
    },
    {
      "epoch": 2.4195942602671945,
      "grad_norm": 0.0016915793530642986,
      "learning_rate": 3.8726702952333835e-06,
      "loss": 0.0002,
      "step": 4890
    },
    {
      "epoch": 2.4245423057892133,
      "grad_norm": 0.0032368048559874296,
      "learning_rate": 3.839683325086591e-06,
      "loss": 0.0002,
      "step": 4900
    },
    {
      "epoch": 2.429490351311232,
      "grad_norm": 0.002021042862907052,
      "learning_rate": 3.8066963549397987e-06,
      "loss": 0.0002,
      "step": 4910
    },
    {
      "epoch": 2.434438396833251,
      "grad_norm": 0.010837748646736145,
      "learning_rate": 3.773709384793007e-06,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 2.4393864423552696,
      "grad_norm": 0.007761740125715733,
      "learning_rate": 3.7407224146462152e-06,
      "loss": 0.0001,
      "step": 4930
    },
    {
      "epoch": 2.4443344878772884,
      "grad_norm": 0.011065281927585602,
      "learning_rate": 3.707735444499423e-06,
      "loss": 0.0002,
      "step": 4940
    },
    {
      "epoch": 2.449282533399307,
      "grad_norm": 0.003983821254223585,
      "learning_rate": 3.6747484743526313e-06,
      "loss": 0.017,
      "step": 4950
    },
    {
      "epoch": 2.454230578921326,
      "grad_norm": 0.0025419355370104313,
      "learning_rate": 3.641761504205839e-06,
      "loss": 0.0003,
      "step": 4960
    },
    {
      "epoch": 2.4591786244433447,
      "grad_norm": 0.002913529286161065,
      "learning_rate": 3.608774534059047e-06,
      "loss": 0.0674,
      "step": 4970
    },
    {
      "epoch": 2.4641266699653634,
      "grad_norm": 0.1870151311159134,
      "learning_rate": 3.5757875639122545e-06,
      "loss": 0.0002,
      "step": 4980
    },
    {
      "epoch": 2.4690747154873827,
      "grad_norm": 0.001757357851602137,
      "learning_rate": 3.542800593765463e-06,
      "loss": 0.0392,
      "step": 4990
    },
    {
      "epoch": 2.4740227610094014,
      "grad_norm": 0.00264545576646924,
      "learning_rate": 3.509813623618671e-06,
      "loss": 0.0418,
      "step": 5000
    },
    {
      "epoch": 2.47897080653142,
      "grad_norm": 0.00244870875030756,
      "learning_rate": 3.4768266534718786e-06,
      "loss": 0.0001,
      "step": 5010
    },
    {
      "epoch": 2.483918852053439,
      "grad_norm": 0.0064508249051868916,
      "learning_rate": 3.443839683325087e-06,
      "loss": 0.0002,
      "step": 5020
    },
    {
      "epoch": 2.4888668975754578,
      "grad_norm": 0.0017021491657942533,
      "learning_rate": 3.4108527131782946e-06,
      "loss": 0.0001,
      "step": 5030
    },
    {
      "epoch": 2.4938149430974765,
      "grad_norm": 0.0015442928997799754,
      "learning_rate": 3.3778657430315027e-06,
      "loss": 0.0002,
      "step": 5040
    },
    {
      "epoch": 2.4987629886194953,
      "grad_norm": 0.005428459495306015,
      "learning_rate": 3.344878772884711e-06,
      "loss": 0.0003,
      "step": 5050
    },
    {
      "epoch": 2.503711034141514,
      "grad_norm": 0.001629415201023221,
      "learning_rate": 3.3118918027379187e-06,
      "loss": 0.0002,
      "step": 5060
    },
    {
      "epoch": 2.508659079663533,
      "grad_norm": 0.0034507657401263714,
      "learning_rate": 3.2789048325911267e-06,
      "loss": 0.0002,
      "step": 5070
    },
    {
      "epoch": 2.5136071251855516,
      "grad_norm": 0.004431388806551695,
      "learning_rate": 3.2459178624443348e-06,
      "loss": 0.0003,
      "step": 5080
    },
    {
      "epoch": 2.5185551707075704,
      "grad_norm": 0.0031868258956819773,
      "learning_rate": 3.2129308922975428e-06,
      "loss": 0.0383,
      "step": 5090
    },
    {
      "epoch": 2.523503216229589,
      "grad_norm": 0.3385382890701294,
      "learning_rate": 3.1799439221507504e-06,
      "loss": 0.0012,
      "step": 5100
    },
    {
      "epoch": 2.5284512617516084,
      "grad_norm": 0.002560005523264408,
      "learning_rate": 3.146956952003959e-06,
      "loss": 0.0001,
      "step": 5110
    },
    {
      "epoch": 2.533399307273627,
      "grad_norm": 0.0009507280774414539,
      "learning_rate": 3.113969981857167e-06,
      "loss": 0.0001,
      "step": 5120
    },
    {
      "epoch": 2.538347352795646,
      "grad_norm": 0.017968865111470222,
      "learning_rate": 3.0809830117103745e-06,
      "loss": 0.0001,
      "step": 5130
    },
    {
      "epoch": 2.5432953983176647,
      "grad_norm": 0.004293992184102535,
      "learning_rate": 3.047996041563583e-06,
      "loss": 0.0003,
      "step": 5140
    },
    {
      "epoch": 2.5482434438396835,
      "grad_norm": 0.0017181748989969492,
      "learning_rate": 3.0150090714167905e-06,
      "loss": 0.0001,
      "step": 5150
    },
    {
      "epoch": 2.5531914893617023,
      "grad_norm": 0.011937184259295464,
      "learning_rate": 2.9820221012699985e-06,
      "loss": 0.0274,
      "step": 5160
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 0.007260187994688749,
      "learning_rate": 2.949035131123207e-06,
      "loss": 0.0001,
      "step": 5170
    },
    {
      "epoch": 2.56308758040574,
      "grad_norm": 6.568288326263428,
      "learning_rate": 2.9160481609764146e-06,
      "loss": 0.0395,
      "step": 5180
    },
    {
      "epoch": 2.5680356259277586,
      "grad_norm": 23.438304901123047,
      "learning_rate": 2.8830611908296226e-06,
      "loss": 0.0235,
      "step": 5190
    },
    {
      "epoch": 2.5729836714497774,
      "grad_norm": 0.009583188220858574,
      "learning_rate": 2.8500742206828302e-06,
      "loss": 0.0001,
      "step": 5200
    },
    {
      "epoch": 2.577931716971796,
      "grad_norm": 0.004085449036210775,
      "learning_rate": 2.8170872505360387e-06,
      "loss": 0.0002,
      "step": 5210
    },
    {
      "epoch": 2.582879762493815,
      "grad_norm": 0.1552029550075531,
      "learning_rate": 2.7841002803892463e-06,
      "loss": 0.0307,
      "step": 5220
    },
    {
      "epoch": 2.5878278080158337,
      "grad_norm": 0.011877148412168026,
      "learning_rate": 2.7511133102424543e-06,
      "loss": 0.0003,
      "step": 5230
    },
    {
      "epoch": 2.5927758535378524,
      "grad_norm": 0.019670676440000534,
      "learning_rate": 2.7181263400956627e-06,
      "loss": 0.0015,
      "step": 5240
    },
    {
      "epoch": 2.5977238990598712,
      "grad_norm": 0.00179294275585562,
      "learning_rate": 2.6851393699488704e-06,
      "loss": 0.0004,
      "step": 5250
    },
    {
      "epoch": 2.60267194458189,
      "grad_norm": 0.003201988060027361,
      "learning_rate": 2.6521523998020784e-06,
      "loss": 0.0001,
      "step": 5260
    },
    {
      "epoch": 2.6076199901039088,
      "grad_norm": 1.5256478786468506,
      "learning_rate": 2.6191654296552864e-06,
      "loss": 0.0018,
      "step": 5270
    },
    {
      "epoch": 2.6125680356259275,
      "grad_norm": 0.017972836270928383,
      "learning_rate": 2.5861784595084944e-06,
      "loss": 0.0265,
      "step": 5280
    },
    {
      "epoch": 2.6175160811479463,
      "grad_norm": 1.0858359336853027,
      "learning_rate": 2.553191489361702e-06,
      "loss": 0.0002,
      "step": 5290
    },
    {
      "epoch": 2.622464126669965,
      "grad_norm": 0.0010249781189486384,
      "learning_rate": 2.5202045192149105e-06,
      "loss": 0.0004,
      "step": 5300
    },
    {
      "epoch": 2.6274121721919843,
      "grad_norm": 0.0020270701497793198,
      "learning_rate": 2.4872175490681185e-06,
      "loss": 0.0002,
      "step": 5310
    },
    {
      "epoch": 2.632360217714003,
      "grad_norm": 0.039418455213308334,
      "learning_rate": 2.4542305789213265e-06,
      "loss": 0.0379,
      "step": 5320
    },
    {
      "epoch": 2.637308263236022,
      "grad_norm": 0.0037904810160398483,
      "learning_rate": 2.421243608774534e-06,
      "loss": 0.0002,
      "step": 5330
    },
    {
      "epoch": 2.6422563087580406,
      "grad_norm": 0.007710678037256002,
      "learning_rate": 2.388256638627742e-06,
      "loss": 0.0101,
      "step": 5340
    },
    {
      "epoch": 2.6472043542800594,
      "grad_norm": 0.001337846857495606,
      "learning_rate": 2.35526966848095e-06,
      "loss": 0.0442,
      "step": 5350
    },
    {
      "epoch": 2.652152399802078,
      "grad_norm": 0.001970655517652631,
      "learning_rate": 2.322282698334158e-06,
      "loss": 0.0005,
      "step": 5360
    },
    {
      "epoch": 2.657100445324097,
      "grad_norm": 0.0036245465744286776,
      "learning_rate": 2.2892957281873662e-06,
      "loss": 0.0001,
      "step": 5370
    },
    {
      "epoch": 2.6620484908461157,
      "grad_norm": 0.002017468446865678,
      "learning_rate": 2.256308758040574e-06,
      "loss": 0.0001,
      "step": 5380
    },
    {
      "epoch": 2.6669965363681345,
      "grad_norm": 0.0022716629318892956,
      "learning_rate": 2.2233217878937823e-06,
      "loss": 0.0004,
      "step": 5390
    },
    {
      "epoch": 2.6719445818901533,
      "grad_norm": 0.001517022610642016,
      "learning_rate": 2.1903348177469903e-06,
      "loss": 0.0001,
      "step": 5400
    },
    {
      "epoch": 2.676892627412172,
      "grad_norm": 0.002808080753311515,
      "learning_rate": 2.157347847600198e-06,
      "loss": 0.0001,
      "step": 5410
    },
    {
      "epoch": 2.6818406729341913,
      "grad_norm": 0.01073595229536295,
      "learning_rate": 2.124360877453406e-06,
      "loss": 0.0001,
      "step": 5420
    },
    {
      "epoch": 2.68678871845621,
      "grad_norm": 0.0055045271292328835,
      "learning_rate": 2.091373907306614e-06,
      "loss": 0.0001,
      "step": 5430
    },
    {
      "epoch": 2.691736763978229,
      "grad_norm": 0.0026762972120195627,
      "learning_rate": 2.058386937159822e-06,
      "loss": 0.0001,
      "step": 5440
    },
    {
      "epoch": 2.6966848095002476,
      "grad_norm": 0.0015311328461393714,
      "learning_rate": 2.02539996701303e-06,
      "loss": 0.0001,
      "step": 5450
    },
    {
      "epoch": 2.7016328550222664,
      "grad_norm": 0.005090516060590744,
      "learning_rate": 1.992412996866238e-06,
      "loss": 0.0092,
      "step": 5460
    },
    {
      "epoch": 2.706580900544285,
      "grad_norm": 0.001047588186338544,
      "learning_rate": 1.959426026719446e-06,
      "loss": 0.0396,
      "step": 5470
    },
    {
      "epoch": 2.711528946066304,
      "grad_norm": 0.0025559631176292896,
      "learning_rate": 1.926439056572654e-06,
      "loss": 0.0357,
      "step": 5480
    },
    {
      "epoch": 2.7164769915883227,
      "grad_norm": 0.013308130204677582,
      "learning_rate": 1.893452086425862e-06,
      "loss": 0.0001,
      "step": 5490
    },
    {
      "epoch": 2.7214250371103414,
      "grad_norm": 0.0011761847417801619,
      "learning_rate": 1.86046511627907e-06,
      "loss": 0.0007,
      "step": 5500
    },
    {
      "epoch": 2.7263730826323602,
      "grad_norm": 0.0015764860436320305,
      "learning_rate": 1.827478146132278e-06,
      "loss": 0.0857,
      "step": 5510
    },
    {
      "epoch": 2.731321128154379,
      "grad_norm": 0.002498041605576873,
      "learning_rate": 1.7944911759854858e-06,
      "loss": 0.0001,
      "step": 5520
    },
    {
      "epoch": 2.7362691736763978,
      "grad_norm": 0.0028141189832240343,
      "learning_rate": 1.7615042058386938e-06,
      "loss": 0.0002,
      "step": 5530
    },
    {
      "epoch": 2.7412172191984165,
      "grad_norm": 0.0029176680836826563,
      "learning_rate": 1.728517235691902e-06,
      "loss": 0.0127,
      "step": 5540
    },
    {
      "epoch": 2.7461652647204353,
      "grad_norm": 0.0022191694006323814,
      "learning_rate": 1.6955302655451096e-06,
      "loss": 0.0099,
      "step": 5550
    },
    {
      "epoch": 2.751113310242454,
      "grad_norm": 0.0031275709625333548,
      "learning_rate": 1.6625432953983179e-06,
      "loss": 0.0003,
      "step": 5560
    },
    {
      "epoch": 2.756061355764473,
      "grad_norm": 0.07607778906822205,
      "learning_rate": 1.629556325251526e-06,
      "loss": 0.0002,
      "step": 5570
    },
    {
      "epoch": 2.7610094012864916,
      "grad_norm": 0.0016372015234082937,
      "learning_rate": 1.5965693551047337e-06,
      "loss": 0.0001,
      "step": 5580
    },
    {
      "epoch": 2.7659574468085104,
      "grad_norm": 0.0016566045815125108,
      "learning_rate": 1.5635823849579417e-06,
      "loss": 0.0001,
      "step": 5590
    },
    {
      "epoch": 2.770905492330529,
      "grad_norm": 0.018526725471019745,
      "learning_rate": 1.5305954148111496e-06,
      "loss": 0.0225,
      "step": 5600
    },
    {
      "epoch": 2.7758535378525484,
      "grad_norm": 0.0012902001617476344,
      "learning_rate": 1.4976084446643576e-06,
      "loss": 0.0004,
      "step": 5610
    },
    {
      "epoch": 2.780801583374567,
      "grad_norm": 20.378032684326172,
      "learning_rate": 1.4646214745175658e-06,
      "loss": 0.0025,
      "step": 5620
    },
    {
      "epoch": 2.785749628896586,
      "grad_norm": 0.0011318776523694396,
      "learning_rate": 1.4316345043707736e-06,
      "loss": 0.0123,
      "step": 5630
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 0.0010003232164308429,
      "learning_rate": 1.3986475342239817e-06,
      "loss": 0.0167,
      "step": 5640
    },
    {
      "epoch": 2.7956457199406235,
      "grad_norm": 0.0010155282216146588,
      "learning_rate": 1.3656605640771897e-06,
      "loss": 0.0268,
      "step": 5650
    },
    {
      "epoch": 2.8005937654626423,
      "grad_norm": 0.003975769970566034,
      "learning_rate": 1.3326735939303975e-06,
      "loss": 0.0062,
      "step": 5660
    },
    {
      "epoch": 2.805541810984661,
      "grad_norm": 0.0038644352462142706,
      "learning_rate": 1.2996866237836055e-06,
      "loss": 0.0003,
      "step": 5670
    },
    {
      "epoch": 2.81048985650668,
      "grad_norm": 0.29919007420539856,
      "learning_rate": 1.2666996536368138e-06,
      "loss": 0.0398,
      "step": 5680
    },
    {
      "epoch": 2.8154379020286986,
      "grad_norm": 6.118772506713867,
      "learning_rate": 1.2337126834900216e-06,
      "loss": 0.0434,
      "step": 5690
    },
    {
      "epoch": 2.8203859475507174,
      "grad_norm": 0.008186768740415573,
      "learning_rate": 1.2007257133432296e-06,
      "loss": 0.0001,
      "step": 5700
    },
    {
      "epoch": 2.825333993072736,
      "grad_norm": 0.000962803780566901,
      "learning_rate": 1.1677387431964374e-06,
      "loss": 0.0001,
      "step": 5710
    },
    {
      "epoch": 2.830282038594755,
      "grad_norm": 0.0010169005254283547,
      "learning_rate": 1.1347517730496454e-06,
      "loss": 0.0001,
      "step": 5720
    },
    {
      "epoch": 2.835230084116774,
      "grad_norm": 0.03243269771337509,
      "learning_rate": 1.1017648029028535e-06,
      "loss": 0.0001,
      "step": 5730
    },
    {
      "epoch": 2.840178129638793,
      "grad_norm": 0.005815545562654734,
      "learning_rate": 1.0687778327560615e-06,
      "loss": 0.0061,
      "step": 5740
    },
    {
      "epoch": 2.8451261751608117,
      "grad_norm": 0.0010005414951592684,
      "learning_rate": 1.0357908626092695e-06,
      "loss": 0.0289,
      "step": 5750
    },
    {
      "epoch": 2.8500742206828305,
      "grad_norm": 0.04448213055729866,
      "learning_rate": 1.0028038924624773e-06,
      "loss": 0.0001,
      "step": 5760
    },
    {
      "epoch": 2.8550222662048492,
      "grad_norm": 0.008925292640924454,
      "learning_rate": 9.698169223156854e-07,
      "loss": 0.0001,
      "step": 5770
    },
    {
      "epoch": 2.859970311726868,
      "grad_norm": 0.0022454007994383574,
      "learning_rate": 9.368299521688934e-07,
      "loss": 0.0374,
      "step": 5780
    },
    {
      "epoch": 2.8649183572488868,
      "grad_norm": 0.04975239560008049,
      "learning_rate": 9.038429820221013e-07,
      "loss": 0.0001,
      "step": 5790
    },
    {
      "epoch": 2.8698664027709055,
      "grad_norm": 0.0043885232880711555,
      "learning_rate": 8.708560118753092e-07,
      "loss": 0.0001,
      "step": 5800
    },
    {
      "epoch": 2.8748144482929243,
      "grad_norm": 0.006347522605210543,
      "learning_rate": 8.378690417285174e-07,
      "loss": 0.0003,
      "step": 5810
    },
    {
      "epoch": 2.879762493814943,
      "grad_norm": 0.002072261879220605,
      "learning_rate": 8.048820715817253e-07,
      "loss": 0.0005,
      "step": 5820
    },
    {
      "epoch": 2.884710539336962,
      "grad_norm": 0.003906330559402704,
      "learning_rate": 7.718951014349332e-07,
      "loss": 0.0001,
      "step": 5830
    },
    {
      "epoch": 2.8896585848589806,
      "grad_norm": 0.0015940823359414935,
      "learning_rate": 7.389081312881412e-07,
      "loss": 0.0002,
      "step": 5840
    },
    {
      "epoch": 2.8946066303809994,
      "grad_norm": 0.008783211000263691,
      "learning_rate": 7.059211611413492e-07,
      "loss": 0.0001,
      "step": 5850
    },
    {
      "epoch": 2.899554675903018,
      "grad_norm": 0.09045571088790894,
      "learning_rate": 6.729341909945572e-07,
      "loss": 0.0002,
      "step": 5860
    },
    {
      "epoch": 2.904502721425037,
      "grad_norm": 0.1824129968881607,
      "learning_rate": 6.399472208477652e-07,
      "loss": 0.0002,
      "step": 5870
    },
    {
      "epoch": 2.9094507669470557,
      "grad_norm": 0.006014722399413586,
      "learning_rate": 6.069602507009731e-07,
      "loss": 0.0002,
      "step": 5880
    },
    {
      "epoch": 2.9143988124690745,
      "grad_norm": 0.3206616938114166,
      "learning_rate": 5.739732805541811e-07,
      "loss": 0.0065,
      "step": 5890
    },
    {
      "epoch": 2.9193468579910933,
      "grad_norm": 0.022616779431700706,
      "learning_rate": 5.409863104073891e-07,
      "loss": 0.0233,
      "step": 5900
    },
    {
      "epoch": 2.924294903513112,
      "grad_norm": 0.002706903265789151,
      "learning_rate": 5.079993402605971e-07,
      "loss": 0.0003,
      "step": 5910
    },
    {
      "epoch": 2.9292429490351313,
      "grad_norm": 0.0017269197851419449,
      "learning_rate": 4.7501237011380505e-07,
      "loss": 0.0001,
      "step": 5920
    },
    {
      "epoch": 2.93419099455715,
      "grad_norm": 0.0011886799475178123,
      "learning_rate": 4.420253999670131e-07,
      "loss": 0.0743,
      "step": 5930
    },
    {
      "epoch": 2.939139040079169,
      "grad_norm": 0.007892570458352566,
      "learning_rate": 4.09038429820221e-07,
      "loss": 0.0337,
      "step": 5940
    },
    {
      "epoch": 2.9440870856011876,
      "grad_norm": 0.0028426917269825935,
      "learning_rate": 3.76051459673429e-07,
      "loss": 0.0241,
      "step": 5950
    },
    {
      "epoch": 2.9490351311232064,
      "grad_norm": 0.0026965918950736523,
      "learning_rate": 3.4306448952663705e-07,
      "loss": 0.0001,
      "step": 5960
    },
    {
      "epoch": 2.953983176645225,
      "grad_norm": 0.00360115896910429,
      "learning_rate": 3.1007751937984497e-07,
      "loss": 0.0002,
      "step": 5970
    },
    {
      "epoch": 2.958931222167244,
      "grad_norm": 0.001336471876129508,
      "learning_rate": 2.7709054923305294e-07,
      "loss": 0.0002,
      "step": 5980
    },
    {
      "epoch": 2.9638792676892627,
      "grad_norm": 0.005517998710274696,
      "learning_rate": 2.441035790862609e-07,
      "loss": 0.0001,
      "step": 5990
    },
    {
      "epoch": 2.9688273132112815,
      "grad_norm": 0.002456523710861802,
      "learning_rate": 2.1111660893946892e-07,
      "loss": 0.0699,
      "step": 6000
    },
    {
      "epoch": 2.9737753587333002,
      "grad_norm": 0.00382255925796926,
      "learning_rate": 1.781296387926769e-07,
      "loss": 0.0113,
      "step": 6010
    },
    {
      "epoch": 2.978723404255319,
      "grad_norm": 0.002240643138065934,
      "learning_rate": 1.451426686458849e-07,
      "loss": 0.0067,
      "step": 6020
    },
    {
      "epoch": 2.9836714497773382,
      "grad_norm": 0.015105263330042362,
      "learning_rate": 1.1215569849909286e-07,
      "loss": 0.0002,
      "step": 6030
    },
    {
      "epoch": 2.988619495299357,
      "grad_norm": 0.006423927377909422,
      "learning_rate": 7.916872835230086e-08,
      "loss": 0.0001,
      "step": 6040
    },
    {
      "epoch": 2.9935675408213758,
      "grad_norm": 0.24241109192371368,
      "learning_rate": 4.6181758205508826e-08,
      "loss": 0.0001,
      "step": 6050
    },
    {
      "epoch": 2.9985155863433945,
      "grad_norm": 0.001093497616238892,
      "learning_rate": 1.3194788058716807e-08,
      "loss": 0.0289,
      "step": 6060
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.98413140311804,
      "eval_f1": 0.983435047951177,
      "eval_loss": 0.09428271651268005,
      "eval_precision": 0.9791666666666666,
      "eval_recall": 0.9877408056042032,
      "eval_runtime": 170.2252,
      "eval_samples_per_second": 21.101,
      "eval_steps_per_second": 1.322,
      "step": 6063
    }
  ]
}